{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "OFKxEUQXLe3P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Importing the basics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "TEST_PROPORTION = 0.1\n",
        "VAL_PROPORTION = 0.15\n",
        "FILE_PATH = \"clean_dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "jXOx6_TEL0x6"
      },
      "outputs": [],
      "source": [
        "#Job resume categorization, callback or no callback, categorize without attributes to bias it such as names or gender,\n",
        "#dataset is randomized and sent to real job applications that gave or did not give callbacks.\n",
        "\n",
        "#A test set where we can verify there is no bias to name or gender would be great, only based on experience or schooling, since there is a chance there could\n",
        "#be bias in the callbacks in the data\n",
        "\n",
        "#Maybe a more general model by combining similar datasets? As this one is strictly 2 cities in the USA during 2001-2002\n",
        "\n",
        "#If the vector at the end can be linked back to either name or gender or [insert other attribute that should not have bias], the AI is still biased.\n",
        "\n",
        "#If anyone is reading this, would it be possible to drop the chosen dataset's/datasets' zip file/s in the discord?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "KRSz8o9_RTI_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "311\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "323\n",
            "324\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "332\n",
            "334\n",
            "335\n",
            "336\n",
            "339\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "356\n",
            "358\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "367\n",
            "369\n",
            "370\n",
            "371\n",
            "373\n",
            "374\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "396\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "404\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "413\n",
            "414\n",
            "416\n",
            "417\n",
            "418\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "446\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "461\n",
            "462\n",
            "466\n",
            "468\n",
            "469\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "481\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "491\n",
            "492\n",
            "495\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "503\n",
            "505\n",
            "509\n",
            "510\n",
            "513\n",
            "514\n",
            "515\n",
            "517\n",
            "519\n",
            "520\n",
            "522\n",
            "525\n",
            "526\n",
            "529\n",
            "532\n",
            "533\n",
            "534\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "555\n",
            "556\n",
            "558\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "566\n",
            "568\n",
            "570\n",
            "571\n",
            "572\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "598\n",
            "599\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "633\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "644\n",
            "645\n",
            "647\n",
            "648\n",
            "650\n",
            "653\n",
            "656\n",
            "660\n",
            "661\n",
            "663\n",
            "664\n",
            "665\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "673\n",
            "677\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "688\n",
            "689\n",
            "ones: 211\n",
            "zeros: 210\n"
          ]
        }
      ],
      "source": [
        "# Read Dataset\n",
        "data = pd.read_csv(FILE_PATH)\n",
        "\n",
        "# Drop zipcodes\n",
        "data = data.drop([\"ZipCode\",\"Ethnicity\"], axis=1)\n",
        "\n",
        "# One hot encode categorical attributes.\n",
        "columns = [\"Industry\", \"Citizen\"]\n",
        "data = pd.get_dummies(data=data, columns=columns, dtype=int)\n",
        "ones = 0\n",
        "zeros = 0\n",
        "for index, row in data.iterrows():\n",
        "    if row['Gender']==1:\n",
        "        ones+=1\n",
        "    else:\n",
        "        zeros+=1\n",
        "\n",
        "ones2=0\n",
        "zeros2=0\n",
        "for index, row in data.iterrows():\n",
        "    if row['Gender']==1:\n",
        "        if ones2 > min(ones,zeros):\n",
        "            print(index)\n",
        "            data = data.drop(index=index)\n",
        "        ones2+=1\n",
        "    else:\n",
        "        if zeros2 > min(ones,zeros):\n",
        "            print(index)\n",
        "            data = data.drop(index=index)\n",
        "        zeros2+=1\n",
        "\n",
        "\n",
        "ones = 0\n",
        "zeros = 0\n",
        "for index, row in data.iterrows():\n",
        "    if row['Gender']==1:\n",
        "        ones+=1\n",
        "    else:\n",
        "        zeros+=1\n",
        "\n",
        "print(\"ones:\",ones)\n",
        "print(\"zeros:\",zeros)\n",
        "\n",
        "\n",
        "# To pytorch.tensor format\n",
        "X_tensor = torch.tensor(\n",
        "    data.drop([\"Approved\", \"Gender\"], axis=1).values, dtype=torch.float32\n",
        ")\n",
        "y_tensor_approved = F.one_hot(torch.tensor(data[\"Approved\"].values, dtype=torch.int64))\n",
        "y_tensor_gender = F.one_hot(torch.tensor(data[\"Gender\"].values, dtype=torch.int64))\n",
        "\n",
        "# Define a custom dataset\n",
        "class Custom_Dataset(Dataset):\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]\n",
        "\n",
        "# Init Dataset\n",
        "pay_dataset = Custom_Dataset(X_tensor, y_tensor_gender)\n",
        "\n",
        "# Calculate Dataset proportions\n",
        "test_size = int(TEST_PROPORTION * len(pay_dataset))\n",
        "val_size = int(VAL_PROPORTION * len(pay_dataset))\n",
        "train_size = len(pay_dataset) - test_size - val_size\n",
        "\n",
        "# Creates datasets\n",
        "train_pay_dataset, val_pay_dataset, test_pay_dataset = torch.utils.data.random_split(\n",
        "    pay_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "# Creates DataLoaders.\n",
        "train_gender_loader = DataLoader(train_pay_dataset, shuffle=True, batch_size=16)\n",
        "val_gender_loader = DataLoader(val_pay_dataset, shuffle=True, batch_size=16)\n",
        "test_gender_loader = DataLoader(val_pay_dataset, shuffle=True, batch_size=16)\n",
        "\n",
        "\n",
        "# Init Dataset\n",
        "pay_dataset = Custom_Dataset(X_tensor, y_tensor_approved)\n",
        "\n",
        "# Calculate Dataset proportions\n",
        "test_size = int(TEST_PROPORTION * len(pay_dataset))\n",
        "val_size = int(VAL_PROPORTION * len(pay_dataset))\n",
        "train_size = len(pay_dataset) - test_size - val_size\n",
        "\n",
        "# Creates datasets\n",
        "train_pay_dataset, val_pay_dataset, test_pay_dataset = torch.utils.data.random_split(\n",
        "    pay_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "# Creates DataLoaders.\n",
        "train_approved_loader = DataLoader(train_pay_dataset, shuffle=True, batch_size=16)\n",
        "val_approved_loader = DataLoader(val_pay_dataset, shuffle=True, batch_size=16)\n",
        "test_approved_loader = DataLoader(val_pay_dataset, shuffle=True, batch_size=16)\n",
        "\n",
        "#TODO Delete\n",
        "it = iter(train_gender_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 40.0000,   6.5000,   1.0000,   1.0000,   3.5000,   1.0000,   1.0000,\n",
            "          1.0000,   0.0000, 500.0000,   0.0000,   0.0000,   1.0000,   0.0000,\n",
            "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "          0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   0.0000])\n",
            "tensor([0, 1])\n",
            "Index(['Age', 'Debt', 'Married', 'BankCustomer', 'YearsEmployed',\n",
            "       'PriorDefault', 'Employed', 'CreditScore', 'DriversLicense', 'Income',\n",
            "       'Industry_CommunicationServices', 'Industry_ConsumerDiscretionary',\n",
            "       'Industry_ConsumerStaples', 'Industry_Education', 'Industry_Energy',\n",
            "       'Industry_Financials', 'Industry_Healthcare', 'Industry_Industrials',\n",
            "       'Industry_InformationTechnology', 'Industry_Materials',\n",
            "       'Industry_Real Estate', 'Industry_Research', 'Industry_Transport',\n",
            "       'Industry_Utilities', 'Citizen_ByBirth', 'Citizen_ByOtherMeans',\n",
            "       'Citizen_Temporary'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "batch = next(it)\n",
        "\n",
        "# Test print TODO Delete\n",
        "print(batch[0][0,:])\n",
        "print(batch[1][0])\n",
        "\n",
        "print(data.drop([\"Approved\", \"Gender\"], axis=1).columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define basic ANN\n",
        "class ANN_approved(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.l1 = nn.Linear(27, 32)\n",
        "        self.l2 = nn.Linear(32, 16)\n",
        "        self.l3 = nn.Linear(16, 2)\n",
        "\n",
        "        self.soft = nn.Softmax(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.act(x)\n",
        "        self.drop(x)\n",
        "        x = self.l2(x)\n",
        "        out = self.act(x)\n",
        "        self.drop(out)\n",
        "        out = self.soft(out)\n",
        "        out = self.l3(out)\n",
        "        return out, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define basic ANN\n",
        "class ANN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.l1 = nn.Linear(16, 32)\n",
        "        self.l2 = nn.Linear(32, 16)\n",
        "        self.l3 = nn.Linear(16, 2)\n",
        "\n",
        "        self.soft = nn.Softmax(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.act(x)\n",
        "        self.drop(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.act(x)\n",
        "        self.drop(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.soft(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_2(model, train_loader, val_loader, epochs, optimizer, criterion, augment=None):\n",
        "\n",
        "    best_model = None\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    train_lst = []\n",
        "    val_lst = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*15)\n",
        "        print(\"Processing epoch:\",epoch+1,\"of\",epochs)\n",
        "        print(\"-\"*15)\n",
        "        model.train()\n",
        "\n",
        "        train_loss = 0\n",
        "        train_count = 0\n",
        "\n",
        "        for batch_nr, (features,label) in enumerate(train_loader):\n",
        "            features, label = features.to(device), label.to(device).float()\n",
        "\n",
        "            #Add augmentations\n",
        "            if augment!=None:\n",
        "                features = augment(features)\n",
        "            prediction = model(features)[0].squeeze()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(prediction, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss  +=  loss.item()\n",
        "            train_count +=  1\n",
        "\n",
        "            #if (batch_nr%10==0):\n",
        "            #    print(\"Batch_nr: \", batch_nr, \"\\tTrain loss: \", (loss.item()))\n",
        "\n",
        "        val_loss = 0\n",
        "        val_count = 0\n",
        "\n",
        "        model.eval()\n",
        "        for batch_nr, (features,label) in enumerate(val_loader):\n",
        "            features, label = features.to(device), label.to(device).float()\n",
        "\n",
        "            prediction = model(features)[0].squeeze()\n",
        "\n",
        "            loss = criterion(prediction, label)\n",
        "\n",
        "            val_loss  +=  loss.item()\n",
        "            val_count +=  1\n",
        "\n",
        "        \n",
        "        print(\"Validation loss:\\t\", (val_loss/val_count))\n",
        "        val_lst.append((val_loss/val_count))\n",
        "        print(\"Training loss:  \\t\", (train_loss/train_count))\n",
        "        train_lst.append((train_loss/train_count))\n",
        "\n",
        "        if (val_loss/val_count) < best_val_loss:\n",
        "            best_val_loss = val_loss/val_count\n",
        "            torch.save(model, \"best_model.pt\")\n",
        "            best_model = model\n",
        "\n",
        "    return best_model,train_lst,val_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "OXpaud6kBO5X"
      },
      "outputs": [],
      "source": [
        "def train_model(model1,model2, train_loader, val_loader, epochs, optimizer, criterion, augment=None):\n",
        "\n",
        "    best_model = None\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    train_lst = []\n",
        "    val_lst = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"-\"*15)\n",
        "        print(\"Processing epoch:\",epoch+1,\"of\",epochs)\n",
        "        print(\"-\"*15)\n",
        "        model1.eval()\n",
        "        model2.train()\n",
        "\n",
        "        train_loss = 0\n",
        "        train_count = 0\n",
        "\n",
        "        for batch_nr, (features,label) in enumerate(train_loader):\n",
        "            features, label = features.to(device), label.to(device).float()\n",
        "\n",
        "            #Add augmentations\n",
        "            if augment!=None:\n",
        "                features = augment(features)\n",
        "            prediction, final = model1(features)\n",
        "            prediction = model2(final).squeeze()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(prediction, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss  +=  loss.item()\n",
        "            train_count +=  1\n",
        "\n",
        "            #if (batch_nr%10==0):\n",
        "            #    print(\"Batch_nr: \", batch_nr, \"\\tTrain loss: \", (loss.item()))\n",
        "\n",
        "        val_loss = 0\n",
        "        val_count = 0\n",
        "\n",
        "        model2.eval()\n",
        "        for batch_nr, (features,label) in enumerate(val_loader):\n",
        "            features, label = features.to(device), label.to(device).float()\n",
        "\n",
        "            prediction, final = model1(features)\n",
        "            prediction = model2(final).squeeze()\n",
        "\n",
        "            loss = criterion(prediction, label)\n",
        "\n",
        "            val_loss  +=  loss.item()\n",
        "            val_count +=  1\n",
        "\n",
        "        \n",
        "        print(\"Validation loss:\\t\", (val_loss/val_count))\n",
        "        val_lst.append((val_loss/val_count))\n",
        "        print(\"Training loss:  \\t\", (train_loss/train_count))\n",
        "        train_lst.append((train_loss/train_count))\n",
        "\n",
        "        if (val_loss/val_count) < best_val_loss:\n",
        "            best_val_loss = val_loss/val_count\n",
        "            torch.save(model2, \"best_model2.pt\")\n",
        "            best_model = model2\n",
        "\n",
        "    return best_model,train_lst,val_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(test_loader,model1,model2):\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch_nr, (features,label) in enumerate(test_loader):\n",
        "        features, label = features.to(device), label.to(device).type(torch.int)\n",
        "\n",
        "\n",
        "        prediction, final = model1(features)\n",
        "        prediction = model2(final).squeeze().round().type(torch.int)\n",
        "        \n",
        "        all_preds.extend(torch.argmax(prediction.detach(),dim=1).tolist())\n",
        "        all_targets.extend(torch.argmax(label,dim=1).tolist())\n",
        "\n",
        "    cm = [[0,0],[0,0]]\n",
        "    for p,t in zip(all_preds,all_targets):\n",
        "        cm[p][t]+=1\n",
        "    \n",
        "    return cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_gender(model1,model2):\n",
        "    cm = test_model(test_gender_loader,model1,model2)\n",
        "    print(\"\\t\\t Male Prediction \\t Female Prediction\")\n",
        "    print(\"Male Label \\t\",cm[1][1],\"\\t\\t\\t\",cm[0][1])\n",
        "    print(\"Female Label\\t\",cm[1][0],\"\\t\\t\\t\",cm[0][0])\n",
        "    \n",
        "    print()\n",
        "    print()\n",
        "    print(\"Accuracy:\",(cm[1][1]+cm[0][0])/(cm[1][1]+cm[0][1]+cm[1][0]+cm[0][0]))\n",
        "    print()\n",
        "    print(\"Accuracy male:\",(cm[1][1])/(cm[1][1]+cm[0][1]))\n",
        "    print(\"Precision male:\",(cm[1][1]/(cm[1][1]+cm[1][0])))\n",
        "    print(\"Recall male:\",(cm[1][1]/(cm[1][1]+cm[0][1])))\n",
        "    print(\"F1-score male:\",(cm[1][1]*2)/(cm[1][1]*2+cm[0][1]+cm[1][0]))\n",
        "    print()\n",
        "    print(\"Accuracy female:\",(cm[0][0])/(cm[1][0]+cm[0][0]))\n",
        "    print(\"Precision female:\",(cm[0][0]/(cm[0][0]+cm[0][1])))\n",
        "    print(\"Recall female:\",(cm[0][0]/(cm[0][0]+cm[1][0])))\n",
        "    print(\"F1-score female:\",(cm[0][0]*2)/(cm[0][0]*2+cm[1][0]+cm[0][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------\n",
            "Processing epoch: 1 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.679347351193428\n",
            "Training loss:  \t 0.6793128967285156\n",
            "---------------\n",
            "Processing epoch: 2 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6768175363540649\n",
            "Training loss:  \t 0.6763145446777343\n",
            "---------------\n",
            "Processing epoch: 3 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6743391901254654\n",
            "Training loss:  \t 0.6737020343542099\n",
            "---------------\n",
            "Processing epoch: 4 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6721664667129517\n",
            "Training loss:  \t 0.6707544922828674\n",
            "---------------\n",
            "Processing epoch: 5 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6672109663486481\n",
            "Training loss:  \t 0.6682345002889634\n",
            "---------------\n",
            "Processing epoch: 6 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6655360907316208\n",
            "Training loss:  \t 0.6657981842756271\n",
            "---------------\n",
            "Processing epoch: 7 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6606982946395874\n",
            "Training loss:  \t 0.6631997197866439\n",
            "---------------\n",
            "Processing epoch: 8 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6587141454219818\n",
            "Training loss:  \t 0.6601602613925934\n",
            "---------------\n",
            "Processing epoch: 9 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6566209346055984\n",
            "Training loss:  \t 0.6568684548139572\n",
            "---------------\n",
            "Processing epoch: 10 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6523604243993759\n",
            "Training loss:  \t 0.6538710951805115\n",
            "---------------\n",
            "Processing epoch: 11 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6464063972234726\n",
            "Training loss:  \t 0.6512518018484116\n",
            "---------------\n",
            "Processing epoch: 12 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6435865312814713\n",
            "Training loss:  \t 0.6472005426883698\n",
            "---------------\n",
            "Processing epoch: 13 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406056731939316\n",
            "Training loss:  \t 0.6426874041557312\n",
            "---------------\n",
            "Processing epoch: 14 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381117552518845\n",
            "Training loss:  \t 0.6404392063617707\n",
            "---------------\n",
            "Processing epoch: 15 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6371138840913773\n",
            "Training loss:  \t 0.6362995564937591\n",
            "---------------\n",
            "Processing epoch: 16 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6353407651185989\n",
            "Training loss:  \t 0.6356581717729568\n",
            "---------------\n",
            "Processing epoch: 17 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6300838589668274\n",
            "Training loss:  \t 0.6309666126966477\n",
            "---------------\n",
            "Processing epoch: 18 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6274903118610382\n",
            "Training loss:  \t 0.6288073658943176\n",
            "---------------\n",
            "Processing epoch: 19 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6293573081493378\n",
            "Training loss:  \t 0.6254799157381058\n",
            "---------------\n",
            "Processing epoch: 20 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6259773820638657\n",
            "Training loss:  \t 0.6227983087301254\n",
            "---------------\n",
            "Processing epoch: 21 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6201644688844681\n",
            "Training loss:  \t 0.6219235807657242\n",
            "---------------\n",
            "Processing epoch: 22 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6174425482749939\n",
            "Training loss:  \t 0.6192739307880402\n",
            "---------------\n",
            "Processing epoch: 23 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6196091026067734\n",
            "Training loss:  \t 0.6160680651664734\n",
            "---------------\n",
            "Processing epoch: 24 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6130052506923676\n",
            "Training loss:  \t 0.6179918825626374\n",
            "---------------\n",
            "Processing epoch: 25 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6118089407682419\n",
            "Training loss:  \t 0.6135238468647003\n",
            "---------------\n",
            "Processing epoch: 26 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6124812215566635\n",
            "Training loss:  \t 0.6089747726917267\n",
            "---------------\n",
            "Processing epoch: 27 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6081720590591431\n",
            "Training loss:  \t 0.6074390977621078\n",
            "---------------\n",
            "Processing epoch: 28 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6098448783159256\n",
            "Training loss:  \t 0.6038698643445969\n",
            "---------------\n",
            "Processing epoch: 29 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6082689166069031\n",
            "Training loss:  \t 0.603103631734848\n",
            "---------------\n",
            "Processing epoch: 30 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6085638105869293\n",
            "Training loss:  \t 0.6022341340780258\n",
            "---------------\n",
            "Processing epoch: 31 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6031398624181747\n",
            "Training loss:  \t 0.5997227400541305\n",
            "---------------\n",
            "Processing epoch: 32 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6029611676931381\n",
            "Training loss:  \t 0.5962614089250564\n",
            "---------------\n",
            "Processing epoch: 33 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6027347296476364\n",
            "Training loss:  \t 0.5953878045082093\n",
            "---------------\n",
            "Processing epoch: 34 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.596260592341423\n",
            "Training loss:  \t 0.5940776854753494\n",
            "---------------\n",
            "Processing epoch: 35 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5965652763843536\n",
            "Training loss:  \t 0.5927684098482132\n",
            "---------------\n",
            "Processing epoch: 36 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5968416184186935\n",
            "Training loss:  \t 0.5896705120801926\n",
            "---------------\n",
            "Processing epoch: 37 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5963344722986221\n",
            "Training loss:  \t 0.5863388612866401\n",
            "---------------\n",
            "Processing epoch: 38 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5947524458169937\n",
            "Training loss:  \t 0.5852173566818237\n",
            "---------------\n",
            "Processing epoch: 39 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5905445069074631\n",
            "Training loss:  \t 0.586058384180069\n",
            "---------------\n",
            "Processing epoch: 40 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5908187031745911\n",
            "Training loss:  \t 0.5822586551308632\n",
            "---------------\n",
            "Processing epoch: 41 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.585794135928154\n",
            "Training loss:  \t 0.5824548318982125\n",
            "---------------\n",
            "Processing epoch: 42 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5873042047023773\n",
            "Training loss:  \t 0.5809438973665237\n",
            "---------------\n",
            "Processing epoch: 43 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5873050093650818\n",
            "Training loss:  \t 0.5769292861223221\n",
            "---------------\n",
            "Processing epoch: 44 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5871810019016266\n",
            "Training loss:  \t 0.5739828586578369\n",
            "---------------\n",
            "Processing epoch: 45 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5871045291423798\n",
            "Training loss:  \t 0.5751865833997727\n",
            "---------------\n",
            "Processing epoch: 46 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5781190246343613\n",
            "Training loss:  \t 0.572242358326912\n",
            "---------------\n",
            "Processing epoch: 47 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5805020481348038\n",
            "Training loss:  \t 0.5716872707009315\n",
            "---------------\n",
            "Processing epoch: 48 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5804331302642822\n",
            "Training loss:  \t 0.5668997779488564\n",
            "---------------\n",
            "Processing epoch: 49 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5764949172735214\n",
            "Training loss:  \t 0.5639010518789291\n",
            "---------------\n",
            "Processing epoch: 50 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5750358253717422\n",
            "Training loss:  \t 0.5679071754217148\n",
            "---------------\n",
            "Processing epoch: 51 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5772530883550644\n",
            "Training loss:  \t 0.5662077710032463\n",
            "---------------\n",
            "Processing epoch: 52 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5755389481782913\n",
            "Training loss:  \t 0.5642556056380272\n",
            "---------------\n",
            "Processing epoch: 53 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5751312226057053\n",
            "Training loss:  \t 0.5603716507554054\n",
            "---------------\n",
            "Processing epoch: 54 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5704145058989525\n",
            "Training loss:  \t 0.5615431398153305\n",
            "---------------\n",
            "Processing epoch: 55 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5699401050806046\n",
            "Training loss:  \t 0.5553441867232323\n",
            "---------------\n",
            "Processing epoch: 56 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5690432116389275\n",
            "Training loss:  \t 0.5563789263367653\n",
            "---------------\n",
            "Processing epoch: 57 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5669908374547958\n",
            "Training loss:  \t 0.5542316108942031\n",
            "---------------\n",
            "Processing epoch: 58 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5649125427007675\n",
            "Training loss:  \t 0.5545328736305237\n",
            "---------------\n",
            "Processing epoch: 59 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5673500597476959\n",
            "Training loss:  \t 0.5528796464204788\n",
            "---------------\n",
            "Processing epoch: 60 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5633299797773361\n",
            "Training loss:  \t 0.5529250890016556\n",
            "---------------\n",
            "Processing epoch: 61 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5669471472501755\n",
            "Training loss:  \t 0.5510732367634773\n",
            "---------------\n",
            "Processing epoch: 62 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5624583959579468\n",
            "Training loss:  \t 0.5533226385712624\n",
            "---------------\n",
            "Processing epoch: 63 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5614634156227112\n",
            "Training loss:  \t 0.5500731527805328\n",
            "---------------\n",
            "Processing epoch: 64 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5567571967840195\n",
            "Training loss:  \t 0.5461488604545593\n",
            "---------------\n",
            "Processing epoch: 65 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5579564422369003\n",
            "Training loss:  \t 0.5461843684315681\n",
            "---------------\n",
            "Processing epoch: 66 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5554772168397903\n",
            "Training loss:  \t 0.541733731329441\n",
            "---------------\n",
            "Processing epoch: 67 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5558396130800247\n",
            "Training loss:  \t 0.5435814902186393\n",
            "---------------\n",
            "Processing epoch: 68 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5513973757624626\n",
            "Training loss:  \t 0.546102936565876\n",
            "---------------\n",
            "Processing epoch: 69 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5528772547841072\n",
            "Training loss:  \t 0.5442902863025665\n",
            "---------------\n",
            "Processing epoch: 70 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5534224063158035\n",
            "Training loss:  \t 0.5367370069026947\n",
            "---------------\n",
            "Processing epoch: 71 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5502567738294601\n",
            "Training loss:  \t 0.5388097107410431\n",
            "---------------\n",
            "Processing epoch: 72 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5490602478384972\n",
            "Training loss:  \t 0.5373684287071228\n",
            "---------------\n",
            "Processing epoch: 73 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5507941842079163\n",
            "Training loss:  \t 0.5369132429361343\n",
            "---------------\n",
            "Processing epoch: 74 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5491085350513458\n",
            "Training loss:  \t 0.5338673323392868\n",
            "---------------\n",
            "Processing epoch: 75 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5446524769067764\n",
            "Training loss:  \t 0.5319660753011703\n",
            "---------------\n",
            "Processing epoch: 76 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5466177463531494\n",
            "Training loss:  \t 0.5303617134690285\n",
            "---------------\n",
            "Processing epoch: 77 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.547155924141407\n",
            "Training loss:  \t 0.5287743613123894\n",
            "---------------\n",
            "Processing epoch: 78 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5443650484085083\n",
            "Training loss:  \t 0.5280093595385551\n",
            "---------------\n",
            "Processing epoch: 79 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5439464598894119\n",
            "Training loss:  \t 0.5268361836671829\n",
            "---------------\n",
            "Processing epoch: 80 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5387183576822281\n",
            "Training loss:  \t 0.525001423060894\n",
            "---------------\n",
            "Processing epoch: 81 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5349602699279785\n",
            "Training loss:  \t 0.5237865433096885\n",
            "---------------\n",
            "Processing epoch: 82 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5322313159704208\n",
            "Training loss:  \t 0.5239003166556359\n",
            "---------------\n",
            "Processing epoch: 83 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5334930270910263\n",
            "Training loss:  \t 0.5203018844127655\n",
            "---------------\n",
            "Processing epoch: 84 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5362430140376091\n",
            "Training loss:  \t 0.5206036314368248\n",
            "---------------\n",
            "Processing epoch: 85 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5318374633789062\n",
            "Training loss:  \t 0.5201550915837287\n",
            "---------------\n",
            "Processing epoch: 86 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5961786955595016\n",
            "Training loss:  \t 0.5163246750831604\n",
            "---------------\n",
            "Processing epoch: 87 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5347485318779945\n",
            "Training loss:  \t 0.5315661936998367\n",
            "---------------\n",
            "Processing epoch: 88 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5315326005220413\n",
            "Training loss:  \t 0.5203901886940002\n",
            "---------------\n",
            "Processing epoch: 89 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.535485289990902\n",
            "Training loss:  \t 0.5188184410333634\n",
            "---------------\n",
            "Processing epoch: 90 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5259439423680305\n",
            "Training loss:  \t 0.5145126134157181\n",
            "---------------\n",
            "Processing epoch: 91 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5260136052966118\n",
            "Training loss:  \t 0.5136473953723908\n",
            "---------------\n",
            "Processing epoch: 92 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5234393328428268\n",
            "Training loss:  \t 0.5128494888544083\n",
            "---------------\n",
            "Processing epoch: 93 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5210545510053635\n",
            "Training loss:  \t 0.5096774727106095\n",
            "---------------\n",
            "Processing epoch: 94 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5183273628354073\n",
            "Training loss:  \t 0.5101083487272262\n",
            "---------------\n",
            "Processing epoch: 95 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5266602784395218\n",
            "Training loss:  \t 0.5209689170122147\n",
            "---------------\n",
            "Processing epoch: 96 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5292055830359459\n",
            "Training loss:  \t 0.515879724919796\n",
            "---------------\n",
            "Processing epoch: 97 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5249234437942505\n",
            "Training loss:  \t 0.5101219847798347\n",
            "---------------\n",
            "Processing epoch: 98 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5146806091070175\n",
            "Training loss:  \t 0.5073506295681\n",
            "---------------\n",
            "Processing epoch: 99 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5143722221255302\n",
            "Training loss:  \t 0.5062152802944183\n",
            "---------------\n",
            "Processing epoch: 100 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5124998241662979\n",
            "Training loss:  \t 0.5036715865135193\n",
            "---------------\n",
            "Processing epoch: 101 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5109776929020882\n",
            "Training loss:  \t 0.5024261981248855\n",
            "---------------\n",
            "Processing epoch: 102 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5193798020482063\n",
            "Training loss:  \t 0.5042339086532592\n",
            "---------------\n",
            "Processing epoch: 103 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5166866406798363\n",
            "Training loss:  \t 0.5187268570065499\n",
            "---------------\n",
            "Processing epoch: 104 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5182416290044785\n",
            "Training loss:  \t 0.5202597171068192\n",
            "---------------\n",
            "Processing epoch: 105 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.516921654343605\n",
            "Training loss:  \t 0.5226972430944443\n",
            "---------------\n",
            "Processing epoch: 106 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5188439711928368\n",
            "Training loss:  \t 0.510646952688694\n",
            "---------------\n",
            "Processing epoch: 107 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5222653299570084\n",
            "Training loss:  \t 0.5052968174219131\n",
            "---------------\n",
            "Processing epoch: 108 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.514401413500309\n",
            "Training loss:  \t 0.5025585368275642\n",
            "---------------\n",
            "Processing epoch: 109 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5074290335178375\n",
            "Training loss:  \t 0.49853999763727186\n",
            "---------------\n",
            "Processing epoch: 110 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5142167955636978\n",
            "Training loss:  \t 0.5226925298571586\n",
            "---------------\n",
            "Processing epoch: 111 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5090635195374489\n",
            "Training loss:  \t 0.5213048309087753\n",
            "---------------\n",
            "Processing epoch: 112 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5102613270282745\n",
            "Training loss:  \t 0.5222096055746078\n",
            "---------------\n",
            "Processing epoch: 113 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.514147013425827\n",
            "Training loss:  \t 0.5127265900373459\n",
            "---------------\n",
            "Processing epoch: 114 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5230299606919289\n",
            "Training loss:  \t 0.5038443893194199\n",
            "---------------\n",
            "Processing epoch: 115 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5206684917211533\n",
            "Training loss:  \t 0.4958865582942963\n",
            "---------------\n",
            "Processing epoch: 116 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5175800248980522\n",
            "Training loss:  \t 0.49734355360269544\n",
            "---------------\n",
            "Processing epoch: 117 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.507642112672329\n",
            "Training loss:  \t 0.49327932894229887\n",
            "---------------\n",
            "Processing epoch: 118 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5072006508708\n",
            "Training loss:  \t 0.4931793689727783\n",
            "---------------\n",
            "Processing epoch: 119 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5798992067575455\n",
            "Training loss:  \t 0.5072202980518341\n",
            "---------------\n",
            "Processing epoch: 120 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5066773071885109\n",
            "Training loss:  \t 0.5099543049931526\n",
            "---------------\n",
            "Processing epoch: 121 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5127808377146721\n",
            "Training loss:  \t 0.5003965079784394\n",
            "---------------\n",
            "Processing epoch: 122 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5090046375989914\n",
            "Training loss:  \t 0.4876022771000862\n",
            "---------------\n",
            "Processing epoch: 123 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5064337179064751\n",
            "Training loss:  \t 0.49947618693113327\n",
            "---------------\n",
            "Processing epoch: 124 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5049026310443878\n",
            "Training loss:  \t 0.4956275954842567\n",
            "---------------\n",
            "Processing epoch: 125 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48954905569553375\n",
            "Training loss:  \t 0.4818826004862785\n",
            "---------------\n",
            "Processing epoch: 126 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5029237791895866\n",
            "Training loss:  \t 0.48897603899240494\n",
            "---------------\n",
            "Processing epoch: 127 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4889822378754616\n",
            "Training loss:  \t 0.48715427368879316\n",
            "---------------\n",
            "Processing epoch: 128 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48394256085157394\n",
            "Training loss:  \t 0.482238681614399\n",
            "---------------\n",
            "Processing epoch: 129 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5023270696401596\n",
            "Training loss:  \t 0.49197982996702194\n",
            "---------------\n",
            "Processing epoch: 130 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.49094681441783905\n",
            "Training loss:  \t 0.48316545486450196\n",
            "---------------\n",
            "Processing epoch: 131 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4981105476617813\n",
            "Training loss:  \t 0.48821201622486116\n",
            "---------------\n",
            "Processing epoch: 132 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4967169538140297\n",
            "Training loss:  \t 0.4904502287507057\n",
            "---------------\n",
            "Processing epoch: 133 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.49332089722156525\n",
            "Training loss:  \t 0.5076897293329239\n",
            "---------------\n",
            "Processing epoch: 134 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4915560781955719\n",
            "Training loss:  \t 0.5086511269211769\n",
            "---------------\n",
            "Processing epoch: 135 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4913923144340515\n",
            "Training loss:  \t 0.5038955509662628\n",
            "---------------\n",
            "Processing epoch: 136 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5003181397914886\n",
            "Training loss:  \t 0.49541354179382324\n",
            "---------------\n",
            "Processing epoch: 137 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.505802258849144\n",
            "Training loss:  \t 0.4856698527932167\n",
            "---------------\n",
            "Processing epoch: 138 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5049144476652145\n",
            "Training loss:  \t 0.4821543231606483\n",
            "---------------\n",
            "Processing epoch: 139 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5065150409936905\n",
            "Training loss:  \t 0.4822909295558929\n",
            "---------------\n",
            "Processing epoch: 140 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.49528270959854126\n",
            "Training loss:  \t 0.4821507424116135\n",
            "---------------\n",
            "Processing epoch: 141 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4873867779970169\n",
            "Training loss:  \t 0.47785145938396456\n",
            "---------------\n",
            "Processing epoch: 142 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4833758622407913\n",
            "Training loss:  \t 0.47614255994558335\n",
            "---------------\n",
            "Processing epoch: 143 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48643510788679123\n",
            "Training loss:  \t 0.4756388008594513\n",
            "---------------\n",
            "Processing epoch: 144 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.47430939972400665\n",
            "Training loss:  \t 0.47241965383291246\n",
            "---------------\n",
            "Processing epoch: 145 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48403553664684296\n",
            "Training loss:  \t 0.4917424082756042\n",
            "---------------\n",
            "Processing epoch: 146 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48432332277297974\n",
            "Training loss:  \t 0.5069369167089463\n",
            "---------------\n",
            "Processing epoch: 147 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4832666292786598\n",
            "Training loss:  \t 0.50429707467556\n",
            "---------------\n",
            "Processing epoch: 148 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48497722297906876\n",
            "Training loss:  \t 0.4970755487680435\n",
            "---------------\n",
            "Processing epoch: 149 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48668372631073\n",
            "Training loss:  \t 0.4874744564294815\n",
            "---------------\n",
            "Processing epoch: 150 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.49356698244810104\n",
            "Training loss:  \t 0.4807711273431778\n",
            "---------------\n",
            "Processing epoch: 151 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4954521656036377\n",
            "Training loss:  \t 0.47599233537912367\n",
            "---------------\n",
            "Processing epoch: 152 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4988897442817688\n",
            "Training loss:  \t 0.4735680967569351\n",
            "---------------\n",
            "Processing epoch: 153 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.49665509164333344\n",
            "Training loss:  \t 0.4746706858277321\n",
            "---------------\n",
            "Processing epoch: 154 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4953315630555153\n",
            "Training loss:  \t 0.47034288197755814\n",
            "---------------\n",
            "Processing epoch: 155 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4944630563259125\n",
            "Training loss:  \t 0.4717304289340973\n",
            "---------------\n",
            "Processing epoch: 156 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4943902865052223\n",
            "Training loss:  \t 0.4702406272292137\n",
            "---------------\n",
            "Processing epoch: 157 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4867454692721367\n",
            "Training loss:  \t 0.46774803996086123\n",
            "---------------\n",
            "Processing epoch: 158 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48799269646406174\n",
            "Training loss:  \t 0.4644129440188408\n",
            "---------------\n",
            "Processing epoch: 159 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.48595210164785385\n",
            "Training loss:  \t 0.4645091205835342\n",
            "---------------\n",
            "Processing epoch: 160 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.47850044816732407\n",
            "Training loss:  \t 0.46439715325832365\n",
            "---------------\n",
            "Processing epoch: 161 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.471911184489727\n",
            "Training loss:  \t 0.46179723739624023\n",
            "---------------\n",
            "Processing epoch: 162 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.47622113674879074\n",
            "Training loss:  \t 0.45998514592647555\n",
            "---------------\n",
            "Processing epoch: 163 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4740402176976204\n",
            "Training loss:  \t 0.458991801738739\n",
            "---------------\n",
            "Processing epoch: 164 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4652171730995178\n",
            "Training loss:  \t 0.45721845179796217\n",
            "---------------\n",
            "Processing epoch: 165 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4683748930692673\n",
            "Training loss:  \t 0.4579430565237999\n",
            "---------------\n",
            "Processing epoch: 166 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.46602270007133484\n",
            "Training loss:  \t 0.4555034726858139\n",
            "---------------\n",
            "Processing epoch: 167 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4610435292124748\n",
            "Training loss:  \t 0.45371469259262087\n",
            "---------------\n",
            "Processing epoch: 168 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.46303611993789673\n",
            "Training loss:  \t 0.4561610743403435\n",
            "---------------\n",
            "Processing epoch: 169 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.46167656034231186\n",
            "Training loss:  \t 0.4537115454673767\n",
            "---------------\n",
            "Processing epoch: 170 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.45444321632385254\n",
            "Training loss:  \t 0.45637772381305697\n",
            "---------------\n",
            "Processing epoch: 171 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4634293094277382\n",
            "Training loss:  \t 0.45128893554210664\n",
            "---------------\n",
            "Processing epoch: 172 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4512583538889885\n",
            "Training loss:  \t 0.45049650222063065\n",
            "---------------\n",
            "Processing epoch: 173 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44022996723651886\n",
            "Training loss:  \t 0.45308169573545454\n",
            "---------------\n",
            "Processing epoch: 174 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.45782405138015747\n",
            "Training loss:  \t 0.44827329069375993\n",
            "---------------\n",
            "Processing epoch: 175 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.43713466078042984\n",
            "Training loss:  \t 0.44972201287746427\n",
            "---------------\n",
            "Processing epoch: 176 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.43725821375846863\n",
            "Training loss:  \t 0.4456070840358734\n",
            "---------------\n",
            "Processing epoch: 177 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4630711227655411\n",
            "Training loss:  \t 0.4488653793931007\n",
            "---------------\n",
            "Processing epoch: 178 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4605366885662079\n",
            "Training loss:  \t 0.4692636221647263\n",
            "---------------\n",
            "Processing epoch: 179 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4568929448723793\n",
            "Training loss:  \t 0.4543231427669525\n",
            "---------------\n",
            "Processing epoch: 180 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.45550379157066345\n",
            "Training loss:  \t 0.4502136528491974\n",
            "---------------\n",
            "Processing epoch: 181 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4534457251429558\n",
            "Training loss:  \t 0.48908829092979433\n",
            "---------------\n",
            "Processing epoch: 182 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4566466137766838\n",
            "Training loss:  \t 0.49127852022647855\n",
            "---------------\n",
            "Processing epoch: 183 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.455349363386631\n",
            "Training loss:  \t 0.4823993131518364\n",
            "---------------\n",
            "Processing epoch: 184 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.45054221898317337\n",
            "Training loss:  \t 0.47504009306430817\n",
            "---------------\n",
            "Processing epoch: 185 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4571848288178444\n",
            "Training loss:  \t 0.46846928745508193\n",
            "---------------\n",
            "Processing epoch: 186 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.45814721286296844\n",
            "Training loss:  \t 0.4497814506292343\n",
            "---------------\n",
            "Processing epoch: 187 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4561714455485344\n",
            "Training loss:  \t 0.4466682061553001\n",
            "---------------\n",
            "Processing epoch: 188 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4501797929406166\n",
            "Training loss:  \t 0.4440519481897354\n",
            "---------------\n",
            "Processing epoch: 189 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44371477514505386\n",
            "Training loss:  \t 0.44122840017080306\n",
            "---------------\n",
            "Processing epoch: 190 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44320034980773926\n",
            "Training loss:  \t 0.4364606499671936\n",
            "---------------\n",
            "Processing epoch: 191 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42980945110321045\n",
            "Training loss:  \t 0.43618340119719506\n",
            "---------------\n",
            "Processing epoch: 192 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44476302713155746\n",
            "Training loss:  \t 0.4360755354166031\n",
            "---------------\n",
            "Processing epoch: 193 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4286552518606186\n",
            "Training loss:  \t 0.4351037174463272\n",
            "---------------\n",
            "Processing epoch: 194 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4175731837749481\n",
            "Training loss:  \t 0.4310717821121216\n",
            "---------------\n",
            "Processing epoch: 195 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41698984801769257\n",
            "Training loss:  \t 0.43405060172080995\n",
            "---------------\n",
            "Processing epoch: 196 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44614942371845245\n",
            "Training loss:  \t 0.4613120540976524\n",
            "---------------\n",
            "Processing epoch: 197 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44725362956523895\n",
            "Training loss:  \t 0.4897279441356659\n",
            "---------------\n",
            "Processing epoch: 198 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4447018504142761\n",
            "Training loss:  \t 0.48773694336414336\n",
            "---------------\n",
            "Processing epoch: 199 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.43992476165294647\n",
            "Training loss:  \t 0.48286471962928773\n",
            "---------------\n",
            "Processing epoch: 200 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44279634952545166\n",
            "Training loss:  \t 0.4758289009332657\n",
            "---------------\n",
            "Processing epoch: 201 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4386373534798622\n",
            "Training loss:  \t 0.47493823021650317\n",
            "---------------\n",
            "Processing epoch: 202 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4377758726477623\n",
            "Training loss:  \t 0.46613051295280455\n",
            "---------------\n",
            "Processing epoch: 203 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4435323178768158\n",
            "Training loss:  \t 0.45233278125524523\n",
            "---------------\n",
            "Processing epoch: 204 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4497532621026039\n",
            "Training loss:  \t 0.4421924605965614\n",
            "---------------\n",
            "Processing epoch: 205 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.44457922130823135\n",
            "Training loss:  \t 0.4380219653248787\n",
            "---------------\n",
            "Processing epoch: 206 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4458831399679184\n",
            "Training loss:  \t 0.4353340774774551\n",
            "---------------\n",
            "Processing epoch: 207 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4302715063095093\n",
            "Training loss:  \t 0.43267765939235686\n",
            "---------------\n",
            "Processing epoch: 208 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4258849024772644\n",
            "Training loss:  \t 0.42851313203573227\n",
            "---------------\n",
            "Processing epoch: 209 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4208265393972397\n",
            "Training loss:  \t 0.42803474217653276\n",
            "---------------\n",
            "Processing epoch: 210 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4221206605434418\n",
            "Training loss:  \t 0.4262898027896881\n",
            "---------------\n",
            "Processing epoch: 211 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41621183604002\n",
            "Training loss:  \t 0.4257993683218956\n",
            "---------------\n",
            "Processing epoch: 212 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41955018788576126\n",
            "Training loss:  \t 0.4215389549732208\n",
            "---------------\n",
            "Processing epoch: 213 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4249266982078552\n",
            "Training loss:  \t 0.42238293439149854\n",
            "---------------\n",
            "Processing epoch: 214 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4154455214738846\n",
            "Training loss:  \t 0.4288206726312637\n",
            "---------------\n",
            "Processing epoch: 215 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4076172262430191\n",
            "Training loss:  \t 0.42215846553444863\n",
            "---------------\n",
            "Processing epoch: 216 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4345521628856659\n",
            "Training loss:  \t 0.4281717360019684\n",
            "---------------\n",
            "Processing epoch: 217 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41721753776073456\n",
            "Training loss:  \t 0.43201381862163546\n",
            "---------------\n",
            "Processing epoch: 218 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.400637648999691\n",
            "Training loss:  \t 0.41900658011436465\n",
            "---------------\n",
            "Processing epoch: 219 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4203553572297096\n",
            "Training loss:  \t 0.4225523069500923\n",
            "---------------\n",
            "Processing epoch: 220 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39728425443172455\n",
            "Training loss:  \t 0.42456950545310973\n",
            "---------------\n",
            "Processing epoch: 221 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40306375175714493\n",
            "Training loss:  \t 0.413768470287323\n",
            "---------------\n",
            "Processing epoch: 222 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39126601070165634\n",
            "Training loss:  \t 0.4152802646160126\n",
            "---------------\n",
            "Processing epoch: 223 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.411064051091671\n",
            "Training loss:  \t 0.4165725067257881\n",
            "---------------\n",
            "Processing epoch: 224 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4321705028414726\n",
            "Training loss:  \t 0.42989111244678496\n",
            "---------------\n",
            "Processing epoch: 225 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.43301304802298546\n",
            "Training loss:  \t 0.48283468186855316\n",
            "---------------\n",
            "Processing epoch: 226 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42555684596300125\n",
            "Training loss:  \t 0.48106536865234373\n",
            "---------------\n",
            "Processing epoch: 227 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4246677905321121\n",
            "Training loss:  \t 0.47501430958509444\n",
            "---------------\n",
            "Processing epoch: 228 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4242537282407284\n",
            "Training loss:  \t 0.4594421356916428\n",
            "---------------\n",
            "Processing epoch: 229 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42953646183013916\n",
            "Training loss:  \t 0.441778239607811\n",
            "---------------\n",
            "Processing epoch: 230 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39954832196235657\n",
            "Training loss:  \t 0.4262209787964821\n",
            "---------------\n",
            "Processing epoch: 231 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3992091864347458\n",
            "Training loss:  \t 0.4199884682893753\n",
            "---------------\n",
            "Processing epoch: 232 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39060085639357567\n",
            "Training loss:  \t 0.41982587799429893\n",
            "---------------\n",
            "Processing epoch: 233 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40423567593097687\n",
            "Training loss:  \t 0.42192851901054385\n",
            "---------------\n",
            "Processing epoch: 234 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3877793103456497\n",
            "Training loss:  \t 0.4090592905879021\n",
            "---------------\n",
            "Processing epoch: 235 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3886386901140213\n",
            "Training loss:  \t 0.4123464174568653\n",
            "---------------\n",
            "Processing epoch: 236 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.49632478505373\n",
            "Training loss:  \t 0.4027775526046753\n",
            "---------------\n",
            "Processing epoch: 237 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42322350293397903\n",
            "Training loss:  \t 0.45992272198200224\n",
            "---------------\n",
            "Processing epoch: 238 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42770323157310486\n",
            "Training loss:  \t 0.4574892923235893\n",
            "---------------\n",
            "Processing epoch: 239 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42783626168966293\n",
            "Training loss:  \t 0.43916092067956924\n",
            "---------------\n",
            "Processing epoch: 240 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40132298320531845\n",
            "Training loss:  \t 0.41593815982341764\n",
            "---------------\n",
            "Processing epoch: 241 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3968396559357643\n",
            "Training loss:  \t 0.41251215934753416\n",
            "---------------\n",
            "Processing epoch: 242 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3819567561149597\n",
            "Training loss:  \t 0.4146516159176826\n",
            "---------------\n",
            "Processing epoch: 243 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4099922925233841\n",
            "Training loss:  \t 0.4075200006365776\n",
            "---------------\n",
            "Processing epoch: 244 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39124783873558044\n",
            "Training loss:  \t 0.41298931688070295\n",
            "---------------\n",
            "Processing epoch: 245 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41845184564590454\n",
            "Training loss:  \t 0.4156523197889328\n",
            "---------------\n",
            "Processing epoch: 246 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41975611448287964\n",
            "Training loss:  \t 0.42451395839452744\n",
            "---------------\n",
            "Processing epoch: 247 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.385182224214077\n",
            "Training loss:  \t 0.4105780512094498\n",
            "---------------\n",
            "Processing epoch: 248 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38030488789081573\n",
            "Training loss:  \t 0.40345804691314696\n",
            "---------------\n",
            "Processing epoch: 249 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6459594815969467\n",
            "Training loss:  \t 0.7226147040724754\n",
            "---------------\n",
            "Processing epoch: 250 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4235207214951515\n",
            "Training loss:  \t 0.5250493541359902\n",
            "---------------\n",
            "Processing epoch: 251 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4271790012717247\n",
            "Training loss:  \t 0.4606220334768295\n",
            "---------------\n",
            "Processing epoch: 252 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4170820415019989\n",
            "Training loss:  \t 0.4326677292585373\n",
            "---------------\n",
            "Processing epoch: 253 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37860895693302155\n",
            "Training loss:  \t 0.4135647751390934\n",
            "---------------\n",
            "Processing epoch: 254 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3796231225132942\n",
            "Training loss:  \t 0.40423336923122405\n",
            "---------------\n",
            "Processing epoch: 255 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41692499071359634\n",
            "Training loss:  \t 0.4103497311472893\n",
            "---------------\n",
            "Processing epoch: 256 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41506826132535934\n",
            "Training loss:  \t 0.42598040625452993\n",
            "---------------\n",
            "Processing epoch: 257 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3762623369693756\n",
            "Training loss:  \t 0.40328519940376284\n",
            "---------------\n",
            "Processing epoch: 258 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4008536711335182\n",
            "Training loss:  \t 0.40170212984085085\n",
            "---------------\n",
            "Processing epoch: 259 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3833872824907303\n",
            "Training loss:  \t 0.40391385480761527\n",
            "---------------\n",
            "Processing epoch: 260 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37269843369722366\n",
            "Training loss:  \t 0.4045435056090355\n",
            "---------------\n",
            "Processing epoch: 261 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39946693181991577\n",
            "Training loss:  \t 0.3998754918575287\n",
            "---------------\n",
            "Processing epoch: 262 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3915760740637779\n",
            "Training loss:  \t 0.40922117680311204\n",
            "---------------\n",
            "Processing epoch: 263 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41179002821445465\n",
            "Training loss:  \t 0.41060563996434213\n",
            "---------------\n",
            "Processing epoch: 264 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3736787810921669\n",
            "Training loss:  \t 0.41392752155661583\n",
            "---------------\n",
            "Processing epoch: 265 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39137446880340576\n",
            "Training loss:  \t 0.40006001442670824\n",
            "---------------\n",
            "Processing epoch: 266 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41706641763448715\n",
            "Training loss:  \t 0.46249165311455726\n",
            "---------------\n",
            "Processing epoch: 267 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4163989946246147\n",
            "Training loss:  \t 0.4273385003209114\n",
            "---------------\n",
            "Processing epoch: 268 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37391162663698196\n",
            "Training loss:  \t 0.4002817325294018\n",
            "---------------\n",
            "Processing epoch: 269 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4152531325817108\n",
            "Training loss:  \t 0.41395649760961534\n",
            "---------------\n",
            "Processing epoch: 270 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41184699907898903\n",
            "Training loss:  \t 0.4266580671072006\n",
            "---------------\n",
            "Processing epoch: 271 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37089376151561737\n",
            "Training loss:  \t 0.40521612763404846\n",
            "---------------\n",
            "Processing epoch: 272 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3780139908194542\n",
            "Training loss:  \t 0.39831584319472313\n",
            "---------------\n",
            "Processing epoch: 273 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4084196090698242\n",
            "Training loss:  \t 0.4057440981268883\n",
            "---------------\n",
            "Processing epoch: 274 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39857739955186844\n",
            "Training loss:  \t 0.4114620715379715\n",
            "---------------\n",
            "Processing epoch: 275 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4120223671197891\n",
            "Training loss:  \t 0.4094846695661545\n",
            "---------------\n",
            "Processing epoch: 276 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4251142889261246\n",
            "Training loss:  \t 0.4788426622748375\n",
            "---------------\n",
            "Processing epoch: 277 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4213378429412842\n",
            "Training loss:  \t 0.4919342666864395\n",
            "---------------\n",
            "Processing epoch: 278 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4158816859126091\n",
            "Training loss:  \t 0.48516643792390823\n",
            "---------------\n",
            "Processing epoch: 279 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.414151594042778\n",
            "Training loss:  \t 0.48523454964160917\n",
            "---------------\n",
            "Processing epoch: 280 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4094732105731964\n",
            "Training loss:  \t 0.4786393165588379\n",
            "---------------\n",
            "Processing epoch: 281 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41053352504968643\n",
            "Training loss:  \t 0.4785759039223194\n",
            "---------------\n",
            "Processing epoch: 282 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4087313115596771\n",
            "Training loss:  \t 0.4741696208715439\n",
            "---------------\n",
            "Processing epoch: 283 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4061367064714432\n",
            "Training loss:  \t 0.4700986959040165\n",
            "---------------\n",
            "Processing epoch: 284 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4012957029044628\n",
            "Training loss:  \t 0.4649328991770744\n",
            "---------------\n",
            "Processing epoch: 285 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39873380959033966\n",
            "Training loss:  \t 0.46436578333377837\n",
            "---------------\n",
            "Processing epoch: 286 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40067778527736664\n",
            "Training loss:  \t 0.46523545905947683\n",
            "---------------\n",
            "Processing epoch: 287 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40051858872175217\n",
            "Training loss:  \t 0.46246001273393633\n",
            "---------------\n",
            "Processing epoch: 288 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.396941140294075\n",
            "Training loss:  \t 0.45797709226608274\n",
            "---------------\n",
            "Processing epoch: 289 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3970591649413109\n",
            "Training loss:  \t 0.45889457911252973\n",
            "---------------\n",
            "Processing epoch: 290 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3978038690984249\n",
            "Training loss:  \t 0.45355637520551684\n",
            "---------------\n",
            "Processing epoch: 291 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3991287909448147\n",
            "Training loss:  \t 0.4535643935203552\n",
            "---------------\n",
            "Processing epoch: 292 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39439545571804047\n",
            "Training loss:  \t 0.4482435569167137\n",
            "---------------\n",
            "Processing epoch: 293 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39415451884269714\n",
            "Training loss:  \t 0.44611887335777284\n",
            "---------------\n",
            "Processing epoch: 294 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40481841564178467\n",
            "Training loss:  \t 0.442651130259037\n",
            "---------------\n",
            "Processing epoch: 295 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4040270149707794\n",
            "Training loss:  \t 0.4347247317433357\n",
            "---------------\n",
            "Processing epoch: 296 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40551868826150894\n",
            "Training loss:  \t 0.43638638481497766\n",
            "---------------\n",
            "Processing epoch: 297 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40989573299884796\n",
            "Training loss:  \t 0.43666110932826996\n",
            "---------------\n",
            "Processing epoch: 298 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4069168269634247\n",
            "Training loss:  \t 0.43066260889172553\n",
            "---------------\n",
            "Processing epoch: 299 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4081008918583393\n",
            "Training loss:  \t 0.4302104003727436\n",
            "---------------\n",
            "Processing epoch: 300 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41130324825644493\n",
            "Training loss:  \t 0.42555796429514886\n",
            "---------------\n",
            "Processing epoch: 301 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4105508178472519\n",
            "Training loss:  \t 0.4307443112134933\n",
            "---------------\n",
            "Processing epoch: 302 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4241795018315315\n",
            "Training loss:  \t 0.42796874791383743\n",
            "---------------\n",
            "Processing epoch: 303 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4137285649776459\n",
            "Training loss:  \t 0.42421076744794844\n",
            "---------------\n",
            "Processing epoch: 304 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4153794124722481\n",
            "Training loss:  \t 0.4257769472897053\n",
            "---------------\n",
            "Processing epoch: 305 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4191190376877785\n",
            "Training loss:  \t 0.41994651705026625\n",
            "---------------\n",
            "Processing epoch: 306 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4096984565258026\n",
            "Training loss:  \t 0.42017962485551835\n",
            "---------------\n",
            "Processing epoch: 307 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42125120759010315\n",
            "Training loss:  \t 0.41874665170907976\n",
            "---------------\n",
            "Processing epoch: 308 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41780422627925873\n",
            "Training loss:  \t 0.41442997455596925\n",
            "---------------\n",
            "Processing epoch: 309 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4125414304435253\n",
            "Training loss:  \t 0.41580241098999976\n",
            "---------------\n",
            "Processing epoch: 310 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41512929648160934\n",
            "Training loss:  \t 0.40745128989219664\n",
            "---------------\n",
            "Processing epoch: 311 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4165787547826767\n",
            "Training loss:  \t 0.4089574798941612\n",
            "---------------\n",
            "Processing epoch: 312 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41700558364391327\n",
            "Training loss:  \t 0.409038157761097\n",
            "---------------\n",
            "Processing epoch: 313 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41413843631744385\n",
            "Training loss:  \t 0.4059705913066864\n",
            "---------------\n",
            "Processing epoch: 314 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4076264649629593\n",
            "Training loss:  \t 0.40080877766013145\n",
            "---------------\n",
            "Processing epoch: 315 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39981885254383087\n",
            "Training loss:  \t 0.40086858719587326\n",
            "---------------\n",
            "Processing epoch: 316 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39197567850351334\n",
            "Training loss:  \t 0.39485775381326677\n",
            "---------------\n",
            "Processing epoch: 317 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3941289409995079\n",
            "Training loss:  \t 0.3959930345416069\n",
            "---------------\n",
            "Processing epoch: 318 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3770785257220268\n",
            "Training loss:  \t 0.3947972260415554\n",
            "---------------\n",
            "Processing epoch: 319 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36004258692264557\n",
            "Training loss:  \t 0.39105122685432436\n",
            "---------------\n",
            "Processing epoch: 320 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3869381472468376\n",
            "Training loss:  \t 0.39716149792075156\n",
            "---------------\n",
            "Processing epoch: 321 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3627122491598129\n",
            "Training loss:  \t 0.38902601301670076\n",
            "---------------\n",
            "Processing epoch: 322 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3687063828110695\n",
            "Training loss:  \t 0.3858364835381508\n",
            "---------------\n",
            "Processing epoch: 323 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3522426709532738\n",
            "Training loss:  \t 0.3869147315621376\n",
            "---------------\n",
            "Processing epoch: 324 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3465372510254383\n",
            "Training loss:  \t 0.3840117543935776\n",
            "---------------\n",
            "Processing epoch: 325 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3452942855656147\n",
            "Training loss:  \t 0.38189852237701416\n",
            "---------------\n",
            "Processing epoch: 326 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.384575255215168\n",
            "Training loss:  \t 0.4400727339088917\n",
            "---------------\n",
            "Processing epoch: 327 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35370009392499924\n",
            "Training loss:  \t 0.3935615301132202\n",
            "---------------\n",
            "Processing epoch: 328 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35681723803281784\n",
            "Training loss:  \t 0.3788405604660511\n",
            "---------------\n",
            "Processing epoch: 329 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34467869997024536\n",
            "Training loss:  \t 0.3922031857073307\n",
            "---------------\n",
            "Processing epoch: 330 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38997526466846466\n",
            "Training loss:  \t 0.3711925134062767\n",
            "---------------\n",
            "Processing epoch: 331 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3501211293041706\n",
            "Training loss:  \t 0.39673600867390635\n",
            "---------------\n",
            "Processing epoch: 332 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33947204053401947\n",
            "Training loss:  \t 0.38219972774386407\n",
            "---------------\n",
            "Processing epoch: 333 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39811351522803307\n",
            "Training loss:  \t 0.39966555014252664\n",
            "---------------\n",
            "Processing epoch: 334 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40015559643507004\n",
            "Training loss:  \t 0.4165869243443012\n",
            "---------------\n",
            "Processing epoch: 335 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3502371609210968\n",
            "Training loss:  \t 0.39430842250585557\n",
            "---------------\n",
            "Processing epoch: 336 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.377148050814867\n",
            "Training loss:  \t 0.3832548506557941\n",
            "---------------\n",
            "Processing epoch: 337 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.392416637390852\n",
            "Training loss:  \t 0.4038310319185257\n",
            "---------------\n",
            "Processing epoch: 338 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3545372486114502\n",
            "Training loss:  \t 0.3920230932533741\n",
            "---------------\n",
            "Processing epoch: 339 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3410767428576946\n",
            "Training loss:  \t 0.3773301750421524\n",
            "---------------\n",
            "Processing epoch: 340 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3431638665497303\n",
            "Training loss:  \t 0.38456444069743156\n",
            "---------------\n",
            "Processing epoch: 341 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3602787256240845\n",
            "Training loss:  \t 0.38527540788054465\n",
            "---------------\n",
            "Processing epoch: 342 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39219997823238373\n",
            "Training loss:  \t 0.39233245700597763\n",
            "---------------\n",
            "Processing epoch: 343 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39690838754177094\n",
            "Training loss:  \t 0.4173585154116154\n",
            "---------------\n",
            "Processing epoch: 344 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3949470520019531\n",
            "Training loss:  \t 0.4068120189011097\n",
            "---------------\n",
            "Processing epoch: 345 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37312301248311996\n",
            "Training loss:  \t 0.3899950958788395\n",
            "---------------\n",
            "Processing epoch: 346 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35638438910245895\n",
            "Training loss:  \t 0.38019811138510706\n",
            "---------------\n",
            "Processing epoch: 347 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3431924730539322\n",
            "Training loss:  \t 0.37534174099564555\n",
            "---------------\n",
            "Processing epoch: 348 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34478700906038284\n",
            "Training loss:  \t 0.3761654615402222\n",
            "---------------\n",
            "Processing epoch: 349 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3370564542710781\n",
            "Training loss:  \t 0.3716045930981636\n",
            "---------------\n",
            "Processing epoch: 350 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3463535010814667\n",
            "Training loss:  \t 0.37363874688744547\n",
            "---------------\n",
            "Processing epoch: 351 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39701899886131287\n",
            "Training loss:  \t 0.3849021501839161\n",
            "---------------\n",
            "Processing epoch: 352 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4092317745089531\n",
            "Training loss:  \t 0.4861034095287323\n",
            "---------------\n",
            "Processing epoch: 353 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.41098711639642715\n",
            "Training loss:  \t 0.48421799167990687\n",
            "---------------\n",
            "Processing epoch: 354 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4040362164378166\n",
            "Training loss:  \t 0.4850602179765701\n",
            "---------------\n",
            "Processing epoch: 355 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39729709178209305\n",
            "Training loss:  \t 0.48007036224007604\n",
            "---------------\n",
            "Processing epoch: 356 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40006372332572937\n",
            "Training loss:  \t 0.47119545489549636\n",
            "---------------\n",
            "Processing epoch: 357 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39205191656947136\n",
            "Training loss:  \t 0.47384564131498336\n",
            "---------------\n",
            "Processing epoch: 358 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38945654034614563\n",
            "Training loss:  \t 0.46236568614840506\n",
            "---------------\n",
            "Processing epoch: 359 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3887539505958557\n",
            "Training loss:  \t 0.46265771687030793\n",
            "---------------\n",
            "Processing epoch: 360 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3854488655924797\n",
            "Training loss:  \t 0.4608444221317768\n",
            "---------------\n",
            "Processing epoch: 361 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38427016884088516\n",
            "Training loss:  \t 0.4575776219367981\n",
            "---------------\n",
            "Processing epoch: 362 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38364453613758087\n",
            "Training loss:  \t 0.4547587506473064\n",
            "---------------\n",
            "Processing epoch: 363 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38334357365965843\n",
            "Training loss:  \t 0.45122142508625984\n",
            "---------------\n",
            "Processing epoch: 364 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38011738657951355\n",
            "Training loss:  \t 0.4491895578801632\n",
            "---------------\n",
            "Processing epoch: 365 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3776414692401886\n",
            "Training loss:  \t 0.44868301302194596\n",
            "---------------\n",
            "Processing epoch: 366 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3788803070783615\n",
            "Training loss:  \t 0.4436008885502815\n",
            "---------------\n",
            "Processing epoch: 367 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3801932856440544\n",
            "Training loss:  \t 0.44226300716400146\n",
            "---------------\n",
            "Processing epoch: 368 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37967609614133835\n",
            "Training loss:  \t 0.4420347660779953\n",
            "---------------\n",
            "Processing epoch: 369 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38194694370031357\n",
            "Training loss:  \t 0.4366642639040947\n",
            "---------------\n",
            "Processing epoch: 370 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3795875906944275\n",
            "Training loss:  \t 0.4274943143129349\n",
            "---------------\n",
            "Processing epoch: 371 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35664233565330505\n",
            "Training loss:  \t 0.4191636309027672\n",
            "---------------\n",
            "Processing epoch: 372 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37870634347200394\n",
            "Training loss:  \t 0.4164330452680588\n",
            "---------------\n",
            "Processing epoch: 373 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3809126615524292\n",
            "Training loss:  \t 0.4152652591466904\n",
            "---------------\n",
            "Processing epoch: 374 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3647538386285305\n",
            "Training loss:  \t 0.4103162676095963\n",
            "---------------\n",
            "Processing epoch: 375 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37922726199030876\n",
            "Training loss:  \t 0.4017844170331955\n",
            "---------------\n",
            "Processing epoch: 376 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38392167165875435\n",
            "Training loss:  \t 0.4170738771557808\n",
            "---------------\n",
            "Processing epoch: 377 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38226593285799026\n",
            "Training loss:  \t 0.4107655085623264\n",
            "---------------\n",
            "Processing epoch: 378 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3857228457927704\n",
            "Training loss:  \t 0.40798882097005845\n",
            "---------------\n",
            "Processing epoch: 379 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39318396896123886\n",
            "Training loss:  \t 0.4083363078534603\n",
            "---------------\n",
            "Processing epoch: 380 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3874831907451153\n",
            "Training loss:  \t 0.404438991099596\n",
            "---------------\n",
            "Processing epoch: 381 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39229951053857803\n",
            "Training loss:  \t 0.3988266013562679\n",
            "---------------\n",
            "Processing epoch: 382 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39415863528847694\n",
            "Training loss:  \t 0.4001269944012165\n",
            "---------------\n",
            "Processing epoch: 383 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3941789045929909\n",
            "Training loss:  \t 0.39532696828246117\n",
            "---------------\n",
            "Processing epoch: 384 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3936847746372223\n",
            "Training loss:  \t 0.39391468465328217\n",
            "---------------\n",
            "Processing epoch: 385 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3944019228219986\n",
            "Training loss:  \t 0.3891724243760109\n",
            "---------------\n",
            "Processing epoch: 386 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3930443003773689\n",
            "Training loss:  \t 0.3905560113489628\n",
            "---------------\n",
            "Processing epoch: 387 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38966841995716095\n",
            "Training loss:  \t 0.38847815468907354\n",
            "---------------\n",
            "Processing epoch: 388 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38243237882852554\n",
            "Training loss:  \t 0.38714409917593\n",
            "---------------\n",
            "Processing epoch: 389 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3790571093559265\n",
            "Training loss:  \t 0.38353282660245896\n",
            "---------------\n",
            "Processing epoch: 390 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37416691333055496\n",
            "Training loss:  \t 0.380216845870018\n",
            "---------------\n",
            "Processing epoch: 391 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3720911182463169\n",
            "Training loss:  \t 0.37845762372016906\n",
            "---------------\n",
            "Processing epoch: 392 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3649923726916313\n",
            "Training loss:  \t 0.3751504436135292\n",
            "---------------\n",
            "Processing epoch: 393 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36186426877975464\n",
            "Training loss:  \t 0.37486991211771964\n",
            "---------------\n",
            "Processing epoch: 394 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34551333636045456\n",
            "Training loss:  \t 0.3726841054856777\n",
            "---------------\n",
            "Processing epoch: 395 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3577486351132393\n",
            "Training loss:  \t 0.37450565695762633\n",
            "---------------\n",
            "Processing epoch: 396 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33981359004974365\n",
            "Training loss:  \t 0.3699899405241013\n",
            "---------------\n",
            "Processing epoch: 397 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33121391385793686\n",
            "Training loss:  \t 0.36683196648955346\n",
            "---------------\n",
            "Processing epoch: 398 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3326318562030792\n",
            "Training loss:  \t 0.3670323446393013\n",
            "---------------\n",
            "Processing epoch: 399 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3259260803461075\n",
            "Training loss:  \t 0.36474344283342364\n",
            "---------------\n",
            "Processing epoch: 400 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3937797471880913\n",
            "Training loss:  \t 0.40500953495502473\n",
            "---------------\n",
            "Processing epoch: 401 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39558858424425125\n",
            "Training loss:  \t 0.4608721867203712\n",
            "---------------\n",
            "Processing epoch: 402 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3916128873825073\n",
            "Training loss:  \t 0.46300358027219773\n",
            "---------------\n",
            "Processing epoch: 403 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38453633338212967\n",
            "Training loss:  \t 0.44996670857071874\n",
            "---------------\n",
            "Processing epoch: 404 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3829037770628929\n",
            "Training loss:  \t 0.4478092692792416\n",
            "---------------\n",
            "Processing epoch: 405 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3766673095524311\n",
            "Training loss:  \t 0.4423363208770752\n",
            "---------------\n",
            "Processing epoch: 406 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38551075011491776\n",
            "Training loss:  \t 0.4410008296370506\n",
            "---------------\n",
            "Processing epoch: 407 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37413445115089417\n",
            "Training loss:  \t 0.4288365587592125\n",
            "---------------\n",
            "Processing epoch: 408 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3743800111114979\n",
            "Training loss:  \t 0.41379987373948096\n",
            "---------------\n",
            "Processing epoch: 409 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3814953938126564\n",
            "Training loss:  \t 0.4044618047773838\n",
            "---------------\n",
            "Processing epoch: 410 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3801677078008652\n",
            "Training loss:  \t 0.3981046795845032\n",
            "---------------\n",
            "Processing epoch: 411 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3827826455235481\n",
            "Training loss:  \t 0.3943040564656258\n",
            "---------------\n",
            "Processing epoch: 412 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3811381384730339\n",
            "Training loss:  \t 0.3866978645324707\n",
            "---------------\n",
            "Processing epoch: 413 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36167337745428085\n",
            "Training loss:  \t 0.3825040563941002\n",
            "---------------\n",
            "Processing epoch: 414 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3821041062474251\n",
            "Training loss:  \t 0.3764250747859478\n",
            "---------------\n",
            "Processing epoch: 415 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3821447417140007\n",
            "Training loss:  \t 0.40287351310253144\n",
            "---------------\n",
            "Processing epoch: 416 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38524558395147324\n",
            "Training loss:  \t 0.39971218034625056\n",
            "---------------\n",
            "Processing epoch: 417 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38549231737852097\n",
            "Training loss:  \t 0.39036317095160483\n",
            "---------------\n",
            "Processing epoch: 418 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38643383234739304\n",
            "Training loss:  \t 0.39191332310438154\n",
            "---------------\n",
            "Processing epoch: 419 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38490843772888184\n",
            "Training loss:  \t 0.3827104762196541\n",
            "---------------\n",
            "Processing epoch: 420 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38295120373368263\n",
            "Training loss:  \t 0.38061038553714754\n",
            "---------------\n",
            "Processing epoch: 421 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3770984634757042\n",
            "Training loss:  \t 0.3760028138756752\n",
            "---------------\n",
            "Processing epoch: 422 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3632667064666748\n",
            "Training loss:  \t 0.37156994119286535\n",
            "---------------\n",
            "Processing epoch: 423 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3677612915635109\n",
            "Training loss:  \t 0.37228274866938593\n",
            "---------------\n",
            "Processing epoch: 424 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34173722192645073\n",
            "Training loss:  \t 0.36793900206685065\n",
            "---------------\n",
            "Processing epoch: 425 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3292582482099533\n",
            "Training loss:  \t 0.36080541387200354\n",
            "---------------\n",
            "Processing epoch: 426 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3370024748146534\n",
            "Training loss:  \t 0.3592881076037884\n",
            "---------------\n",
            "Processing epoch: 427 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32184983044862747\n",
            "Training loss:  \t 0.35714255794882777\n",
            "---------------\n",
            "Processing epoch: 428 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3241407573223114\n",
            "Training loss:  \t 0.3561468951404095\n",
            "---------------\n",
            "Processing epoch: 429 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3143167197704315\n",
            "Training loss:  \t 0.35763652846217153\n",
            "---------------\n",
            "Processing epoch: 430 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34499092400074005\n",
            "Training loss:  \t 0.3535099782049656\n",
            "---------------\n",
            "Processing epoch: 431 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3285754695534706\n",
            "Training loss:  \t 0.35867808759212494\n",
            "---------------\n",
            "Processing epoch: 432 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32593587785959244\n",
            "Training loss:  \t 0.36640944257378577\n",
            "---------------\n",
            "Processing epoch: 433 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31216471269726753\n",
            "Training loss:  \t 0.35575158670544627\n",
            "---------------\n",
            "Processing epoch: 434 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3457421362400055\n",
            "Training loss:  \t 0.34968032091856005\n",
            "---------------\n",
            "Processing epoch: 435 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38717102259397507\n",
            "Training loss:  \t 0.4207032836973667\n",
            "---------------\n",
            "Processing epoch: 436 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38482265174388885\n",
            "Training loss:  \t 0.45528214424848557\n",
            "---------------\n",
            "Processing epoch: 437 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37915412336587906\n",
            "Training loss:  \t 0.44299490451812745\n",
            "---------------\n",
            "Processing epoch: 438 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37521497160196304\n",
            "Training loss:  \t 0.4313180178403854\n",
            "---------------\n",
            "Processing epoch: 439 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.376464806497097\n",
            "Training loss:  \t 0.41237069964408873\n",
            "---------------\n",
            "Processing epoch: 440 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3785487115383148\n",
            "Training loss:  \t 0.3940432444214821\n",
            "---------------\n",
            "Processing epoch: 441 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.376471608877182\n",
            "Training loss:  \t 0.38472438529133796\n",
            "---------------\n",
            "Processing epoch: 442 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37839823216199875\n",
            "Training loss:  \t 0.3769208014011383\n",
            "---------------\n",
            "Processing epoch: 443 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36718031018972397\n",
            "Training loss:  \t 0.3697549395263195\n",
            "---------------\n",
            "Processing epoch: 444 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34099462255835533\n",
            "Training loss:  \t 0.3610086694359779\n",
            "---------------\n",
            "Processing epoch: 445 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3062002807855606\n",
            "Training loss:  \t 0.35615002512931826\n",
            "---------------\n",
            "Processing epoch: 446 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34226472675800323\n",
            "Training loss:  \t 0.35198862478137016\n",
            "---------------\n",
            "Processing epoch: 447 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2993016093969345\n",
            "Training loss:  \t 0.35498962700366976\n",
            "---------------\n",
            "Processing epoch: 448 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30505452305078506\n",
            "Training loss:  \t 0.3555804677307606\n",
            "---------------\n",
            "Processing epoch: 449 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3012338653206825\n",
            "Training loss:  \t 0.3532636269927025\n",
            "---------------\n",
            "Processing epoch: 450 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.358730960637331\n",
            "Training loss:  \t 0.37661654576659204\n",
            "---------------\n",
            "Processing epoch: 451 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3098819926381111\n",
            "Training loss:  \t 0.3610563546419144\n",
            "---------------\n",
            "Processing epoch: 452 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3300315737724304\n",
            "Training loss:  \t 0.3541675262153149\n",
            "---------------\n",
            "Processing epoch: 453 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30966174602508545\n",
            "Training loss:  \t 0.34834773689508436\n",
            "---------------\n",
            "Processing epoch: 454 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32891109585762024\n",
            "Training loss:  \t 0.3546628139913082\n",
            "---------------\n",
            "Processing epoch: 455 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32141271978616714\n",
            "Training loss:  \t 0.3527200810611248\n",
            "---------------\n",
            "Processing epoch: 456 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3225393146276474\n",
            "Training loss:  \t 0.34888754710555075\n",
            "---------------\n",
            "Processing epoch: 457 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30839236453175545\n",
            "Training loss:  \t 0.350263848900795\n",
            "---------------\n",
            "Processing epoch: 458 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3044828735291958\n",
            "Training loss:  \t 0.35112693160772324\n",
            "---------------\n",
            "Processing epoch: 459 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30795738846063614\n",
            "Training loss:  \t 0.3496767535805702\n",
            "---------------\n",
            "Processing epoch: 460 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32887542620301247\n",
            "Training loss:  \t 0.350481266528368\n",
            "---------------\n",
            "Processing epoch: 461 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33994514867663383\n",
            "Training loss:  \t 0.34918311089277265\n",
            "---------------\n",
            "Processing epoch: 462 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32665059342980385\n",
            "Training loss:  \t 0.359151716530323\n",
            "---------------\n",
            "Processing epoch: 463 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3066551983356476\n",
            "Training loss:  \t 0.3452510215342045\n",
            "---------------\n",
            "Processing epoch: 464 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30613039806485176\n",
            "Training loss:  \t 0.3488870069384575\n",
            "---------------\n",
            "Processing epoch: 465 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3059598281979561\n",
            "Training loss:  \t 0.34850604459643364\n",
            "---------------\n",
            "Processing epoch: 466 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33327943831682205\n",
            "Training loss:  \t 0.35043042823672294\n",
            "---------------\n",
            "Processing epoch: 467 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3362686559557915\n",
            "Training loss:  \t 0.36329704597592355\n",
            "---------------\n",
            "Processing epoch: 468 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3134165182709694\n",
            "Training loss:  \t 0.3483009748160839\n",
            "---------------\n",
            "Processing epoch: 469 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30768296867609024\n",
            "Training loss:  \t 0.3436593681573868\n",
            "---------------\n",
            "Processing epoch: 470 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37449292838573456\n",
            "Training loss:  \t 0.355498468875885\n",
            "---------------\n",
            "Processing epoch: 471 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3772885575890541\n",
            "Training loss:  \t 0.39586764201521873\n",
            "---------------\n",
            "Processing epoch: 472 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35512423515319824\n",
            "Training loss:  \t 0.3647980555891991\n",
            "---------------\n",
            "Processing epoch: 473 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31850218027830124\n",
            "Training loss:  \t 0.35298448130488397\n",
            "---------------\n",
            "Processing epoch: 474 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3175771199166775\n",
            "Training loss:  \t 0.35184931084513665\n",
            "---------------\n",
            "Processing epoch: 475 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3216448798775673\n",
            "Training loss:  \t 0.3467232033610344\n",
            "---------------\n",
            "Processing epoch: 476 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3120085373520851\n",
            "Training loss:  \t 0.35262945145368574\n",
            "---------------\n",
            "Processing epoch: 477 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30222100019454956\n",
            "Training loss:  \t 0.34280889928340913\n",
            "---------------\n",
            "Processing epoch: 478 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30212799832224846\n",
            "Training loss:  \t 0.34378604739904406\n",
            "---------------\n",
            "Processing epoch: 479 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29565344378352165\n",
            "Training loss:  \t 0.3466332532465458\n",
            "---------------\n",
            "Processing epoch: 480 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30616074427962303\n",
            "Training loss:  \t 0.33795915096998214\n",
            "---------------\n",
            "Processing epoch: 481 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3058612421154976\n",
            "Training loss:  \t 0.3472508914768696\n",
            "---------------\n",
            "Processing epoch: 482 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30026477575302124\n",
            "Training loss:  \t 0.34174964725971224\n",
            "---------------\n",
            "Processing epoch: 483 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30982157588005066\n",
            "Training loss:  \t 0.3435926653444767\n",
            "---------------\n",
            "Processing epoch: 484 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33924413099884987\n",
            "Training loss:  \t 0.34641178473830225\n",
            "---------------\n",
            "Processing epoch: 485 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30842556431889534\n",
            "Training loss:  \t 0.3393179666250944\n",
            "---------------\n",
            "Processing epoch: 486 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3270047530531883\n",
            "Training loss:  \t 0.35244565159082414\n",
            "---------------\n",
            "Processing epoch: 487 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39716391265392303\n",
            "Training loss:  \t 0.3668352194130421\n",
            "---------------\n",
            "Processing epoch: 488 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40345433354377747\n",
            "Training loss:  \t 0.4885602183640003\n",
            "---------------\n",
            "Processing epoch: 489 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39872854948043823\n",
            "Training loss:  \t 0.4910034567117691\n",
            "---------------\n",
            "Processing epoch: 490 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3943226784467697\n",
            "Training loss:  \t 0.4844908520579338\n",
            "---------------\n",
            "Processing epoch: 491 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3837389163672924\n",
            "Training loss:  \t 0.482027105987072\n",
            "---------------\n",
            "Processing epoch: 492 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3791353330016136\n",
            "Training loss:  \t 0.4735662296414375\n",
            "---------------\n",
            "Processing epoch: 493 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3768855184316635\n",
            "Training loss:  \t 0.46293905973434446\n",
            "---------------\n",
            "Processing epoch: 494 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36638033390045166\n",
            "Training loss:  \t 0.45277852565050125\n",
            "---------------\n",
            "Processing epoch: 495 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3661789298057556\n",
            "Training loss:  \t 0.43525330200791357\n",
            "---------------\n",
            "Processing epoch: 496 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3685028925538063\n",
            "Training loss:  \t 0.41250497177243234\n",
            "---------------\n",
            "Processing epoch: 497 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34379320219159126\n",
            "Training loss:  \t 0.39042217582464217\n",
            "---------------\n",
            "Processing epoch: 498 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36998871713876724\n",
            "Training loss:  \t 0.377402751147747\n",
            "---------------\n",
            "Processing epoch: 499 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36492201313376427\n",
            "Training loss:  \t 0.37336183041334153\n",
            "---------------\n",
            "Processing epoch: 500 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3450077548623085\n",
            "Training loss:  \t 0.3598969765007496\n",
            "---------------\n",
            "Processing epoch: 501 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3192376270890236\n",
            "Training loss:  \t 0.3480346456170082\n",
            "---------------\n",
            "Processing epoch: 502 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31947147101163864\n",
            "Training loss:  \t 0.34856632351875305\n",
            "---------------\n",
            "Processing epoch: 503 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30400870740413666\n",
            "Training loss:  \t 0.3458629220724106\n",
            "---------------\n",
            "Processing epoch: 504 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29917868971824646\n",
            "Training loss:  \t 0.34199151396751404\n",
            "---------------\n",
            "Processing epoch: 505 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2989475019276142\n",
            "Training loss:  \t 0.34234479889273645\n",
            "---------------\n",
            "Processing epoch: 506 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3432723358273506\n",
            "Training loss:  \t 0.3546592518687248\n",
            "---------------\n",
            "Processing epoch: 507 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3043463006615639\n",
            "Training loss:  \t 0.3423508800566196\n",
            "---------------\n",
            "Processing epoch: 508 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37283143028616905\n",
            "Training loss:  \t 0.4239633042365313\n",
            "---------------\n",
            "Processing epoch: 509 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3757086470723152\n",
            "Training loss:  \t 0.399448062479496\n",
            "---------------\n",
            "Processing epoch: 510 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37392886728048325\n",
            "Training loss:  \t 0.3878055468201637\n",
            "---------------\n",
            "Processing epoch: 511 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3501303642988205\n",
            "Training loss:  \t 0.36151172071695326\n",
            "---------------\n",
            "Processing epoch: 512 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3253951221704483\n",
            "Training loss:  \t 0.3467402905225754\n",
            "---------------\n",
            "Processing epoch: 513 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3316369168460369\n",
            "Training loss:  \t 0.34607156068086625\n",
            "---------------\n",
            "Processing epoch: 514 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3039659634232521\n",
            "Training loss:  \t 0.34518880769610405\n",
            "---------------\n",
            "Processing epoch: 515 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30209793895483017\n",
            "Training loss:  \t 0.3396602936089039\n",
            "---------------\n",
            "Processing epoch: 516 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34342626482248306\n",
            "Training loss:  \t 0.34568210393190385\n",
            "---------------\n",
            "Processing epoch: 517 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3034828379750252\n",
            "Training loss:  \t 0.3458708494901657\n",
            "---------------\n",
            "Processing epoch: 518 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30148573964834213\n",
            "Training loss:  \t 0.3402396284043789\n",
            "---------------\n",
            "Processing epoch: 519 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29534173756837845\n",
            "Training loss:  \t 0.33896815925836565\n",
            "---------------\n",
            "Processing epoch: 520 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2951314002275467\n",
            "Training loss:  \t 0.34065771475434303\n",
            "---------------\n",
            "Processing epoch: 521 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3509366363286972\n",
            "Training loss:  \t 0.33607508391141894\n",
            "---------------\n",
            "Processing epoch: 522 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31619274243712425\n",
            "Training loss:  \t 0.3482212983071804\n",
            "---------------\n",
            "Processing epoch: 523 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29701419174671173\n",
            "Training loss:  \t 0.3354209288954735\n",
            "---------------\n",
            "Processing epoch: 524 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36259257420897484\n",
            "Training loss:  \t 0.35080147683620455\n",
            "---------------\n",
            "Processing epoch: 525 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35509946942329407\n",
            "Training loss:  \t 0.36295793280005456\n",
            "---------------\n",
            "Processing epoch: 526 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31403979286551476\n",
            "Training loss:  \t 0.34516046196222305\n",
            "---------------\n",
            "Processing epoch: 527 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2984035164117813\n",
            "Training loss:  \t 0.3338619127869606\n",
            "---------------\n",
            "Processing epoch: 528 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2924463301897049\n",
            "Training loss:  \t 0.3372787080705166\n",
            "---------------\n",
            "Processing epoch: 529 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3623431846499443\n",
            "Training loss:  \t 0.33966453522443774\n",
            "---------------\n",
            "Processing epoch: 530 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.310946486890316\n",
            "Training loss:  \t 0.3492198042571545\n",
            "---------------\n",
            "Processing epoch: 531 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3096334710717201\n",
            "Training loss:  \t 0.3400390766561031\n",
            "---------------\n",
            "Processing epoch: 532 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2955630235373974\n",
            "Training loss:  \t 0.3324262276291847\n",
            "---------------\n",
            "Processing epoch: 533 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2922072857618332\n",
            "Training loss:  \t 0.3348174042999744\n",
            "---------------\n",
            "Processing epoch: 534 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28812410682439804\n",
            "Training loss:  \t 0.3306245803833008\n",
            "---------------\n",
            "Processing epoch: 535 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29208891093730927\n",
            "Training loss:  \t 0.33919600024819374\n",
            "---------------\n",
            "Processing epoch: 536 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31976019963622093\n",
            "Training loss:  \t 0.3300271064043045\n",
            "---------------\n",
            "Processing epoch: 537 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29220736771821976\n",
            "Training loss:  \t 0.33687846958637235\n",
            "---------------\n",
            "Processing epoch: 538 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32264532893896103\n",
            "Training loss:  \t 0.33818645402789116\n",
            "---------------\n",
            "Processing epoch: 539 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2942030131816864\n",
            "Training loss:  \t 0.3431562751531601\n",
            "---------------\n",
            "Processing epoch: 540 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28894251957535744\n",
            "Training loss:  \t 0.3377155359834433\n",
            "---------------\n",
            "Processing epoch: 541 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3001822642982006\n",
            "Training loss:  \t 0.33736407160758974\n",
            "---------------\n",
            "Processing epoch: 542 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30294862762093544\n",
            "Training loss:  \t 0.3290967926383018\n",
            "---------------\n",
            "Processing epoch: 543 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28691910952329636\n",
            "Training loss:  \t 0.3314343072474003\n",
            "---------------\n",
            "Processing epoch: 544 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30682171136140823\n",
            "Training loss:  \t 0.3312336206436157\n",
            "---------------\n",
            "Processing epoch: 545 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3857502415776253\n",
            "Training loss:  \t 0.43396376073360443\n",
            "---------------\n",
            "Processing epoch: 546 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3793352171778679\n",
            "Training loss:  \t 0.46036857962608335\n",
            "---------------\n",
            "Processing epoch: 547 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37329693883657455\n",
            "Training loss:  \t 0.44779300019145013\n",
            "---------------\n",
            "Processing epoch: 548 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3731175512075424\n",
            "Training loss:  \t 0.43757321164011953\n",
            "---------------\n",
            "Processing epoch: 549 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3676849640905857\n",
            "Training loss:  \t 0.42349768728017806\n",
            "---------------\n",
            "Processing epoch: 550 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3632125072181225\n",
            "Training loss:  \t 0.4092760026454926\n",
            "---------------\n",
            "Processing epoch: 551 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3616904765367508\n",
            "Training loss:  \t 0.3979228772222996\n",
            "---------------\n",
            "Processing epoch: 552 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.364297728985548\n",
            "Training loss:  \t 0.38864368498325347\n",
            "---------------\n",
            "Processing epoch: 553 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36966872960329056\n",
            "Training loss:  \t 0.3864293947815895\n",
            "---------------\n",
            "Processing epoch: 554 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36686600744724274\n",
            "Training loss:  \t 0.37142650336027144\n",
            "---------------\n",
            "Processing epoch: 555 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36735786497592926\n",
            "Training loss:  \t 0.364008616656065\n",
            "---------------\n",
            "Processing epoch: 556 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3501106835901737\n",
            "Training loss:  \t 0.357458670437336\n",
            "---------------\n",
            "Processing epoch: 557 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32980022206902504\n",
            "Training loss:  \t 0.342559851706028\n",
            "---------------\n",
            "Processing epoch: 558 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31399428099393845\n",
            "Training loss:  \t 0.3381115190684795\n",
            "---------------\n",
            "Processing epoch: 559 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29664038121700287\n",
            "Training loss:  \t 0.33572999462485315\n",
            "---------------\n",
            "Processing epoch: 560 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29304058849811554\n",
            "Training loss:  \t 0.3301990069448948\n",
            "---------------\n",
            "Processing epoch: 561 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2900906316936016\n",
            "Training loss:  \t 0.33311778828501704\n",
            "---------------\n",
            "Processing epoch: 562 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29003771394491196\n",
            "Training loss:  \t 0.32843405157327654\n",
            "---------------\n",
            "Processing epoch: 563 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3005591295659542\n",
            "Training loss:  \t 0.33241305500268936\n",
            "---------------\n",
            "Processing epoch: 564 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30299391224980354\n",
            "Training loss:  \t 0.3319752007722855\n",
            "---------------\n",
            "Processing epoch: 565 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3569456562399864\n",
            "Training loss:  \t 0.3339532591402531\n",
            "---------------\n",
            "Processing epoch: 566 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33511245250701904\n",
            "Training loss:  \t 0.3532072748988867\n",
            "---------------\n",
            "Processing epoch: 567 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2988126464188099\n",
            "Training loss:  \t 0.3296897806227207\n",
            "---------------\n",
            "Processing epoch: 568 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3448371961712837\n",
            "Training loss:  \t 0.3455661103129387\n",
            "---------------\n",
            "Processing epoch: 569 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30709609761834145\n",
            "Training loss:  \t 0.3429618954658508\n",
            "---------------\n",
            "Processing epoch: 570 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29270146787166595\n",
            "Training loss:  \t 0.3296826120465994\n",
            "---------------\n",
            "Processing epoch: 571 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29091525077819824\n",
            "Training loss:  \t 0.33065285384654997\n",
            "---------------\n",
            "Processing epoch: 572 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30779028683900833\n",
            "Training loss:  \t 0.3281777210533619\n",
            "---------------\n",
            "Processing epoch: 573 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2894705832004547\n",
            "Training loss:  \t 0.32476132214069364\n",
            "---------------\n",
            "Processing epoch: 574 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37464790791273117\n",
            "Training loss:  \t 0.39827594682574274\n",
            "---------------\n",
            "Processing epoch: 575 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3676464706659317\n",
            "Training loss:  \t 0.39898496568202974\n",
            "---------------\n",
            "Processing epoch: 576 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.367858424782753\n",
            "Training loss:  \t 0.3763451762497425\n",
            "---------------\n",
            "Processing epoch: 577 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3586231395602226\n",
            "Training loss:  \t 0.3606262840330601\n",
            "---------------\n",
            "Processing epoch: 578 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34082354605197906\n",
            "Training loss:  \t 0.3465730719268322\n",
            "---------------\n",
            "Processing epoch: 579 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32927314192056656\n",
            "Training loss:  \t 0.3399097051471472\n",
            "---------------\n",
            "Processing epoch: 580 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31732987985014915\n",
            "Training loss:  \t 0.33453262224793434\n",
            "---------------\n",
            "Processing epoch: 581 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32657915353775024\n",
            "Training loss:  \t 0.3337076261639595\n",
            "---------------\n",
            "Processing epoch: 582 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3690754063427448\n",
            "Training loss:  \t 0.3841694906353951\n",
            "---------------\n",
            "Processing epoch: 583 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3557589165866375\n",
            "Training loss:  \t 0.35707867294549944\n",
            "---------------\n",
            "Processing epoch: 584 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3042335510253906\n",
            "Training loss:  \t 0.33753123357892034\n",
            "---------------\n",
            "Processing epoch: 585 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3748121149837971\n",
            "Training loss:  \t 0.34428652822971345\n",
            "---------------\n",
            "Processing epoch: 586 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3834199756383896\n",
            "Training loss:  \t 0.4663375772535801\n",
            "---------------\n",
            "Processing epoch: 587 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3809797316789627\n",
            "Training loss:  \t 0.47123450189828875\n",
            "---------------\n",
            "Processing epoch: 588 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3764880634844303\n",
            "Training loss:  \t 0.46832022443413734\n",
            "---------------\n",
            "Processing epoch: 589 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37162112444639206\n",
            "Training loss:  \t 0.4635939374566078\n",
            "---------------\n",
            "Processing epoch: 590 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36464427411556244\n",
            "Training loss:  \t 0.447314926981926\n",
            "---------------\n",
            "Processing epoch: 591 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3667493686079979\n",
            "Training loss:  \t 0.4431696206331253\n",
            "---------------\n",
            "Processing epoch: 592 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3582764156162739\n",
            "Training loss:  \t 0.43604337275028227\n",
            "---------------\n",
            "Processing epoch: 593 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3638864606618881\n",
            "Training loss:  \t 0.42554607689380647\n",
            "---------------\n",
            "Processing epoch: 594 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36190757155418396\n",
            "Training loss:  \t 0.42270047664642335\n",
            "---------------\n",
            "Processing epoch: 595 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3594844862818718\n",
            "Training loss:  \t 0.4226606585085392\n",
            "---------------\n",
            "Processing epoch: 596 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3580305688083172\n",
            "Training loss:  \t 0.4151004649698734\n",
            "---------------\n",
            "Processing epoch: 597 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3590127229690552\n",
            "Training loss:  \t 0.4118746183812618\n",
            "---------------\n",
            "Processing epoch: 598 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35949070006608963\n",
            "Training loss:  \t 0.404840499907732\n",
            "---------------\n",
            "Processing epoch: 599 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36186616867780685\n",
            "Training loss:  \t 0.3963211067020893\n",
            "---------------\n",
            "Processing epoch: 600 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36007434874773026\n",
            "Training loss:  \t 0.39008326157927514\n",
            "---------------\n",
            "Processing epoch: 601 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3626306354999542\n",
            "Training loss:  \t 0.3838595226407051\n",
            "---------------\n",
            "Processing epoch: 602 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3645755276083946\n",
            "Training loss:  \t 0.379732558876276\n",
            "---------------\n",
            "Processing epoch: 603 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3631974756717682\n",
            "Training loss:  \t 0.37451371029019354\n",
            "---------------\n",
            "Processing epoch: 604 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36866338923573494\n",
            "Training loss:  \t 0.37390398420393467\n",
            "---------------\n",
            "Processing epoch: 605 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3691071346402168\n",
            "Training loss:  \t 0.36792799904942514\n",
            "---------------\n",
            "Processing epoch: 606 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37027427554130554\n",
            "Training loss:  \t 0.3612193040549755\n",
            "---------------\n",
            "Processing epoch: 607 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3689018413424492\n",
            "Training loss:  \t 0.3580626010894775\n",
            "---------------\n",
            "Processing epoch: 608 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35661379620432854\n",
            "Training loss:  \t 0.34854022338986396\n",
            "---------------\n",
            "Processing epoch: 609 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3510873317718506\n",
            "Training loss:  \t 0.3424899511039257\n",
            "---------------\n",
            "Processing epoch: 610 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3421402871608734\n",
            "Training loss:  \t 0.3412930712103844\n",
            "---------------\n",
            "Processing epoch: 611 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3162512555718422\n",
            "Training loss:  \t 0.34556104987859726\n",
            "---------------\n",
            "Processing epoch: 612 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3103998079895973\n",
            "Training loss:  \t 0.3374436967074871\n",
            "---------------\n",
            "Processing epoch: 613 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31130601093173027\n",
            "Training loss:  \t 0.3337366312742233\n",
            "---------------\n",
            "Processing epoch: 614 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3072355166077614\n",
            "Training loss:  \t 0.3337902963161469\n",
            "---------------\n",
            "Processing epoch: 615 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2879044860601425\n",
            "Training loss:  \t 0.3384796030819416\n",
            "---------------\n",
            "Processing epoch: 616 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.288373664021492\n",
            "Training loss:  \t 0.33664690926671026\n",
            "---------------\n",
            "Processing epoch: 617 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27938375249505043\n",
            "Training loss:  \t 0.32510527074337003\n",
            "---------------\n",
            "Processing epoch: 618 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3218802399933338\n",
            "Training loss:  \t 0.3542567744851112\n",
            "---------------\n",
            "Processing epoch: 619 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28421832621097565\n",
            "Training loss:  \t 0.3390593394637108\n",
            "---------------\n",
            "Processing epoch: 620 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3850537911057472\n",
            "Training loss:  \t 0.4624258100986481\n",
            "---------------\n",
            "Processing epoch: 621 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3912213370203972\n",
            "Training loss:  \t 0.4770096853375435\n",
            "---------------\n",
            "Processing epoch: 622 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3825989402830601\n",
            "Training loss:  \t 0.47628330513834954\n",
            "---------------\n",
            "Processing epoch: 623 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38598664849996567\n",
            "Training loss:  \t 0.47268444374203683\n",
            "---------------\n",
            "Processing epoch: 624 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3795202672481537\n",
            "Training loss:  \t 0.46775835305452346\n",
            "---------------\n",
            "Processing epoch: 625 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3701650984585285\n",
            "Training loss:  \t 0.4593363687396049\n",
            "---------------\n",
            "Processing epoch: 626 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36599482223391533\n",
            "Training loss:  \t 0.45731373205780984\n",
            "---------------\n",
            "Processing epoch: 627 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3659995272755623\n",
            "Training loss:  \t 0.451362457126379\n",
            "---------------\n",
            "Processing epoch: 628 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36576149612665176\n",
            "Training loss:  \t 0.44533874839544296\n",
            "---------------\n",
            "Processing epoch: 629 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3341134116053581\n",
            "Training loss:  \t 0.43407907113432886\n",
            "---------------\n",
            "Processing epoch: 630 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3581690862774849\n",
            "Training loss:  \t 0.4192888744175434\n",
            "---------------\n",
            "Processing epoch: 631 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33798738569021225\n",
            "Training loss:  \t 0.41964913010597227\n",
            "---------------\n",
            "Processing epoch: 632 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3279982954263687\n",
            "Training loss:  \t 0.40017819702625274\n",
            "---------------\n",
            "Processing epoch: 633 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32574600726366043\n",
            "Training loss:  \t 0.39709057807922366\n",
            "---------------\n",
            "Processing epoch: 634 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3233490660786629\n",
            "Training loss:  \t 0.39126924276351926\n",
            "---------------\n",
            "Processing epoch: 635 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35765179619193077\n",
            "Training loss:  \t 0.40965705290436744\n",
            "---------------\n",
            "Processing epoch: 636 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3351026102900505\n",
            "Training loss:  \t 0.42293880581855775\n",
            "---------------\n",
            "Processing epoch: 637 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3330717198550701\n",
            "Training loss:  \t 0.4002923034131527\n",
            "---------------\n",
            "Processing epoch: 638 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3602490723133087\n",
            "Training loss:  \t 0.4033517062664032\n",
            "---------------\n",
            "Processing epoch: 639 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33350492268800735\n",
            "Training loss:  \t 0.39040028527379034\n",
            "---------------\n",
            "Processing epoch: 640 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3321225345134735\n",
            "Training loss:  \t 0.3828805208206177\n",
            "---------------\n",
            "Processing epoch: 641 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42647987604141235\n",
            "Training loss:  \t 0.39415025860071184\n",
            "---------------\n",
            "Processing epoch: 642 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3516799993813038\n",
            "Training loss:  \t 0.47067058756947516\n",
            "---------------\n",
            "Processing epoch: 643 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3412648215889931\n",
            "Training loss:  \t 0.39851138964295385\n",
            "---------------\n",
            "Processing epoch: 644 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3408418074250221\n",
            "Training loss:  \t 0.3760808162391186\n",
            "---------------\n",
            "Processing epoch: 645 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3228541314601898\n",
            "Training loss:  \t 0.3789181552827358\n",
            "---------------\n",
            "Processing epoch: 646 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3410263806581497\n",
            "Training loss:  \t 0.3737007148563862\n",
            "---------------\n",
            "Processing epoch: 647 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3297940418124199\n",
            "Training loss:  \t 0.38369265720248225\n",
            "---------------\n",
            "Processing epoch: 648 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3631863482296467\n",
            "Training loss:  \t 0.3745510719716549\n",
            "---------------\n",
            "Processing epoch: 649 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.362753551453352\n",
            "Training loss:  \t 0.4323169760406017\n",
            "---------------\n",
            "Processing epoch: 650 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36113106831908226\n",
            "Training loss:  \t 0.44766138345003126\n",
            "---------------\n",
            "Processing epoch: 651 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36195075511932373\n",
            "Training loss:  \t 0.4355992183089256\n",
            "---------------\n",
            "Processing epoch: 652 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35846811160445213\n",
            "Training loss:  \t 0.44186322540044787\n",
            "---------------\n",
            "Processing epoch: 653 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3578476719558239\n",
            "Training loss:  \t 0.4316800981760025\n",
            "---------------\n",
            "Processing epoch: 654 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3608817905187607\n",
            "Training loss:  \t 0.4277376808226109\n",
            "---------------\n",
            "Processing epoch: 655 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3582161143422127\n",
            "Training loss:  \t 0.42000472769141195\n",
            "---------------\n",
            "Processing epoch: 656 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3594610244035721\n",
            "Training loss:  \t 0.4160150669515133\n",
            "---------------\n",
            "Processing epoch: 657 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36257947236299515\n",
            "Training loss:  \t 0.4058214515447617\n",
            "---------------\n",
            "Processing epoch: 658 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36268599331378937\n",
            "Training loss:  \t 0.3911094941198826\n",
            "---------------\n",
            "Processing epoch: 659 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3529529571533203\n",
            "Training loss:  \t 0.3834505818784237\n",
            "---------------\n",
            "Processing epoch: 660 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3459163159132004\n",
            "Training loss:  \t 0.37732200399041177\n",
            "---------------\n",
            "Processing epoch: 661 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34894615039229393\n",
            "Training loss:  \t 0.3744125418365002\n",
            "---------------\n",
            "Processing epoch: 662 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34000810980796814\n",
            "Training loss:  \t 0.37253166288137435\n",
            "---------------\n",
            "Processing epoch: 663 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3339136615395546\n",
            "Training loss:  \t 0.37134397923946383\n",
            "---------------\n",
            "Processing epoch: 664 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33720511198043823\n",
            "Training loss:  \t 0.3736504763364792\n",
            "---------------\n",
            "Processing epoch: 665 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33268848806619644\n",
            "Training loss:  \t 0.3699919007718563\n",
            "---------------\n",
            "Processing epoch: 666 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33084144443273544\n",
            "Training loss:  \t 0.36925530806183815\n",
            "---------------\n",
            "Processing epoch: 667 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3282987214624882\n",
            "Training loss:  \t 0.36860397309064863\n",
            "---------------\n",
            "Processing epoch: 668 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3271346688270569\n",
            "Training loss:  \t 0.3647391736507416\n",
            "---------------\n",
            "Processing epoch: 669 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32259446009993553\n",
            "Training loss:  \t 0.36690120324492453\n",
            "---------------\n",
            "Processing epoch: 670 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32161959260702133\n",
            "Training loss:  \t 0.3671503014862537\n",
            "---------------\n",
            "Processing epoch: 671 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3285250924527645\n",
            "Training loss:  \t 0.3658850990235806\n",
            "---------------\n",
            "Processing epoch: 672 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32442620024085045\n",
            "Training loss:  \t 0.3606339067220688\n",
            "---------------\n",
            "Processing epoch: 673 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32847482711076736\n",
            "Training loss:  \t 0.3626531183719635\n",
            "---------------\n",
            "Processing epoch: 674 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3287544474005699\n",
            "Training loss:  \t 0.3651551194489002\n",
            "---------------\n",
            "Processing epoch: 675 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3204062879085541\n",
            "Training loss:  \t 0.37096143886446953\n",
            "---------------\n",
            "Processing epoch: 676 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33794448524713516\n",
            "Training loss:  \t 0.3725788496434689\n",
            "---------------\n",
            "Processing epoch: 677 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32386959344148636\n",
            "Training loss:  \t 0.3649172231554985\n",
            "---------------\n",
            "Processing epoch: 678 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3362154886126518\n",
            "Training loss:  \t 0.38024069368839264\n",
            "---------------\n",
            "Processing epoch: 679 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31914278119802475\n",
            "Training loss:  \t 0.36203139275312424\n",
            "---------------\n",
            "Processing epoch: 680 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3267449364066124\n",
            "Training loss:  \t 0.36604267060756684\n",
            "---------------\n",
            "Processing epoch: 681 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3177313506603241\n",
            "Training loss:  \t 0.35943041145801546\n",
            "---------------\n",
            "Processing epoch: 682 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33688419312238693\n",
            "Training loss:  \t 0.3612133800983429\n",
            "---------------\n",
            "Processing epoch: 683 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3307894133031368\n",
            "Training loss:  \t 0.36566418036818504\n",
            "---------------\n",
            "Processing epoch: 684 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3212110176682472\n",
            "Training loss:  \t 0.35803888365626335\n",
            "---------------\n",
            "Processing epoch: 685 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3217793442308903\n",
            "Training loss:  \t 0.36085565462708474\n",
            "---------------\n",
            "Processing epoch: 686 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32544199377298355\n",
            "Training loss:  \t 0.36012844145298006\n",
            "---------------\n",
            "Processing epoch: 687 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3474046103656292\n",
            "Training loss:  \t 0.366590940207243\n",
            "---------------\n",
            "Processing epoch: 688 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32139313220977783\n",
            "Training loss:  \t 0.3644142098724842\n",
            "---------------\n",
            "Processing epoch: 689 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3213556557893753\n",
            "Training loss:  \t 0.3560365319252014\n",
            "---------------\n",
            "Processing epoch: 690 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3635263815522194\n",
            "Training loss:  \t 0.37350096702575686\n",
            "---------------\n",
            "Processing epoch: 691 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3548516817390919\n",
            "Training loss:  \t 0.37995910719037057\n",
            "---------------\n",
            "Processing epoch: 692 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32472963631153107\n",
            "Training loss:  \t 0.36100486293435097\n",
            "---------------\n",
            "Processing epoch: 693 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33233774825930595\n",
            "Training loss:  \t 0.3600462958216667\n",
            "---------------\n",
            "Processing epoch: 694 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32126374915242195\n",
            "Training loss:  \t 0.35310768857598307\n",
            "---------------\n",
            "Processing epoch: 695 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3310755267739296\n",
            "Training loss:  \t 0.3538686953485012\n",
            "---------------\n",
            "Processing epoch: 696 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32703743875026703\n",
            "Training loss:  \t 0.3569075271487236\n",
            "---------------\n",
            "Processing epoch: 697 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3298274241387844\n",
            "Training loss:  \t 0.3545419327914715\n",
            "---------------\n",
            "Processing epoch: 698 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3171253278851509\n",
            "Training loss:  \t 0.35627607852220533\n",
            "---------------\n",
            "Processing epoch: 699 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32395555824041367\n",
            "Training loss:  \t 0.3572280675172806\n",
            "---------------\n",
            "Processing epoch: 700 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3213724344968796\n",
            "Training loss:  \t 0.35837655514478683\n",
            "---------------\n",
            "Processing epoch: 701 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3299047537147999\n",
            "Training loss:  \t 0.3498159572482109\n",
            "---------------\n",
            "Processing epoch: 702 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32278142124414444\n",
            "Training loss:  \t 0.3597019337117672\n",
            "---------------\n",
            "Processing epoch: 703 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31483566761016846\n",
            "Training loss:  \t 0.35641766488552096\n",
            "---------------\n",
            "Processing epoch: 704 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.336429838091135\n",
            "Training loss:  \t 0.3556732192635536\n",
            "---------------\n",
            "Processing epoch: 705 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3136761859059334\n",
            "Training loss:  \t 0.35448889434337616\n",
            "---------------\n",
            "Processing epoch: 706 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34384752064943314\n",
            "Training loss:  \t 0.3586204007267952\n",
            "---------------\n",
            "Processing epoch: 707 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3146418333053589\n",
            "Training loss:  \t 0.35634867623448374\n",
            "---------------\n",
            "Processing epoch: 708 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3108135089278221\n",
            "Training loss:  \t 0.34634257927536966\n",
            "---------------\n",
            "Processing epoch: 709 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32651831954717636\n",
            "Training loss:  \t 0.35047556832432747\n",
            "---------------\n",
            "Processing epoch: 710 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32596953213214874\n",
            "Training loss:  \t 0.3470603048801422\n",
            "---------------\n",
            "Processing epoch: 711 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31306537613272667\n",
            "Training loss:  \t 0.34727351889014246\n",
            "---------------\n",
            "Processing epoch: 712 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31013763323426247\n",
            "Training loss:  \t 0.34839572608470915\n",
            "---------------\n",
            "Processing epoch: 713 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3090614378452301\n",
            "Training loss:  \t 0.34818638265132906\n",
            "---------------\n",
            "Processing epoch: 714 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3095215782523155\n",
            "Training loss:  \t 0.34706406444311144\n",
            "---------------\n",
            "Processing epoch: 715 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3069731295108795\n",
            "Training loss:  \t 0.3437202893197536\n",
            "---------------\n",
            "Processing epoch: 716 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31643783673644066\n",
            "Training loss:  \t 0.34543523117899894\n",
            "---------------\n",
            "Processing epoch: 717 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30628037080168724\n",
            "Training loss:  \t 0.34630201309919356\n",
            "---------------\n",
            "Processing epoch: 718 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3374994769692421\n",
            "Training loss:  \t 0.3551312744617462\n",
            "---------------\n",
            "Processing epoch: 719 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3148790933191776\n",
            "Training loss:  \t 0.3510632127523422\n",
            "---------------\n",
            "Processing epoch: 720 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3060069978237152\n",
            "Training loss:  \t 0.3548725053668022\n",
            "---------------\n",
            "Processing epoch: 721 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31139928847551346\n",
            "Training loss:  \t 0.34497940056025983\n",
            "---------------\n",
            "Processing epoch: 722 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30811241269111633\n",
            "Training loss:  \t 0.34173991307616236\n",
            "---------------\n",
            "Processing epoch: 723 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34358959272503853\n",
            "Training loss:  \t 0.355323913320899\n",
            "---------------\n",
            "Processing epoch: 724 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32036156579852104\n",
            "Training loss:  \t 0.3429761089384556\n",
            "---------------\n",
            "Processing epoch: 725 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31876956671476364\n",
            "Training loss:  \t 0.34301353245973587\n",
            "---------------\n",
            "Processing epoch: 726 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33093467354774475\n",
            "Training loss:  \t 0.3457717977464199\n",
            "---------------\n",
            "Processing epoch: 727 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3352930545806885\n",
            "Training loss:  \t 0.36017781794071196\n",
            "---------------\n",
            "Processing epoch: 728 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3541497699916363\n",
            "Training loss:  \t 0.34743051081895826\n",
            "---------------\n",
            "Processing epoch: 729 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3432270660996437\n",
            "Training loss:  \t 0.3752364456653595\n",
            "---------------\n",
            "Processing epoch: 730 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30729928612709045\n",
            "Training loss:  \t 0.34231909215450285\n",
            "---------------\n",
            "Processing epoch: 731 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3159860745072365\n",
            "Training loss:  \t 0.34065352380275726\n",
            "---------------\n",
            "Processing epoch: 732 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.309387169778347\n",
            "Training loss:  \t 0.3388017348945141\n",
            "---------------\n",
            "Processing epoch: 733 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30928702652454376\n",
            "Training loss:  \t 0.32910419479012487\n",
            "---------------\n",
            "Processing epoch: 734 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3031967170536518\n",
            "Training loss:  \t 0.3377774924039841\n",
            "---------------\n",
            "Processing epoch: 735 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3656504973769188\n",
            "Training loss:  \t 0.3605281263589859\n",
            "---------------\n",
            "Processing epoch: 736 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3721187636256218\n",
            "Training loss:  \t 0.4051742278039455\n",
            "---------------\n",
            "Processing epoch: 737 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36333049088716507\n",
            "Training loss:  \t 0.39399069249629975\n",
            "---------------\n",
            "Processing epoch: 738 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36024781316518784\n",
            "Training loss:  \t 0.3748607762157917\n",
            "---------------\n",
            "Processing epoch: 739 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.361626572906971\n",
            "Training loss:  \t 0.3616566568613052\n",
            "---------------\n",
            "Processing epoch: 740 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3341057300567627\n",
            "Training loss:  \t 0.34957881197333335\n",
            "---------------\n",
            "Processing epoch: 741 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3230321407318115\n",
            "Training loss:  \t 0.3397017553448677\n",
            "---------------\n",
            "Processing epoch: 742 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30952244624495506\n",
            "Training loss:  \t 0.3356744259595871\n",
            "---------------\n",
            "Processing epoch: 743 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31058168038725853\n",
            "Training loss:  \t 0.3348535656929016\n",
            "---------------\n",
            "Processing epoch: 744 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3700670152902603\n",
            "Training loss:  \t 0.3271479353308678\n",
            "---------------\n",
            "Processing epoch: 745 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.318313904106617\n",
            "Training loss:  \t 0.349386190623045\n",
            "---------------\n",
            "Processing epoch: 746 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3216995596885681\n",
            "Training loss:  \t 0.33682973831892016\n",
            "---------------\n",
            "Processing epoch: 747 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30363788455724716\n",
            "Training loss:  \t 0.34418436959385873\n",
            "---------------\n",
            "Processing epoch: 748 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3205210901796818\n",
            "Training loss:  \t 0.33605994656682014\n",
            "---------------\n",
            "Processing epoch: 749 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4088435247540474\n",
            "Training loss:  \t 0.36332443058490754\n",
            "---------------\n",
            "Processing epoch: 750 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3686980940401554\n",
            "Training loss:  \t 0.3800330959260464\n",
            "---------------\n",
            "Processing epoch: 751 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3670104965567589\n",
            "Training loss:  \t 0.3686412893235683\n",
            "---------------\n",
            "Processing epoch: 752 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3497290313243866\n",
            "Training loss:  \t 0.35075902491807937\n",
            "---------------\n",
            "Processing epoch: 753 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3149583041667938\n",
            "Training loss:  \t 0.3442350968718529\n",
            "---------------\n",
            "Processing epoch: 754 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3595855385065079\n",
            "Training loss:  \t 0.34842098578810693\n",
            "---------------\n",
            "Processing epoch: 755 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.310549333691597\n",
            "Training loss:  \t 0.3450112484395504\n",
            "---------------\n",
            "Processing epoch: 756 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3058142922818661\n",
            "Training loss:  \t 0.3332445420324802\n",
            "---------------\n",
            "Processing epoch: 757 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31081831455230713\n",
            "Training loss:  \t 0.33035209253430364\n",
            "---------------\n",
            "Processing epoch: 758 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3233809247612953\n",
            "Training loss:  \t 0.329290808737278\n",
            "---------------\n",
            "Processing epoch: 759 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3165411241352558\n",
            "Training loss:  \t 0.3366477534174919\n",
            "---------------\n",
            "Processing epoch: 760 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30487295985221863\n",
            "Training loss:  \t 0.3253025621175766\n",
            "---------------\n",
            "Processing epoch: 761 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36136797070503235\n",
            "Training loss:  \t 0.335158272087574\n",
            "---------------\n",
            "Processing epoch: 762 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3633251488208771\n",
            "Training loss:  \t 0.36262161284685135\n",
            "---------------\n",
            "Processing epoch: 763 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3438953682780266\n",
            "Training loss:  \t 0.35230291783809664\n",
            "---------------\n",
            "Processing epoch: 764 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30748533830046654\n",
            "Training loss:  \t 0.33757130354642867\n",
            "---------------\n",
            "Processing epoch: 765 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3668948784470558\n",
            "Training loss:  \t 0.35981404408812523\n",
            "---------------\n",
            "Processing epoch: 766 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36900022998452187\n",
            "Training loss:  \t 0.3789692588150501\n",
            "---------------\n",
            "Processing epoch: 767 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3666044771671295\n",
            "Training loss:  \t 0.3678607605397701\n",
            "---------------\n",
            "Processing epoch: 768 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37420927733182907\n",
            "Training loss:  \t 0.3585517264902592\n",
            "---------------\n",
            "Processing epoch: 769 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36129945144057274\n",
            "Training loss:  \t 0.35320858284831047\n",
            "---------------\n",
            "Processing epoch: 770 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34311534464359283\n",
            "Training loss:  \t 0.33771351277828215\n",
            "---------------\n",
            "Processing epoch: 771 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3069949336349964\n",
            "Training loss:  \t 0.3404778204858303\n",
            "---------------\n",
            "Processing epoch: 772 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3059128411114216\n",
            "Training loss:  \t 0.3317953869700432\n",
            "---------------\n",
            "Processing epoch: 773 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3538806885480881\n",
            "Training loss:  \t 0.33752627223730086\n",
            "---------------\n",
            "Processing epoch: 774 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.4092537388205528\n",
            "Training loss:  \t 0.3454954631626606\n",
            "---------------\n",
            "Processing epoch: 775 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37016597390174866\n",
            "Training loss:  \t 0.3547440156340599\n",
            "---------------\n",
            "Processing epoch: 776 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3648672476410866\n",
            "Training loss:  \t 0.35960235483944414\n",
            "---------------\n",
            "Processing epoch: 777 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3329183366149664\n",
            "Training loss:  \t 0.3435110576450825\n",
            "---------------\n",
            "Processing epoch: 778 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3079829066991806\n",
            "Training loss:  \t 0.3359615981578827\n",
            "---------------\n",
            "Processing epoch: 779 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31497855484485626\n",
            "Training loss:  \t 0.323449020087719\n",
            "---------------\n",
            "Processing epoch: 780 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31130265444517136\n",
            "Training loss:  \t 0.32405909821391105\n",
            "---------------\n",
            "Processing epoch: 781 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34891803562641144\n",
            "Training loss:  \t 0.35853768661618235\n",
            "---------------\n",
            "Processing epoch: 782 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.376225546002388\n",
            "Training loss:  \t 0.3269913956522942\n",
            "---------------\n",
            "Processing epoch: 783 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.334436047822237\n",
            "Training loss:  \t 0.3389823317527771\n",
            "---------------\n",
            "Processing epoch: 784 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3017550855875015\n",
            "Training loss:  \t 0.3303593210875988\n",
            "---------------\n",
            "Processing epoch: 785 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30338623002171516\n",
            "Training loss:  \t 0.32483995631337165\n",
            "---------------\n",
            "Processing epoch: 786 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32175825349986553\n",
            "Training loss:  \t 0.34711999669671056\n",
            "---------------\n",
            "Processing epoch: 787 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3116817735135555\n",
            "Training loss:  \t 0.3348537489771843\n",
            "---------------\n",
            "Processing epoch: 788 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3187283091247082\n",
            "Training loss:  \t 0.3313560225069523\n",
            "---------------\n",
            "Processing epoch: 789 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3210821822285652\n",
            "Training loss:  \t 0.33504281640052797\n",
            "---------------\n",
            "Processing epoch: 790 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.40389128774404526\n",
            "Training loss:  \t 0.3389567777514458\n",
            "---------------\n",
            "Processing epoch: 791 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3690638355910778\n",
            "Training loss:  \t 0.3700390674173832\n",
            "---------------\n",
            "Processing epoch: 792 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3714275062084198\n",
            "Training loss:  \t 0.3765911959111691\n",
            "---------------\n",
            "Processing epoch: 793 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36869002133607864\n",
            "Training loss:  \t 0.35989031940698624\n",
            "---------------\n",
            "Processing epoch: 794 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3699929267168045\n",
            "Training loss:  \t 0.3487993061542511\n",
            "---------------\n",
            "Processing epoch: 795 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3328566700220108\n",
            "Training loss:  \t 0.34357390329241755\n",
            "---------------\n",
            "Processing epoch: 796 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3101591356098652\n",
            "Training loss:  \t 0.32766886427998543\n",
            "---------------\n",
            "Processing epoch: 797 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30826936662197113\n",
            "Training loss:  \t 0.32673515006899834\n",
            "---------------\n",
            "Processing epoch: 798 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30881495401263237\n",
            "Training loss:  \t 0.32650439739227294\n",
            "---------------\n",
            "Processing epoch: 799 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3653396964073181\n",
            "Training loss:  \t 0.33512888588011264\n",
            "---------------\n",
            "Processing epoch: 800 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3470074236392975\n",
            "Training loss:  \t 0.34893290251493453\n",
            "---------------\n",
            "Processing epoch: 801 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3844373784959316\n",
            "Training loss:  \t 0.3364356756210327\n",
            "---------------\n",
            "Processing epoch: 802 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3627500832080841\n",
            "Training loss:  \t 0.3516413487493992\n",
            "---------------\n",
            "Processing epoch: 803 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3137909881770611\n",
            "Training loss:  \t 0.3368501175194979\n",
            "---------------\n",
            "Processing epoch: 804 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3079897165298462\n",
            "Training loss:  \t 0.32243676483631134\n",
            "---------------\n",
            "Processing epoch: 805 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3074437864124775\n",
            "Training loss:  \t 0.32189628630876543\n",
            "---------------\n",
            "Processing epoch: 806 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30040475353598595\n",
            "Training loss:  \t 0.3294569760560989\n",
            "---------------\n",
            "Processing epoch: 807 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3639981299638748\n",
            "Training loss:  \t 0.32949502654373647\n",
            "---------------\n",
            "Processing epoch: 808 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3717789612710476\n",
            "Training loss:  \t 0.3695976618677378\n",
            "---------------\n",
            "Processing epoch: 809 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36909423768520355\n",
            "Training loss:  \t 0.35593256130814555\n",
            "---------------\n",
            "Processing epoch: 810 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35143638402223587\n",
            "Training loss:  \t 0.3392470210790634\n",
            "---------------\n",
            "Processing epoch: 811 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30292338505387306\n",
            "Training loss:  \t 0.3398148246109486\n",
            "---------------\n",
            "Processing epoch: 812 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31963320076465607\n",
            "Training loss:  \t 0.3206659406423569\n",
            "---------------\n",
            "Processing epoch: 813 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29696759954094887\n",
            "Training loss:  \t 0.32395132929086684\n",
            "---------------\n",
            "Processing epoch: 814 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3948630765080452\n",
            "Training loss:  \t 0.37652703896164896\n",
            "---------------\n",
            "Processing epoch: 815 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3722461387515068\n",
            "Training loss:  \t 0.3677793890237808\n",
            "---------------\n",
            "Processing epoch: 816 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3657768592238426\n",
            "Training loss:  \t 0.3758858196437359\n",
            "---------------\n",
            "Processing epoch: 817 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3739116359502077\n",
            "Training loss:  \t 0.35622206777334214\n",
            "---------------\n",
            "Processing epoch: 818 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3704550452530384\n",
            "Training loss:  \t 0.3589392013847828\n",
            "---------------\n",
            "Processing epoch: 819 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36700497567653656\n",
            "Training loss:  \t 0.35119751915335656\n",
            "---------------\n",
            "Processing epoch: 820 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3422617167234421\n",
            "Training loss:  \t 0.3404432311654091\n",
            "---------------\n",
            "Processing epoch: 821 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3686145916581154\n",
            "Training loss:  \t 0.3461488001048565\n",
            "---------------\n",
            "Processing epoch: 822 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37560170888900757\n",
            "Training loss:  \t 0.3776463303714991\n",
            "---------------\n",
            "Processing epoch: 823 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36481720954179764\n",
            "Training loss:  \t 0.3594000082463026\n",
            "---------------\n",
            "Processing epoch: 824 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35771729052066803\n",
            "Training loss:  \t 0.33913138285279276\n",
            "---------------\n",
            "Processing epoch: 825 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33410222083330154\n",
            "Training loss:  \t 0.33620689883828164\n",
            "---------------\n",
            "Processing epoch: 826 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31019246205687523\n",
            "Training loss:  \t 0.3203983843326569\n",
            "---------------\n",
            "Processing epoch: 827 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36633963137865067\n",
            "Training loss:  \t 0.3414652578532696\n",
            "---------------\n",
            "Processing epoch: 828 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37212730944156647\n",
            "Training loss:  \t 0.3668739125132561\n",
            "---------------\n",
            "Processing epoch: 829 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36794760823249817\n",
            "Training loss:  \t 0.3529077522456646\n",
            "---------------\n",
            "Processing epoch: 830 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34952429309487343\n",
            "Training loss:  \t 0.3443737432360649\n",
            "---------------\n",
            "Processing epoch: 831 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3053335137665272\n",
            "Training loss:  \t 0.33621223345398904\n",
            "---------------\n",
            "Processing epoch: 832 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34551820158958435\n",
            "Training loss:  \t 0.3238174054771662\n",
            "---------------\n",
            "Processing epoch: 833 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2973054274916649\n",
            "Training loss:  \t 0.3191342860460281\n",
            "---------------\n",
            "Processing epoch: 834 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32701335847377777\n",
            "Training loss:  \t 0.31988791525363924\n",
            "---------------\n",
            "Processing epoch: 835 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30378665030002594\n",
            "Training loss:  \t 0.32136655822396276\n",
            "---------------\n",
            "Processing epoch: 836 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2908801734447479\n",
            "Training loss:  \t 0.3151315461844206\n",
            "---------------\n",
            "Processing epoch: 837 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28510941937565804\n",
            "Training loss:  \t 0.31231958568096163\n",
            "---------------\n",
            "Processing epoch: 838 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2782135456800461\n",
            "Training loss:  \t 0.3227371837943792\n",
            "---------------\n",
            "Processing epoch: 839 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.366623405367136\n",
            "Training loss:  \t 0.4338980831205845\n",
            "---------------\n",
            "Processing epoch: 840 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35079624131321907\n",
            "Training loss:  \t 0.3453550893813372\n",
            "---------------\n",
            "Processing epoch: 841 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2851865738630295\n",
            "Training loss:  \t 0.3154922179877758\n",
            "---------------\n",
            "Processing epoch: 842 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3720376268029213\n",
            "Training loss:  \t 0.37704806998372076\n",
            "---------------\n",
            "Processing epoch: 843 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3684300556778908\n",
            "Training loss:  \t 0.3836601495742798\n",
            "---------------\n",
            "Processing epoch: 844 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3527357801795006\n",
            "Training loss:  \t 0.3545824661850929\n",
            "---------------\n",
            "Processing epoch: 845 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30869071930646896\n",
            "Training loss:  \t 0.3405334196984768\n",
            "---------------\n",
            "Processing epoch: 846 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29945752024650574\n",
            "Training loss:  \t 0.31714518144726755\n",
            "---------------\n",
            "Processing epoch: 847 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3305572606623173\n",
            "Training loss:  \t 0.3189984932541847\n",
            "---------------\n",
            "Processing epoch: 848 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31162384152412415\n",
            "Training loss:  \t 0.31805420368909837\n",
            "---------------\n",
            "Processing epoch: 849 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28300339728593826\n",
            "Training loss:  \t 0.3151749573647976\n",
            "---------------\n",
            "Processing epoch: 850 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33803562074899673\n",
            "Training loss:  \t 0.3138870600610971\n",
            "---------------\n",
            "Processing epoch: 851 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2816879525780678\n",
            "Training loss:  \t 0.310573223978281\n",
            "---------------\n",
            "Processing epoch: 852 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28820578195154667\n",
            "Training loss:  \t 0.32176971398293974\n",
            "---------------\n",
            "Processing epoch: 853 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3703548237681389\n",
            "Training loss:  \t 0.3760379247367382\n",
            "---------------\n",
            "Processing epoch: 854 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3672112040221691\n",
            "Training loss:  \t 0.3773324675858021\n",
            "---------------\n",
            "Processing epoch: 855 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3549369387328625\n",
            "Training loss:  \t 0.3529751092195511\n",
            "---------------\n",
            "Processing epoch: 856 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29221323877573013\n",
            "Training loss:  \t 0.3183942772448063\n",
            "---------------\n",
            "Processing epoch: 857 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29722910374403\n",
            "Training loss:  \t 0.3138205721974373\n",
            "---------------\n",
            "Processing epoch: 858 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28407047316432\n",
            "Training loss:  \t 0.3099166311323643\n",
            "---------------\n",
            "Processing epoch: 859 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27048135176301\n",
            "Training loss:  \t 0.30928136706352233\n",
            "---------------\n",
            "Processing epoch: 860 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.5064615830779076\n",
            "Training loss:  \t 0.31065979823470113\n",
            "---------------\n",
            "Processing epoch: 861 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30185411870479584\n",
            "Training loss:  \t 0.3274307191371918\n",
            "---------------\n",
            "Processing epoch: 862 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3518233969807625\n",
            "Training loss:  \t 0.32101505622267723\n",
            "---------------\n",
            "Processing epoch: 863 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29302141815423965\n",
            "Training loss:  \t 0.32663471475243566\n",
            "---------------\n",
            "Processing epoch: 864 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36531686037778854\n",
            "Training loss:  \t 0.31649603992700576\n",
            "---------------\n",
            "Processing epoch: 865 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3696223497390747\n",
            "Training loss:  \t 0.36061789393424987\n",
            "---------------\n",
            "Processing epoch: 866 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3197576031088829\n",
            "Training loss:  \t 0.34083435535430906\n",
            "---------------\n",
            "Processing epoch: 867 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3599471412599087\n",
            "Training loss:  \t 0.37390741854906084\n",
            "---------------\n",
            "Processing epoch: 868 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3569130003452301\n",
            "Training loss:  \t 0.345869480073452\n",
            "---------------\n",
            "Processing epoch: 869 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3557620570063591\n",
            "Training loss:  \t 0.3420484133064747\n",
            "---------------\n",
            "Processing epoch: 870 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30587131530046463\n",
            "Training loss:  \t 0.33145849853754045\n",
            "---------------\n",
            "Processing epoch: 871 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33060871809720993\n",
            "Training loss:  \t 0.3062335383147001\n",
            "---------------\n",
            "Processing epoch: 872 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2792527787387371\n",
            "Training loss:  \t 0.3191931776702404\n",
            "---------------\n",
            "Processing epoch: 873 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31055014580488205\n",
            "Training loss:  \t 0.31289582699537277\n",
            "---------------\n",
            "Processing epoch: 874 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2805892825126648\n",
            "Training loss:  \t 0.30467465370893476\n",
            "---------------\n",
            "Processing epoch: 875 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3952217809855938\n",
            "Training loss:  \t 0.46113400906324387\n",
            "---------------\n",
            "Processing epoch: 876 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3951444625854492\n",
            "Training loss:  \t 0.4739346049726009\n",
            "---------------\n",
            "Processing epoch: 877 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38746312260627747\n",
            "Training loss:  \t 0.47166968137025833\n",
            "---------------\n",
            "Processing epoch: 878 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38612593337893486\n",
            "Training loss:  \t 0.4697369016706944\n",
            "---------------\n",
            "Processing epoch: 879 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3724396750330925\n",
            "Training loss:  \t 0.46316233053803446\n",
            "---------------\n",
            "Processing epoch: 880 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3802780359983444\n",
            "Training loss:  \t 0.4576728522777557\n",
            "---------------\n",
            "Processing epoch: 881 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36500098556280136\n",
            "Training loss:  \t 0.45046004503965376\n",
            "---------------\n",
            "Processing epoch: 882 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.363948579877615\n",
            "Training loss:  \t 0.4408631891012192\n",
            "---------------\n",
            "Processing epoch: 883 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35728929564356804\n",
            "Training loss:  \t 0.43025303781032564\n",
            "---------------\n",
            "Processing epoch: 884 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35486655682325363\n",
            "Training loss:  \t 0.42418933622539046\n",
            "---------------\n",
            "Processing epoch: 885 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3616953343153\n",
            "Training loss:  \t 0.4207965940237045\n",
            "---------------\n",
            "Processing epoch: 886 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3532218486070633\n",
            "Training loss:  \t 0.4217944651842117\n",
            "---------------\n",
            "Processing epoch: 887 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3506881669163704\n",
            "Training loss:  \t 0.4092007830739021\n",
            "---------------\n",
            "Processing epoch: 888 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3501996248960495\n",
            "Training loss:  \t 0.4027630716562271\n",
            "---------------\n",
            "Processing epoch: 889 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35056551545858383\n",
            "Training loss:  \t 0.39107005670666695\n",
            "---------------\n",
            "Processing epoch: 890 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35229070484638214\n",
            "Training loss:  \t 0.3802058570086956\n",
            "---------------\n",
            "Processing epoch: 891 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35330887883901596\n",
            "Training loss:  \t 0.36878313943743707\n",
            "---------------\n",
            "Processing epoch: 892 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3560520149767399\n",
            "Training loss:  \t 0.35408423393964766\n",
            "---------------\n",
            "Processing epoch: 893 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34128671512007713\n",
            "Training loss:  \t 0.3422804854810238\n",
            "---------------\n",
            "Processing epoch: 894 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3242109827697277\n",
            "Training loss:  \t 0.3366197057068348\n",
            "---------------\n",
            "Processing epoch: 895 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32684797793626785\n",
            "Training loss:  \t 0.3363943211734295\n",
            "---------------\n",
            "Processing epoch: 896 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3297291174530983\n",
            "Training loss:  \t 0.33978435695171355\n",
            "---------------\n",
            "Processing epoch: 897 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3219830393791199\n",
            "Training loss:  \t 0.3291646532714367\n",
            "---------------\n",
            "Processing epoch: 898 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.328665304929018\n",
            "Training loss:  \t 0.3344717353582382\n",
            "---------------\n",
            "Processing epoch: 899 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31404414400458336\n",
            "Training loss:  \t 0.3312088318169117\n",
            "---------------\n",
            "Processing epoch: 900 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31906287744641304\n",
            "Training loss:  \t 0.3377810299396515\n",
            "---------------\n",
            "Processing epoch: 901 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30870096758008003\n",
            "Training loss:  \t 0.3261000163853168\n",
            "---------------\n",
            "Processing epoch: 902 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34717951714992523\n",
            "Training loss:  \t 0.33302858620882037\n",
            "---------------\n",
            "Processing epoch: 903 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3099138215184212\n",
            "Training loss:  \t 0.33355938643217087\n",
            "---------------\n",
            "Processing epoch: 904 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3044484592974186\n",
            "Training loss:  \t 0.32427403926849363\n",
            "---------------\n",
            "Processing epoch: 905 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34253931045532227\n",
            "Training loss:  \t 0.3294800385832787\n",
            "---------------\n",
            "Processing epoch: 906 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30980391800403595\n",
            "Training loss:  \t 0.32912116050720214\n",
            "---------------\n",
            "Processing epoch: 907 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2986900135874748\n",
            "Training loss:  \t 0.31612324714660645\n",
            "---------------\n",
            "Processing epoch: 908 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3066624030470848\n",
            "Training loss:  \t 0.3277433440089226\n",
            "---------------\n",
            "Processing epoch: 909 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3035542592406273\n",
            "Training loss:  \t 0.31549995541572573\n",
            "---------------\n",
            "Processing epoch: 910 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29652056470513344\n",
            "Training loss:  \t 0.31627408489584924\n",
            "---------------\n",
            "Processing epoch: 911 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29996332898736\n",
            "Training loss:  \t 0.3204427517950535\n",
            "---------------\n",
            "Processing epoch: 912 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3008457235991955\n",
            "Training loss:  \t 0.3159826748073101\n",
            "---------------\n",
            "Processing epoch: 913 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.333991888910532\n",
            "Training loss:  \t 0.31130993738770485\n",
            "---------------\n",
            "Processing epoch: 914 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3283190056681633\n",
            "Training loss:  \t 0.32510351315140723\n",
            "---------------\n",
            "Processing epoch: 915 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3013921156525612\n",
            "Training loss:  \t 0.3150860384106636\n",
            "---------------\n",
            "Processing epoch: 916 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31363608315587044\n",
            "Training loss:  \t 0.3162994898855686\n",
            "---------------\n",
            "Processing epoch: 917 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29620739445090294\n",
            "Training loss:  \t 0.3166898854076862\n",
            "---------------\n",
            "Processing epoch: 918 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3571802191436291\n",
            "Training loss:  \t 0.3204840160906315\n",
            "---------------\n",
            "Processing epoch: 919 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3565845489501953\n",
            "Training loss:  \t 0.3427239447832108\n",
            "---------------\n",
            "Processing epoch: 920 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31265170872211456\n",
            "Training loss:  \t 0.3291895370930433\n",
            "---------------\n",
            "Processing epoch: 921 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31257643550634384\n",
            "Training loss:  \t 0.3167610004544258\n",
            "---------------\n",
            "Processing epoch: 922 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3126922696828842\n",
            "Training loss:  \t 0.31945343092083933\n",
            "---------------\n",
            "Processing epoch: 923 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32610562443733215\n",
            "Training loss:  \t 0.3191451869904995\n",
            "---------------\n",
            "Processing epoch: 924 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2990603484213352\n",
            "Training loss:  \t 0.3205286510288715\n",
            "---------------\n",
            "Processing epoch: 925 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2983207739889622\n",
            "Training loss:  \t 0.31381946355104445\n",
            "---------------\n",
            "Processing epoch: 926 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33195099234580994\n",
            "Training loss:  \t 0.3157534271478653\n",
            "---------------\n",
            "Processing epoch: 927 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3026691600680351\n",
            "Training loss:  \t 0.31365292221307756\n",
            "---------------\n",
            "Processing epoch: 928 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29628610238432884\n",
            "Training loss:  \t 0.3137658379971981\n",
            "---------------\n",
            "Processing epoch: 929 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29635922983288765\n",
            "Training loss:  \t 0.30363570153713226\n",
            "---------------\n",
            "Processing epoch: 930 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2959336191415787\n",
            "Training loss:  \t 0.3102765500545502\n",
            "---------------\n",
            "Processing epoch: 931 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31040333583950996\n",
            "Training loss:  \t 0.3278831258416176\n",
            "---------------\n",
            "Processing epoch: 932 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3550790287554264\n",
            "Training loss:  \t 0.3272910162806511\n",
            "---------------\n",
            "Processing epoch: 933 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29260256700217724\n",
            "Training loss:  \t 0.31326182931661606\n",
            "---------------\n",
            "Processing epoch: 934 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3257744610309601\n",
            "Training loss:  \t 0.3120293810963631\n",
            "---------------\n",
            "Processing epoch: 935 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31660113483667374\n",
            "Training loss:  \t 0.3131799578666687\n",
            "---------------\n",
            "Processing epoch: 936 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31967809051275253\n",
            "Training loss:  \t 0.3204068712890148\n",
            "---------------\n",
            "Processing epoch: 937 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29638495296239853\n",
            "Training loss:  \t 0.3022427700459957\n",
            "---------------\n",
            "Processing epoch: 938 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2937926948070526\n",
            "Training loss:  \t 0.3053117521107197\n",
            "---------------\n",
            "Processing epoch: 939 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3599840849637985\n",
            "Training loss:  \t 0.3197561204433441\n",
            "---------------\n",
            "Processing epoch: 940 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3646819368004799\n",
            "Training loss:  \t 0.3392673272639513\n",
            "---------------\n",
            "Processing epoch: 941 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3028999790549278\n",
            "Training loss:  \t 0.31959875822067263\n",
            "---------------\n",
            "Processing epoch: 942 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3046918585896492\n",
            "Training loss:  \t 0.30719146504998207\n",
            "---------------\n",
            "Processing epoch: 943 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2964888699352741\n",
            "Training loss:  \t 0.3073387898504734\n",
            "---------------\n",
            "Processing epoch: 944 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.407743476331234\n",
            "Training loss:  \t 0.3012092784047127\n",
            "---------------\n",
            "Processing epoch: 945 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3507709577679634\n",
            "Training loss:  \t 0.3856631860136986\n",
            "---------------\n",
            "Processing epoch: 946 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33567629009485245\n",
            "Training loss:  \t 0.3248236857354641\n",
            "---------------\n",
            "Processing epoch: 947 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34470999240875244\n",
            "Training loss:  \t 0.31745758801698687\n",
            "---------------\n",
            "Processing epoch: 948 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33157146349549294\n",
            "Training loss:  \t 0.3204400561749935\n",
            "---------------\n",
            "Processing epoch: 949 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29213644936680794\n",
            "Training loss:  \t 0.30874137580394745\n",
            "---------------\n",
            "Processing epoch: 950 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29383135586977005\n",
            "Training loss:  \t 0.30660701617598535\n",
            "---------------\n",
            "Processing epoch: 951 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3551275506615639\n",
            "Training loss:  \t 0.30259127989411355\n",
            "---------------\n",
            "Processing epoch: 952 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3523547947406769\n",
            "Training loss:  \t 0.33055002316832544\n",
            "---------------\n",
            "Processing epoch: 953 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3092508167028427\n",
            "Training loss:  \t 0.31775548234581946\n",
            "---------------\n",
            "Processing epoch: 954 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29783274978399277\n",
            "Training loss:  \t 0.3067162729799747\n",
            "---------------\n",
            "Processing epoch: 955 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36430539190769196\n",
            "Training loss:  \t 0.327935092151165\n",
            "---------------\n",
            "Processing epoch: 956 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3684676978737116\n",
            "Training loss:  \t 0.3457496091723442\n",
            "---------------\n",
            "Processing epoch: 957 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3568146154284477\n",
            "Training loss:  \t 0.3367056980729103\n",
            "---------------\n",
            "Processing epoch: 958 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3117208033800125\n",
            "Training loss:  \t 0.323434454202652\n",
            "---------------\n",
            "Processing epoch: 959 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3049064986407757\n",
            "Training loss:  \t 0.3020445957779884\n",
            "---------------\n",
            "Processing epoch: 960 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36841221898794174\n",
            "Training loss:  \t 0.30741648450493814\n",
            "---------------\n",
            "Processing epoch: 961 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36682914569973946\n",
            "Training loss:  \t 0.35779352821409705\n",
            "---------------\n",
            "Processing epoch: 962 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36688607931137085\n",
            "Training loss:  \t 0.3429501410573721\n",
            "---------------\n",
            "Processing epoch: 963 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3687606602907181\n",
            "Training loss:  \t 0.33700983561575415\n",
            "---------------\n",
            "Processing epoch: 964 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35166555643081665\n",
            "Training loss:  \t 0.33450915291905403\n",
            "---------------\n",
            "Processing epoch: 965 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3310505077242851\n",
            "Training loss:  \t 0.3155114859342575\n",
            "---------------\n",
            "Processing epoch: 966 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30364739522337914\n",
            "Training loss:  \t 0.3054290980100632\n",
            "---------------\n",
            "Processing epoch: 967 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3708079904317856\n",
            "Training loss:  \t 0.32423431649804113\n",
            "---------------\n",
            "Processing epoch: 968 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3777749016880989\n",
            "Training loss:  \t 0.4190896421670914\n",
            "---------------\n",
            "Processing epoch: 969 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3700968511402607\n",
            "Training loss:  \t 0.420964653044939\n",
            "---------------\n",
            "Processing epoch: 970 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3696298971772194\n",
            "Training loss:  \t 0.40501122996211053\n",
            "---------------\n",
            "Processing epoch: 971 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3609410971403122\n",
            "Training loss:  \t 0.3892056465148926\n",
            "---------------\n",
            "Processing epoch: 972 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3596276342868805\n",
            "Training loss:  \t 0.3705307025462389\n",
            "---------------\n",
            "Processing epoch: 973 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3595840558409691\n",
            "Training loss:  \t 0.3582115150988102\n",
            "---------------\n",
            "Processing epoch: 974 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3635493516921997\n",
            "Training loss:  \t 0.3558251455426216\n",
            "---------------\n",
            "Processing epoch: 975 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3627747632563114\n",
            "Training loss:  \t 0.34876004196703436\n",
            "---------------\n",
            "Processing epoch: 976 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3659752607345581\n",
            "Training loss:  \t 0.34500071294605733\n",
            "---------------\n",
            "Processing epoch: 977 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3655082508921623\n",
            "Training loss:  \t 0.35350980795919895\n",
            "---------------\n",
            "Processing epoch: 978 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36920906230807304\n",
            "Training loss:  \t 0.3453497514128685\n",
            "---------------\n",
            "Processing epoch: 979 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37210409343242645\n",
            "Training loss:  \t 0.3433844864368439\n",
            "---------------\n",
            "Processing epoch: 980 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36643121391534805\n",
            "Training loss:  \t 0.34038536697626115\n",
            "---------------\n",
            "Processing epoch: 981 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3710041120648384\n",
            "Training loss:  \t 0.3383657217025757\n",
            "---------------\n",
            "Processing epoch: 982 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3743814006447792\n",
            "Training loss:  \t 0.33504480868577957\n",
            "---------------\n",
            "Processing epoch: 983 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3785376325249672\n",
            "Training loss:  \t 0.33420308381319047\n",
            "---------------\n",
            "Processing epoch: 984 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3778994083404541\n",
            "Training loss:  \t 0.32925708815455434\n",
            "---------------\n",
            "Processing epoch: 985 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38751162588596344\n",
            "Training loss:  \t 0.3483817368745804\n",
            "---------------\n",
            "Processing epoch: 986 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3789736144244671\n",
            "Training loss:  \t 0.3393185306340456\n",
            "---------------\n",
            "Processing epoch: 987 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3697750195860863\n",
            "Training loss:  \t 0.32341190725564956\n",
            "---------------\n",
            "Processing epoch: 988 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37266962602734566\n",
            "Training loss:  \t 0.32849003598093984\n",
            "---------------\n",
            "Processing epoch: 989 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3600013926625252\n",
            "Training loss:  \t 0.31971229761838915\n",
            "---------------\n",
            "Processing epoch: 990 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35267890989780426\n",
            "Training loss:  \t 0.3245312862098217\n",
            "---------------\n",
            "Processing epoch: 991 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.360888734459877\n",
            "Training loss:  \t 0.336562180519104\n",
            "---------------\n",
            "Processing epoch: 992 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35309968143701553\n",
            "Training loss:  \t 0.3318274147808552\n",
            "---------------\n",
            "Processing epoch: 993 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3581051602959633\n",
            "Training loss:  \t 0.3245301924645901\n",
            "---------------\n",
            "Processing epoch: 994 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32871708273887634\n",
            "Training loss:  \t 0.3188796408474445\n",
            "---------------\n",
            "Processing epoch: 995 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30195341631770134\n",
            "Training loss:  \t 0.3153333380818367\n",
            "---------------\n",
            "Processing epoch: 996 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28836364671587944\n",
            "Training loss:  \t 0.3169889472424984\n",
            "---------------\n",
            "Processing epoch: 997 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3234061002731323\n",
            "Training loss:  \t 0.30441425144672396\n",
            "---------------\n",
            "Processing epoch: 998 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29252670519053936\n",
            "Training loss:  \t 0.3048940569162369\n",
            "---------------\n",
            "Processing epoch: 999 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2796379178762436\n",
            "Training loss:  \t 0.2980521317571402\n",
            "---------------\n",
            "Processing epoch: 1000 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3202626034617424\n",
            "Training loss:  \t 0.30294643752276895\n",
            "---------------\n",
            "Processing epoch: 1001 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2757313475012779\n",
            "Training loss:  \t 0.30052811838686466\n",
            "---------------\n",
            "Processing epoch: 1002 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30368463322520256\n",
            "Training loss:  \t 0.3002070277929306\n",
            "---------------\n",
            "Processing epoch: 1003 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36206553131341934\n",
            "Training loss:  \t 0.3523907080292702\n",
            "---------------\n",
            "Processing epoch: 1004 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3672763928771019\n",
            "Training loss:  \t 0.3537031844258308\n",
            "---------------\n",
            "Processing epoch: 1005 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29983362182974815\n",
            "Training loss:  \t 0.32574754431843755\n",
            "---------------\n",
            "Processing epoch: 1006 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26785139739513397\n",
            "Training loss:  \t 0.3017004534602165\n",
            "---------------\n",
            "Processing epoch: 1007 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3659108057618141\n",
            "Training loss:  \t 0.32400885596871376\n",
            "---------------\n",
            "Processing epoch: 1008 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37586095929145813\n",
            "Training loss:  \t 0.3829925861209631\n",
            "---------------\n",
            "Processing epoch: 1009 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3624962419271469\n",
            "Training loss:  \t 0.368773041665554\n",
            "---------------\n",
            "Processing epoch: 1010 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36050456017255783\n",
            "Training loss:  \t 0.3427600212395191\n",
            "---------------\n",
            "Processing epoch: 1011 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3333307318389416\n",
            "Training loss:  \t 0.3275271400809288\n",
            "---------------\n",
            "Processing epoch: 1012 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2778044007718563\n",
            "Training loss:  \t 0.3011862073093653\n",
            "---------------\n",
            "Processing epoch: 1013 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28455131128430367\n",
            "Training loss:  \t 0.2943082317709923\n",
            "---------------\n",
            "Processing epoch: 1014 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29495254158973694\n",
            "Training loss:  \t 0.2912365082651377\n",
            "---------------\n",
            "Processing epoch: 1015 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2794145308434963\n",
            "Training loss:  \t 0.2900539129972458\n",
            "---------------\n",
            "Processing epoch: 1016 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34097934141755104\n",
            "Training loss:  \t 0.3130919672548771\n",
            "---------------\n",
            "Processing epoch: 1017 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.280470609664917\n",
            "Training loss:  \t 0.3747151896357536\n",
            "---------------\n",
            "Processing epoch: 1018 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3663237690925598\n",
            "Training loss:  \t 0.34876077249646187\n",
            "---------------\n",
            "Processing epoch: 1019 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34709062054753304\n",
            "Training loss:  \t 0.331650697439909\n",
            "---------------\n",
            "Processing epoch: 1020 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.8848846703767776\n",
            "Training loss:  \t 0.4285616002976894\n",
            "---------------\n",
            "Processing epoch: 1021 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37868840247392654\n",
            "Training loss:  \t 0.6920283779501915\n",
            "---------------\n",
            "Processing epoch: 1022 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37932539731264114\n",
            "Training loss:  \t 0.4266983263194561\n",
            "---------------\n",
            "Processing epoch: 1023 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36610981076955795\n",
            "Training loss:  \t 0.39219638854265215\n",
            "---------------\n",
            "Processing epoch: 1024 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36903834715485573\n",
            "Training loss:  \t 0.3536655351519585\n",
            "---------------\n",
            "Processing epoch: 1025 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3529781103134155\n",
            "Training loss:  \t 0.3360611766576767\n",
            "---------------\n",
            "Processing epoch: 1026 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30592066794633865\n",
            "Training loss:  \t 0.30656261220574377\n",
            "---------------\n",
            "Processing epoch: 1027 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35599279403686523\n",
            "Training loss:  \t 0.3205530237406492\n",
            "---------------\n",
            "Processing epoch: 1028 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3635789752006531\n",
            "Training loss:  \t 0.35141508243978026\n",
            "---------------\n",
            "Processing epoch: 1029 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31139659136533737\n",
            "Training loss:  \t 0.3139163121581078\n",
            "---------------\n",
            "Processing epoch: 1030 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28898869827389717\n",
            "Training loss:  \t 0.2962460607290268\n",
            "---------------\n",
            "Processing epoch: 1031 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33021094277501106\n",
            "Training loss:  \t 0.28747665584087373\n",
            "---------------\n",
            "Processing epoch: 1032 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3251468576490879\n",
            "Training loss:  \t 0.32321924567222593\n",
            "---------------\n",
            "Processing epoch: 1033 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2766679748892784\n",
            "Training loss:  \t 0.29257604032754897\n",
            "---------------\n",
            "Processing epoch: 1034 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2939753979444504\n",
            "Training loss:  \t 0.2908486068248749\n",
            "---------------\n",
            "Processing epoch: 1035 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30023061856627464\n",
            "Training loss:  \t 0.2865383055061102\n",
            "---------------\n",
            "Processing epoch: 1036 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2937398888170719\n",
            "Training loss:  \t 0.2970416098833084\n",
            "---------------\n",
            "Processing epoch: 1037 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2825647369027138\n",
            "Training loss:  \t 0.2863352958112955\n",
            "---------------\n",
            "Processing epoch: 1038 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26530879735946655\n",
            "Training loss:  \t 0.28850982785224916\n",
            "---------------\n",
            "Processing epoch: 1039 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27072725258767605\n",
            "Training loss:  \t 0.3056170426309109\n",
            "---------------\n",
            "Processing epoch: 1040 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3684229888021946\n",
            "Training loss:  \t 0.332610347121954\n",
            "---------------\n",
            "Processing epoch: 1041 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3729751780629158\n",
            "Training loss:  \t 0.4006234727799892\n",
            "---------------\n",
            "Processing epoch: 1042 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.362700954079628\n",
            "Training loss:  \t 0.3907519742846489\n",
            "---------------\n",
            "Processing epoch: 1043 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3613824136555195\n",
            "Training loss:  \t 0.3604232229292393\n",
            "---------------\n",
            "Processing epoch: 1044 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3615286573767662\n",
            "Training loss:  \t 0.34374478831887245\n",
            "---------------\n",
            "Processing epoch: 1045 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3411816507577896\n",
            "Training loss:  \t 0.33398033156991\n",
            "---------------\n",
            "Processing epoch: 1046 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30925722792744637\n",
            "Training loss:  \t 0.3082407847046852\n",
            "---------------\n",
            "Processing epoch: 1047 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2932051829993725\n",
            "Training loss:  \t 0.29526976086199286\n",
            "---------------\n",
            "Processing epoch: 1048 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27667123079299927\n",
            "Training loss:  \t 0.2912476323544979\n",
            "---------------\n",
            "Processing epoch: 1049 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26863957196474075\n",
            "Training loss:  \t 0.2905937071889639\n",
            "---------------\n",
            "Processing epoch: 1050 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32545413076877594\n",
            "Training loss:  \t 0.29673032127320764\n",
            "---------------\n",
            "Processing epoch: 1051 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31079816073179245\n",
            "Training loss:  \t 0.2978930652141571\n",
            "---------------\n",
            "Processing epoch: 1052 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36726874858140945\n",
            "Training loss:  \t 0.33078335523605346\n",
            "---------------\n",
            "Processing epoch: 1053 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3171949088573456\n",
            "Training loss:  \t 0.325989730656147\n",
            "---------------\n",
            "Processing epoch: 1054 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29936225712299347\n",
            "Training loss:  \t 0.28590732887387277\n",
            "---------------\n",
            "Processing epoch: 1055 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3665241189301014\n",
            "Training loss:  \t 0.34603398814797404\n",
            "---------------\n",
            "Processing epoch: 1056 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3726484179496765\n",
            "Training loss:  \t 0.38464799597859384\n",
            "---------------\n",
            "Processing epoch: 1057 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36815519258379936\n",
            "Training loss:  \t 0.36010564006865026\n",
            "---------------\n",
            "Processing epoch: 1058 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3606957644224167\n",
            "Training loss:  \t 0.3376581646502018\n",
            "---------------\n",
            "Processing epoch: 1059 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3361223079264164\n",
            "Training loss:  \t 0.31883386299014094\n",
            "---------------\n",
            "Processing epoch: 1060 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28396985679864883\n",
            "Training loss:  \t 0.3046422258019447\n",
            "---------------\n",
            "Processing epoch: 1061 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30591800808906555\n",
            "Training loss:  \t 0.29964585080742834\n",
            "---------------\n",
            "Processing epoch: 1062 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3139984756708145\n",
            "Training loss:  \t 0.29877863079309464\n",
            "---------------\n",
            "Processing epoch: 1063 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26956599578261375\n",
            "Training loss:  \t 0.285626333206892\n",
            "---------------\n",
            "Processing epoch: 1064 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2888021767139435\n",
            "Training loss:  \t 0.30437874272465704\n",
            "---------------\n",
            "Processing epoch: 1065 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3017091825604439\n",
            "Training loss:  \t 0.305870970338583\n",
            "---------------\n",
            "Processing epoch: 1066 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35377301275730133\n",
            "Training loss:  \t 0.2947758659720421\n",
            "---------------\n",
            "Processing epoch: 1067 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31689494103193283\n",
            "Training loss:  \t 0.31358808279037476\n",
            "---------------\n",
            "Processing epoch: 1068 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2670537456870079\n",
            "Training loss:  \t 0.2946003139019012\n",
            "---------------\n",
            "Processing epoch: 1069 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26610931009054184\n",
            "Training loss:  \t 0.29197272285819054\n",
            "---------------\n",
            "Processing epoch: 1070 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26605580374598503\n",
            "Training loss:  \t 0.2894988045096397\n",
            "---------------\n",
            "Processing epoch: 1071 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33748430758714676\n",
            "Training loss:  \t 0.28810226209461687\n",
            "---------------\n",
            "Processing epoch: 1072 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35715310648083687\n",
            "Training loss:  \t 0.32550140023231505\n",
            "---------------\n",
            "Processing epoch: 1073 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.269830908626318\n",
            "Training loss:  \t 0.30077371522784235\n",
            "---------------\n",
            "Processing epoch: 1074 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3620118387043476\n",
            "Training loss:  \t 0.3040184132754803\n",
            "---------------\n",
            "Processing epoch: 1075 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3770355358719826\n",
            "Training loss:  \t 0.3933730207383633\n",
            "---------------\n",
            "Processing epoch: 1076 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3677843101322651\n",
            "Training loss:  \t 0.40329874865710735\n",
            "---------------\n",
            "Processing epoch: 1077 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36327822133898735\n",
            "Training loss:  \t 0.36895868107676505\n",
            "---------------\n",
            "Processing epoch: 1078 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35652314499020576\n",
            "Training loss:  \t 0.3454372577369213\n",
            "---------------\n",
            "Processing epoch: 1079 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3608510121703148\n",
            "Training loss:  \t 0.33287507072091105\n",
            "---------------\n",
            "Processing epoch: 1080 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29941780865192413\n",
            "Training loss:  \t 0.3128047171980143\n",
            "---------------\n",
            "Processing epoch: 1081 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3159293085336685\n",
            "Training loss:  \t 0.30361146964132785\n",
            "---------------\n",
            "Processing epoch: 1082 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.307917732745409\n",
            "Training loss:  \t 0.2909604925662279\n",
            "---------------\n",
            "Processing epoch: 1083 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27619146183133125\n",
            "Training loss:  \t 0.2876456089317799\n",
            "---------------\n",
            "Processing epoch: 1084 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3075772672891617\n",
            "Training loss:  \t 0.28860497325658796\n",
            "---------------\n",
            "Processing epoch: 1085 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3197762630879879\n",
            "Training loss:  \t 0.2944945730268955\n",
            "---------------\n",
            "Processing epoch: 1086 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2730356939136982\n",
            "Training loss:  \t 0.2928490832448006\n",
            "---------------\n",
            "Processing epoch: 1087 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33793072402477264\n",
            "Training loss:  \t 0.299007223919034\n",
            "---------------\n",
            "Processing epoch: 1088 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27922188490629196\n",
            "Training loss:  \t 0.28672100640833376\n",
            "---------------\n",
            "Processing epoch: 1089 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2671371102333069\n",
            "Training loss:  \t 0.2864637576043606\n",
            "---------------\n",
            "Processing epoch: 1090 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36304740607738495\n",
            "Training loss:  \t 0.3066220335662365\n",
            "---------------\n",
            "Processing epoch: 1091 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37355887144804\n",
            "Training loss:  \t 0.35178093463182447\n",
            "---------------\n",
            "Processing epoch: 1092 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32070011273026466\n",
            "Training loss:  \t 0.3267662301659584\n",
            "---------------\n",
            "Processing epoch: 1093 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28605325520038605\n",
            "Training loss:  \t 0.2902910731732845\n",
            "---------------\n",
            "Processing epoch: 1094 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35333118587732315\n",
            "Training loss:  \t 0.3104779914021492\n",
            "---------------\n",
            "Processing epoch: 1095 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26595987007021904\n",
            "Training loss:  \t 0.2985759187489748\n",
            "---------------\n",
            "Processing epoch: 1096 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29027653485536575\n",
            "Training loss:  \t 0.28413285352289674\n",
            "---------------\n",
            "Processing epoch: 1097 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2667749561369419\n",
            "Training loss:  \t 0.28681670874357224\n",
            "---------------\n",
            "Processing epoch: 1098 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3611404299736023\n",
            "Training loss:  \t 0.3244857907295227\n",
            "---------------\n",
            "Processing epoch: 1099 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2768983840942383\n",
            "Training loss:  \t 0.3033372685313225\n",
            "---------------\n",
            "Processing epoch: 1100 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26447315141558647\n",
            "Training loss:  \t 0.28211172521114347\n",
            "---------------\n",
            "Processing epoch: 1101 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3251987621188164\n",
            "Training loss:  \t 0.2907928772270679\n",
            "---------------\n",
            "Processing epoch: 1102 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2704186700284481\n",
            "Training loss:  \t 0.2903618089854717\n",
            "---------------\n",
            "Processing epoch: 1103 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2767472602427006\n",
            "Training loss:  \t 0.283301816880703\n",
            "---------------\n",
            "Processing epoch: 1104 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3906133137643337\n",
            "Training loss:  \t 0.3859656386077404\n",
            "---------------\n",
            "Processing epoch: 1105 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39746301621198654\n",
            "Training loss:  \t 0.4543371364474297\n",
            "---------------\n",
            "Processing epoch: 1106 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39206424355506897\n",
            "Training loss:  \t 0.45729371830821036\n",
            "---------------\n",
            "Processing epoch: 1107 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37174712494015694\n",
            "Training loss:  \t 0.45268927738070486\n",
            "---------------\n",
            "Processing epoch: 1108 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3756845071911812\n",
            "Training loss:  \t 0.43693087846040723\n",
            "---------------\n",
            "Processing epoch: 1109 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36605704203248024\n",
            "Training loss:  \t 0.4289230637252331\n",
            "---------------\n",
            "Processing epoch: 1110 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3630318231880665\n",
            "Training loss:  \t 0.4242279179394245\n",
            "---------------\n",
            "Processing epoch: 1111 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36183205246925354\n",
            "Training loss:  \t 0.40752544179558753\n",
            "---------------\n",
            "Processing epoch: 1112 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3537904378026724\n",
            "Training loss:  \t 0.40191101729869844\n",
            "---------------\n",
            "Processing epoch: 1113 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35746313631534576\n",
            "Training loss:  \t 0.38930658660829065\n",
            "---------------\n",
            "Processing epoch: 1114 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3523780032992363\n",
            "Training loss:  \t 0.3852988533675671\n",
            "---------------\n",
            "Processing epoch: 1115 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35675182193517685\n",
            "Training loss:  \t 0.3746172353625298\n",
            "---------------\n",
            "Processing epoch: 1116 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3584287650883198\n",
            "Training loss:  \t 0.36027091816067697\n",
            "---------------\n",
            "Processing epoch: 1117 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35574277490377426\n",
            "Training loss:  \t 0.35835003927350045\n",
            "---------------\n",
            "Processing epoch: 1118 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35741280764341354\n",
            "Training loss:  \t 0.343485151976347\n",
            "---------------\n",
            "Processing epoch: 1119 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3556859642267227\n",
            "Training loss:  \t 0.3388869769871235\n",
            "---------------\n",
            "Processing epoch: 1120 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3579639494419098\n",
            "Training loss:  \t 0.33816350661218164\n",
            "---------------\n",
            "Processing epoch: 1121 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3575756698846817\n",
            "Training loss:  \t 0.32647687420248983\n",
            "---------------\n",
            "Processing epoch: 1122 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35202984139323235\n",
            "Training loss:  \t 0.3193403363227844\n",
            "---------------\n",
            "Processing epoch: 1123 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3283375948667526\n",
            "Training loss:  \t 0.3067836008965969\n",
            "---------------\n",
            "Processing epoch: 1124 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32620586454868317\n",
            "Training loss:  \t 0.2996013343334198\n",
            "---------------\n",
            "Processing epoch: 1125 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3190131336450577\n",
            "Training loss:  \t 0.293696615844965\n",
            "---------------\n",
            "Processing epoch: 1126 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3002905882894993\n",
            "Training loss:  \t 0.30216056667268276\n",
            "---------------\n",
            "Processing epoch: 1127 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29430462792515755\n",
            "Training loss:  \t 0.2913147360086441\n",
            "---------------\n",
            "Processing epoch: 1128 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.280825462192297\n",
            "Training loss:  \t 0.29180610105395316\n",
            "---------------\n",
            "Processing epoch: 1129 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33919118344783783\n",
            "Training loss:  \t 0.28822698518633844\n",
            "---------------\n",
            "Processing epoch: 1130 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29494363628327847\n",
            "Training loss:  \t 0.2998042874038219\n",
            "---------------\n",
            "Processing epoch: 1131 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34327222406864166\n",
            "Training loss:  \t 0.2910691801458597\n",
            "---------------\n",
            "Processing epoch: 1132 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3681969400495291\n",
            "Training loss:  \t 0.3425514817237854\n",
            "---------------\n",
            "Processing epoch: 1133 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36011189967393875\n",
            "Training loss:  \t 0.33073476105928423\n",
            "---------------\n",
            "Processing epoch: 1134 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2951299324631691\n",
            "Training loss:  \t 0.30609478056430817\n",
            "---------------\n",
            "Processing epoch: 1135 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27274302765727043\n",
            "Training loss:  \t 0.2869261421263218\n",
            "---------------\n",
            "Processing epoch: 1136 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29631418734788895\n",
            "Training loss:  \t 0.2819768227636814\n",
            "---------------\n",
            "Processing epoch: 1137 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2757353074848652\n",
            "Training loss:  \t 0.28451896756887435\n",
            "---------------\n",
            "Processing epoch: 1138 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27098990976810455\n",
            "Training loss:  \t 0.28633086010813713\n",
            "---------------\n",
            "Processing epoch: 1139 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33267319947481155\n",
            "Training loss:  \t 0.28440577648580073\n",
            "---------------\n",
            "Processing epoch: 1140 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31605711579322815\n",
            "Training loss:  \t 0.2933268129825592\n",
            "---------------\n",
            "Processing epoch: 1141 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3419357240200043\n",
            "Training loss:  \t 0.3040915377438068\n",
            "---------------\n",
            "Processing epoch: 1142 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2939608357846737\n",
            "Training loss:  \t 0.280523008108139\n",
            "---------------\n",
            "Processing epoch: 1143 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3664892539381981\n",
            "Training loss:  \t 0.3995386637747288\n",
            "---------------\n",
            "Processing epoch: 1144 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36563070863485336\n",
            "Training loss:  \t 0.3488269723951817\n",
            "---------------\n",
            "Processing epoch: 1145 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3479445166885853\n",
            "Training loss:  \t 0.32325769662857057\n",
            "---------------\n",
            "Processing epoch: 1146 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2751859687268734\n",
            "Training loss:  \t 0.2927586488425732\n",
            "---------------\n",
            "Processing epoch: 1147 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2916678264737129\n",
            "Training loss:  \t 0.28389216437935827\n",
            "---------------\n",
            "Processing epoch: 1148 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28034400194883347\n",
            "Training loss:  \t 0.28592346869409085\n",
            "---------------\n",
            "Processing epoch: 1149 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3493565507233143\n",
            "Training loss:  \t 0.3079452410340309\n",
            "---------------\n",
            "Processing epoch: 1150 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2755786143243313\n",
            "Training loss:  \t 0.29773996993899343\n",
            "---------------\n",
            "Processing epoch: 1151 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27463872730731964\n",
            "Training loss:  \t 0.28697998598217966\n",
            "---------------\n",
            "Processing epoch: 1152 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27682700380682945\n",
            "Training loss:  \t 0.28362236768007276\n",
            "---------------\n",
            "Processing epoch: 1153 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2677487023174763\n",
            "Training loss:  \t 0.2845707729458809\n",
            "---------------\n",
            "Processing epoch: 1154 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35676778852939606\n",
            "Training loss:  \t 0.30395601093769076\n",
            "---------------\n",
            "Processing epoch: 1155 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3058759979903698\n",
            "Training loss:  \t 0.2972320135682821\n",
            "---------------\n",
            "Processing epoch: 1156 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.42375269532203674\n",
            "Training loss:  \t 0.5959867879748344\n",
            "---------------\n",
            "Processing epoch: 1157 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3913961797952652\n",
            "Training loss:  \t 0.4689776226878166\n",
            "---------------\n",
            "Processing epoch: 1158 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38101355358958244\n",
            "Training loss:  \t 0.4436004251241684\n",
            "---------------\n",
            "Processing epoch: 1159 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.381179042160511\n",
            "Training loss:  \t 0.4335097037255764\n",
            "---------------\n",
            "Processing epoch: 1160 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37342508137226105\n",
            "Training loss:  \t 0.42078409567475317\n",
            "---------------\n",
            "Processing epoch: 1161 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3613981008529663\n",
            "Training loss:  \t 0.41473882719874383\n",
            "---------------\n",
            "Processing epoch: 1162 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3586354237049818\n",
            "Training loss:  \t 0.4030744507908821\n",
            "---------------\n",
            "Processing epoch: 1163 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35312672331929207\n",
            "Training loss:  \t 0.3841678462922573\n",
            "---------------\n",
            "Processing epoch: 1164 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3551008626818657\n",
            "Training loss:  \t 0.3746738873422146\n",
            "---------------\n",
            "Processing epoch: 1165 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3542540669441223\n",
            "Training loss:  \t 0.3555877983570099\n",
            "---------------\n",
            "Processing epoch: 1166 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35658182203769684\n",
            "Training loss:  \t 0.3452735669910908\n",
            "---------------\n",
            "Processing epoch: 1167 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3602071963250637\n",
            "Training loss:  \t 0.33101641982793806\n",
            "---------------\n",
            "Processing epoch: 1168 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3480710908770561\n",
            "Training loss:  \t 0.32052306495606897\n",
            "---------------\n",
            "Processing epoch: 1169 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3129443861544132\n",
            "Training loss:  \t 0.3084028623998165\n",
            "---------------\n",
            "Processing epoch: 1170 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3273240402340889\n",
            "Training loss:  \t 0.29615578800439835\n",
            "---------------\n",
            "Processing epoch: 1171 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.289250023663044\n",
            "Training loss:  \t 0.28740903325378897\n",
            "---------------\n",
            "Processing epoch: 1172 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2803102284669876\n",
            "Training loss:  \t 0.28893075734376905\n",
            "---------------\n",
            "Processing epoch: 1173 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27713506296277046\n",
            "Training loss:  \t 0.2784467276185751\n",
            "---------------\n",
            "Processing epoch: 1174 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29433294385671616\n",
            "Training loss:  \t 0.2879235874861479\n",
            "---------------\n",
            "Processing epoch: 1175 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27262017130851746\n",
            "Training loss:  \t 0.27948818653821944\n",
            "---------------\n",
            "Processing epoch: 1176 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32505906373262405\n",
            "Training loss:  \t 0.27859067022800443\n",
            "---------------\n",
            "Processing epoch: 1177 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.275055430829525\n",
            "Training loss:  \t 0.28403138741850853\n",
            "---------------\n",
            "Processing epoch: 1178 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29514962434768677\n",
            "Training loss:  \t 0.2824001617729664\n",
            "---------------\n",
            "Processing epoch: 1179 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3649828489869833\n",
            "Training loss:  \t 0.3062806114554405\n",
            "---------------\n",
            "Processing epoch: 1180 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30679042264819145\n",
            "Training loss:  \t 0.30454856902360916\n",
            "---------------\n",
            "Processing epoch: 1181 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27237391844391823\n",
            "Training loss:  \t 0.2860951520502567\n",
            "---------------\n",
            "Processing epoch: 1182 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37587326392531395\n",
            "Training loss:  \t 0.30436397418379785\n",
            "---------------\n",
            "Processing epoch: 1183 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37670496106147766\n",
            "Training loss:  \t 0.415134646743536\n",
            "---------------\n",
            "Processing epoch: 1184 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36664827540516853\n",
            "Training loss:  \t 0.40428785011172297\n",
            "---------------\n",
            "Processing epoch: 1185 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3626588433980942\n",
            "Training loss:  \t 0.3865287143737078\n",
            "---------------\n",
            "Processing epoch: 1186 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35992521792650223\n",
            "Training loss:  \t 0.37147566229104995\n",
            "---------------\n",
            "Processing epoch: 1187 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35418371856212616\n",
            "Training loss:  \t 0.34587463513016703\n",
            "---------------\n",
            "Processing epoch: 1188 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.358551736921072\n",
            "Training loss:  \t 0.3347293261438608\n",
            "---------------\n",
            "Processing epoch: 1189 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35565343499183655\n",
            "Training loss:  \t 0.32326158620417117\n",
            "---------------\n",
            "Processing epoch: 1190 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34282589331269264\n",
            "Training loss:  \t 0.3098252221941948\n",
            "---------------\n",
            "Processing epoch: 1191 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3125813901424408\n",
            "Training loss:  \t 0.29138971082866194\n",
            "---------------\n",
            "Processing epoch: 1192 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2993990443646908\n",
            "Training loss:  \t 0.2899113580584526\n",
            "---------------\n",
            "Processing epoch: 1193 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.311606764793396\n",
            "Training loss:  \t 0.2881031960248947\n",
            "---------------\n",
            "Processing epoch: 1194 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2861917056143284\n",
            "Training loss:  \t 0.2831826277077198\n",
            "---------------\n",
            "Processing epoch: 1195 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2832329384982586\n",
            "Training loss:  \t 0.28146983683109283\n",
            "---------------\n",
            "Processing epoch: 1196 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27272870764136314\n",
            "Training loss:  \t 0.27846643440425395\n",
            "---------------\n",
            "Processing epoch: 1197 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28427427262067795\n",
            "Training loss:  \t 0.2800438217818737\n",
            "---------------\n",
            "Processing epoch: 1198 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.335009902715683\n",
            "Training loss:  \t 0.28790542371571065\n",
            "---------------\n",
            "Processing epoch: 1199 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33475499600172043\n",
            "Training loss:  \t 0.30429451130330565\n",
            "---------------\n",
            "Processing epoch: 1200 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2742185592651367\n",
            "Training loss:  \t 0.2761184860020876\n",
            "---------------\n",
            "Processing epoch: 1201 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3756192494183779\n",
            "Training loss:  \t 0.3176185924559832\n",
            "---------------\n",
            "Processing epoch: 1202 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38088400289416313\n",
            "Training loss:  \t 0.40501413494348526\n",
            "---------------\n",
            "Processing epoch: 1203 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36379437148571014\n",
            "Training loss:  \t 0.40038424730300903\n",
            "---------------\n",
            "Processing epoch: 1204 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3661033362150192\n",
            "Training loss:  \t 0.37182376384735105\n",
            "---------------\n",
            "Processing epoch: 1205 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3594020940363407\n",
            "Training loss:  \t 0.34620954729616643\n",
            "---------------\n",
            "Processing epoch: 1206 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3631919249892235\n",
            "Training loss:  \t 0.3314203888177872\n",
            "---------------\n",
            "Processing epoch: 1207 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3547809664160013\n",
            "Training loss:  \t 0.3213221751153469\n",
            "---------------\n",
            "Processing epoch: 1208 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3437103182077408\n",
            "Training loss:  \t 0.31215134225785734\n",
            "---------------\n",
            "Processing epoch: 1209 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3327053673565388\n",
            "Training loss:  \t 0.29399242959916594\n",
            "---------------\n",
            "Processing epoch: 1210 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29850509390234947\n",
            "Training loss:  \t 0.28847695626318454\n",
            "---------------\n",
            "Processing epoch: 1211 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31056492030620575\n",
            "Training loss:  \t 0.2844650149345398\n",
            "---------------\n",
            "Processing epoch: 1212 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31280768662691116\n",
            "Training loss:  \t 0.2829006813466549\n",
            "---------------\n",
            "Processing epoch: 1213 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27974187955260277\n",
            "Training loss:  \t 0.28877139948308467\n",
            "---------------\n",
            "Processing epoch: 1214 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3116649091243744\n",
            "Training loss:  \t 0.2836258463561535\n",
            "---------------\n",
            "Processing epoch: 1215 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3665735572576523\n",
            "Training loss:  \t 0.27686344683170316\n",
            "---------------\n",
            "Processing epoch: 1216 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37323828414082527\n",
            "Training loss:  \t 0.36186090111732483\n",
            "---------------\n",
            "Processing epoch: 1217 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36642707884311676\n",
            "Training loss:  \t 0.3477969244122505\n",
            "---------------\n",
            "Processing epoch: 1218 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36269352212548256\n",
            "Training loss:  \t 0.3252433605492115\n",
            "---------------\n",
            "Processing epoch: 1219 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35790518298745155\n",
            "Training loss:  \t 0.3215058486908674\n",
            "---------------\n",
            "Processing epoch: 1220 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3301836587488651\n",
            "Training loss:  \t 0.2960235048085451\n",
            "---------------\n",
            "Processing epoch: 1221 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3224106505513191\n",
            "Training loss:  \t 0.2831363558769226\n",
            "---------------\n",
            "Processing epoch: 1222 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28994978219270706\n",
            "Training loss:  \t 0.2859141260385513\n",
            "---------------\n",
            "Processing epoch: 1223 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2820253521203995\n",
            "Training loss:  \t 0.2795543257147074\n",
            "---------------\n",
            "Processing epoch: 1224 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2914941646158695\n",
            "Training loss:  \t 0.27511789873242376\n",
            "---------------\n",
            "Processing epoch: 1225 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2921423688530922\n",
            "Training loss:  \t 0.2870184451341629\n",
            "---------------\n",
            "Processing epoch: 1226 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28315725177526474\n",
            "Training loss:  \t 0.27423386499285696\n",
            "---------------\n",
            "Processing epoch: 1227 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2722278777509928\n",
            "Training loss:  \t 0.2749027207493782\n",
            "---------------\n",
            "Processing epoch: 1228 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29576563835144043\n",
            "Training loss:  \t 0.2785443626344204\n",
            "---------------\n",
            "Processing epoch: 1229 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2903446927666664\n",
            "Training loss:  \t 0.2766705691814423\n",
            "---------------\n",
            "Processing epoch: 1230 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26738743111491203\n",
            "Training loss:  \t 0.2822987861931324\n",
            "---------------\n",
            "Processing epoch: 1231 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28793806210160255\n",
            "Training loss:  \t 0.27480209022760393\n",
            "---------------\n",
            "Processing epoch: 1232 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2716306112706661\n",
            "Training loss:  \t 0.27610025331377985\n",
            "---------------\n",
            "Processing epoch: 1233 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28934210166335106\n",
            "Training loss:  \t 0.2663887348026037\n",
            "---------------\n",
            "Processing epoch: 1234 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2983633205294609\n",
            "Training loss:  \t 0.25853992998600006\n",
            "---------------\n",
            "Processing epoch: 1235 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2818993292748928\n",
            "Training loss:  \t 0.2769336398690939\n",
            "---------------\n",
            "Processing epoch: 1236 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26394081860780716\n",
            "Training loss:  \t 0.27104026563465594\n",
            "---------------\n",
            "Processing epoch: 1237 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37867389619350433\n",
            "Training loss:  \t 0.33172078505158425\n",
            "---------------\n",
            "Processing epoch: 1238 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3807101920247078\n",
            "Training loss:  \t 0.39664059653878214\n",
            "---------------\n",
            "Processing epoch: 1239 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36655534245073795\n",
            "Training loss:  \t 0.38051374405622485\n",
            "---------------\n",
            "Processing epoch: 1240 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3628964051604271\n",
            "Training loss:  \t 0.34952632784843446\n",
            "---------------\n",
            "Processing epoch: 1241 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3639780506491661\n",
            "Training loss:  \t 0.3230950564146042\n",
            "---------------\n",
            "Processing epoch: 1242 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34571685642004013\n",
            "Training loss:  \t 0.3133620873093605\n",
            "---------------\n",
            "Processing epoch: 1243 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30076945573091507\n",
            "Training loss:  \t 0.2918477226048708\n",
            "---------------\n",
            "Processing epoch: 1244 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30081161111593246\n",
            "Training loss:  \t 0.28449374809861183\n",
            "---------------\n",
            "Processing epoch: 1245 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3018731363117695\n",
            "Training loss:  \t 0.28284921012818814\n",
            "---------------\n",
            "Processing epoch: 1246 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2720196917653084\n",
            "Training loss:  \t 0.2714015770703554\n",
            "---------------\n",
            "Processing epoch: 1247 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3027195371687412\n",
            "Training loss:  \t 0.26922500170767305\n",
            "---------------\n",
            "Processing epoch: 1248 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2795392945408821\n",
            "Training loss:  \t 0.26939714662730696\n",
            "---------------\n",
            "Processing epoch: 1249 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29238079860806465\n",
            "Training loss:  \t 0.2764949344098568\n",
            "---------------\n",
            "Processing epoch: 1250 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2656138949096203\n",
            "Training loss:  \t 0.2691827919334173\n",
            "---------------\n",
            "Processing epoch: 1251 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30780841410160065\n",
            "Training loss:  \t 0.28422084227204325\n",
            "---------------\n",
            "Processing epoch: 1252 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27570150420069695\n",
            "Training loss:  \t 0.2703986048698425\n",
            "---------------\n",
            "Processing epoch: 1253 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3614259921014309\n",
            "Training loss:  \t 0.29148959666490554\n",
            "---------------\n",
            "Processing epoch: 1254 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36045584827661514\n",
            "Training loss:  \t 0.3147650957107544\n",
            "---------------\n",
            "Processing epoch: 1255 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26780031621456146\n",
            "Training loss:  \t 0.2805717807263136\n",
            "---------------\n",
            "Processing epoch: 1256 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36517810821533203\n",
            "Training loss:  \t 0.2708240427076817\n",
            "---------------\n",
            "Processing epoch: 1257 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3652123473584652\n",
            "Training loss:  \t 0.32454621940851214\n",
            "---------------\n",
            "Processing epoch: 1258 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28045768290758133\n",
            "Training loss:  \t 0.2893920872360468\n",
            "---------------\n",
            "Processing epoch: 1259 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36704570800065994\n",
            "Training loss:  \t 0.2988698910921812\n",
            "---------------\n",
            "Processing epoch: 1260 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3726828470826149\n",
            "Training loss:  \t 0.3266181744635105\n",
            "---------------\n",
            "Processing epoch: 1261 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3417212441563606\n",
            "Training loss:  \t 0.31053186431527136\n",
            "---------------\n",
            "Processing epoch: 1262 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26972604915499687\n",
            "Training loss:  \t 0.2766679022461176\n",
            "---------------\n",
            "Processing epoch: 1263 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30313780158758163\n",
            "Training loss:  \t 0.2773643184453249\n",
            "---------------\n",
            "Processing epoch: 1264 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2689378671348095\n",
            "Training loss:  \t 0.2697886470705271\n",
            "---------------\n",
            "Processing epoch: 1265 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2683933861553669\n",
            "Training loss:  \t 0.2714738085865974\n",
            "---------------\n",
            "Processing epoch: 1266 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2674790062010288\n",
            "Training loss:  \t 0.2776719406247139\n",
            "---------------\n",
            "Processing epoch: 1267 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37513014674186707\n",
            "Training loss:  \t 0.46109587103128435\n",
            "---------------\n",
            "Processing epoch: 1268 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37367529422044754\n",
            "Training loss:  \t 0.36652159616351127\n",
            "---------------\n",
            "Processing epoch: 1269 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36835236102342606\n",
            "Training loss:  \t 0.3316569462418556\n",
            "---------------\n",
            "Processing epoch: 1270 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32571320980787277\n",
            "Training loss:  \t 0.29873578548431395\n",
            "---------------\n",
            "Processing epoch: 1271 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3294569328427315\n",
            "Training loss:  \t 0.27728764414787294\n",
            "---------------\n",
            "Processing epoch: 1272 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2896842584013939\n",
            "Training loss:  \t 0.2812033247202635\n",
            "---------------\n",
            "Processing epoch: 1273 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.7500386834144592\n",
            "Training loss:  \t 0.3324362188577652\n",
            "---------------\n",
            "Processing epoch: 1274 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.390846349298954\n",
            "Training loss:  \t 0.5065327472984791\n",
            "---------------\n",
            "Processing epoch: 1275 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38548102229833603\n",
            "Training loss:  \t 0.4333686508238316\n",
            "---------------\n",
            "Processing epoch: 1276 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37431421875953674\n",
            "Training loss:  \t 0.4178187049925327\n",
            "---------------\n",
            "Processing epoch: 1277 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3663598373532295\n",
            "Training loss:  \t 0.400953534245491\n",
            "---------------\n",
            "Processing epoch: 1278 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36752209067344666\n",
            "Training loss:  \t 0.3821333087980747\n",
            "---------------\n",
            "Processing epoch: 1279 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36157434433698654\n",
            "Training loss:  \t 0.35903414860367777\n",
            "---------------\n",
            "Processing epoch: 1280 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36428364366292953\n",
            "Training loss:  \t 0.33771923556923866\n",
            "---------------\n",
            "Processing epoch: 1281 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3576790280640125\n",
            "Training loss:  \t 0.31891346648335456\n",
            "---------------\n",
            "Processing epoch: 1282 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3214852511882782\n",
            "Training loss:  \t 0.30500567629933356\n",
            "---------------\n",
            "Processing epoch: 1283 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3041236400604248\n",
            "Training loss:  \t 0.2811209950596094\n",
            "---------------\n",
            "Processing epoch: 1284 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3000158593058586\n",
            "Training loss:  \t 0.2753093756735325\n",
            "---------------\n",
            "Processing epoch: 1285 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30054453760385513\n",
            "Training loss:  \t 0.2735249102115631\n",
            "---------------\n",
            "Processing epoch: 1286 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2819679491221905\n",
            "Training loss:  \t 0.27174752205610275\n",
            "---------------\n",
            "Processing epoch: 1287 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3786570504307747\n",
            "Training loss:  \t 0.3289991572499275\n",
            "---------------\n",
            "Processing epoch: 1288 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39460939168930054\n",
            "Training loss:  \t 0.42955407947301866\n",
            "---------------\n",
            "Processing epoch: 1289 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38125937804579735\n",
            "Training loss:  \t 0.43300498388707637\n",
            "---------------\n",
            "Processing epoch: 1290 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3814238831400871\n",
            "Training loss:  \t 0.4190917208790779\n",
            "---------------\n",
            "Processing epoch: 1291 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36254557967185974\n",
            "Training loss:  \t 0.4089077390730381\n",
            "---------------\n",
            "Processing epoch: 1292 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36243654787540436\n",
            "Training loss:  \t 0.3977597773075104\n",
            "---------------\n",
            "Processing epoch: 1293 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3663325682282448\n",
            "Training loss:  \t 0.3859746687114239\n",
            "---------------\n",
            "Processing epoch: 1294 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3607948385179043\n",
            "Training loss:  \t 0.3764506347477436\n",
            "---------------\n",
            "Processing epoch: 1295 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35732039995491505\n",
            "Training loss:  \t 0.3662439562380314\n",
            "---------------\n",
            "Processing epoch: 1296 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3607748709619045\n",
            "Training loss:  \t 0.360953102260828\n",
            "---------------\n",
            "Processing epoch: 1297 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35789812728762627\n",
            "Training loss:  \t 0.34581355154514315\n",
            "---------------\n",
            "Processing epoch: 1298 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3597523868083954\n",
            "Training loss:  \t 0.3375751435756683\n",
            "---------------\n",
            "Processing epoch: 1299 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3599012978374958\n",
            "Training loss:  \t 0.33043653666973116\n",
            "---------------\n",
            "Processing epoch: 1300 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36105818673968315\n",
            "Training loss:  \t 0.3242641545832157\n",
            "---------------\n",
            "Processing epoch: 1301 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36334479227662086\n",
            "Training loss:  \t 0.3193101927638054\n",
            "---------------\n",
            "Processing epoch: 1302 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36147382110357285\n",
            "Training loss:  \t 0.3152802404016256\n",
            "---------------\n",
            "Processing epoch: 1303 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35453731566667557\n",
            "Training loss:  \t 0.3063149370253086\n",
            "---------------\n",
            "Processing epoch: 1304 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3406253233551979\n",
            "Training loss:  \t 0.29432643949985504\n",
            "---------------\n",
            "Processing epoch: 1305 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33201954513788223\n",
            "Training loss:  \t 0.28508400693535807\n",
            "---------------\n",
            "Processing epoch: 1306 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31269513443112373\n",
            "Training loss:  \t 0.28820371702313424\n",
            "---------------\n",
            "Processing epoch: 1307 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3204357698559761\n",
            "Training loss:  \t 0.28341583125293257\n",
            "---------------\n",
            "Processing epoch: 1308 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.300552811473608\n",
            "Training loss:  \t 0.2772368971258402\n",
            "---------------\n",
            "Processing epoch: 1309 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2956138290464878\n",
            "Training loss:  \t 0.28087173625826833\n",
            "---------------\n",
            "Processing epoch: 1310 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2818235717713833\n",
            "Training loss:  \t 0.2793982870876789\n",
            "---------------\n",
            "Processing epoch: 1311 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2869481183588505\n",
            "Training loss:  \t 0.2747499566525221\n",
            "---------------\n",
            "Processing epoch: 1312 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3077322319149971\n",
            "Training loss:  \t 0.27010841146111486\n",
            "---------------\n",
            "Processing epoch: 1313 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30044572055339813\n",
            "Training loss:  \t 0.27804579623043535\n",
            "---------------\n",
            "Processing epoch: 1314 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3167864568531513\n",
            "Training loss:  \t 0.2847126018255949\n",
            "---------------\n",
            "Processing epoch: 1315 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2726670615375042\n",
            "Training loss:  \t 0.26816622726619244\n",
            "---------------\n",
            "Processing epoch: 1316 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37092970311641693\n",
            "Training loss:  \t 0.3053127802908421\n",
            "---------------\n",
            "Processing epoch: 1317 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37502339109778404\n",
            "Training loss:  \t 0.3357929728925228\n",
            "---------------\n",
            "Processing epoch: 1318 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3612239733338356\n",
            "Training loss:  \t 0.3177878774702549\n",
            "---------------\n",
            "Processing epoch: 1319 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3078153319656849\n",
            "Training loss:  \t 0.2896879531443119\n",
            "---------------\n",
            "Processing epoch: 1320 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3062761016190052\n",
            "Training loss:  \t 0.2794335030019283\n",
            "---------------\n",
            "Processing epoch: 1321 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29881153628230095\n",
            "Training loss:  \t 0.27245517931878566\n",
            "---------------\n",
            "Processing epoch: 1322 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27617717906832695\n",
            "Training loss:  \t 0.2695876233279705\n",
            "---------------\n",
            "Processing epoch: 1323 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2783234342932701\n",
            "Training loss:  \t 0.2679380778223276\n",
            "---------------\n",
            "Processing epoch: 1324 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3574438542127609\n",
            "Training loss:  \t 0.3844770811498165\n",
            "---------------\n",
            "Processing epoch: 1325 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37309105694293976\n",
            "Training loss:  \t 0.35554384663701055\n",
            "---------------\n",
            "Processing epoch: 1326 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36942683905363083\n",
            "Training loss:  \t 0.3379883036017418\n",
            "---------------\n",
            "Processing epoch: 1327 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33401504158973694\n",
            "Training loss:  \t 0.30707116574049\n",
            "---------------\n",
            "Processing epoch: 1328 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3090384565293789\n",
            "Training loss:  \t 0.2796997852623463\n",
            "---------------\n",
            "Processing epoch: 1329 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2803886905312538\n",
            "Training loss:  \t 0.2733153574168682\n",
            "---------------\n",
            "Processing epoch: 1330 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2755264975130558\n",
            "Training loss:  \t 0.26831003427505495\n",
            "---------------\n",
            "Processing epoch: 1331 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27988849207758904\n",
            "Training loss:  \t 0.26811146214604376\n",
            "---------------\n",
            "Processing epoch: 1332 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.286133348941803\n",
            "Training loss:  \t 0.2678242985159159\n",
            "---------------\n",
            "Processing epoch: 1333 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26623696461319923\n",
            "Training loss:  \t 0.2650433529168367\n",
            "---------------\n",
            "Processing epoch: 1334 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3444163240492344\n",
            "Training loss:  \t 0.2818321716040373\n",
            "---------------\n",
            "Processing epoch: 1335 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28141340985894203\n",
            "Training loss:  \t 0.2745890714228153\n",
            "---------------\n",
            "Processing epoch: 1336 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3784879222512245\n",
            "Training loss:  \t 0.37595971003174783\n",
            "---------------\n",
            "Processing epoch: 1337 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37636401131749153\n",
            "Training loss:  \t 0.4056698508560658\n",
            "---------------\n",
            "Processing epoch: 1338 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3691679574549198\n",
            "Training loss:  \t 0.4018197305500507\n",
            "---------------\n",
            "Processing epoch: 1339 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36614973098039627\n",
            "Training loss:  \t 0.3758603289723396\n",
            "---------------\n",
            "Processing epoch: 1340 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.362799022346735\n",
            "Training loss:  \t 0.3577405199408531\n",
            "---------------\n",
            "Processing epoch: 1341 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3590245433151722\n",
            "Training loss:  \t 0.34294487461447715\n",
            "---------------\n",
            "Processing epoch: 1342 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36055392026901245\n",
            "Training loss:  \t 0.3282927442342043\n",
            "---------------\n",
            "Processing epoch: 1343 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3658183813095093\n",
            "Training loss:  \t 0.3202934093773365\n",
            "---------------\n",
            "Processing epoch: 1344 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3573535308241844\n",
            "Training loss:  \t 0.31393732577562333\n",
            "---------------\n",
            "Processing epoch: 1345 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.349559061229229\n",
            "Training loss:  \t 0.29452139139175415\n",
            "---------------\n",
            "Processing epoch: 1346 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3240204304456711\n",
            "Training loss:  \t 0.2877946518361568\n",
            "---------------\n",
            "Processing epoch: 1347 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3219384029507637\n",
            "Training loss:  \t 0.2769976302981377\n",
            "---------------\n",
            "Processing epoch: 1348 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2801377400755882\n",
            "Training loss:  \t 0.2746964059770107\n",
            "---------------\n",
            "Processing epoch: 1349 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30942462757229805\n",
            "Training loss:  \t 0.27566512785851954\n",
            "---------------\n",
            "Processing epoch: 1350 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28632182255387306\n",
            "Training loss:  \t 0.2709909662604332\n",
            "---------------\n",
            "Processing epoch: 1351 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27028364688158035\n",
            "Training loss:  \t 0.2727174572646618\n",
            "---------------\n",
            "Processing epoch: 1352 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3157265894114971\n",
            "Training loss:  \t 0.2685637004673481\n",
            "---------------\n",
            "Processing epoch: 1353 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2892608530819416\n",
            "Training loss:  \t 0.2688339170068502\n",
            "---------------\n",
            "Processing epoch: 1354 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26711321622133255\n",
            "Training loss:  \t 0.2667630709707737\n",
            "---------------\n",
            "Processing epoch: 1355 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37185925617814064\n",
            "Training loss:  \t 0.2871354930102825\n",
            "---------------\n",
            "Processing epoch: 1356 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3761999271810055\n",
            "Training loss:  \t 0.3290332414209843\n",
            "---------------\n",
            "Processing epoch: 1357 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.34527451917529106\n",
            "Training loss:  \t 0.3102438680827618\n",
            "---------------\n",
            "Processing epoch: 1358 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2791906073689461\n",
            "Training loss:  \t 0.26906202286481856\n",
            "---------------\n",
            "Processing epoch: 1359 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.388323150575161\n",
            "Training loss:  \t 0.36116338670253756\n",
            "---------------\n",
            "Processing epoch: 1360 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39645887538790703\n",
            "Training loss:  \t 0.43289635293185713\n",
            "---------------\n",
            "Processing epoch: 1361 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37776193767786026\n",
            "Training loss:  \t 0.4252511836588383\n",
            "---------------\n",
            "Processing epoch: 1362 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.369793426245451\n",
            "Training loss:  \t 0.4173457928001881\n",
            "---------------\n",
            "Processing epoch: 1363 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36557955853641033\n",
            "Training loss:  \t 0.39925289899110794\n",
            "---------------\n",
            "Processing epoch: 1364 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3625146374106407\n",
            "Training loss:  \t 0.3624054238200188\n",
            "---------------\n",
            "Processing epoch: 1365 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3577119819819927\n",
            "Training loss:  \t 0.334241533651948\n",
            "---------------\n",
            "Processing epoch: 1366 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3599729724228382\n",
            "Training loss:  \t 0.31593756899237635\n",
            "---------------\n",
            "Processing epoch: 1367 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35915112495422363\n",
            "Training loss:  \t 0.3152069978415966\n",
            "---------------\n",
            "Processing epoch: 1368 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3452064171433449\n",
            "Training loss:  \t 0.301098420470953\n",
            "---------------\n",
            "Processing epoch: 1369 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2848878614604473\n",
            "Training loss:  \t 0.30066876783967017\n",
            "---------------\n",
            "Processing epoch: 1370 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33172592148184776\n",
            "Training loss:  \t 0.2767714448273182\n",
            "---------------\n",
            "Processing epoch: 1371 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.279169712215662\n",
            "Training loss:  \t 0.2781669359654188\n",
            "---------------\n",
            "Processing epoch: 1372 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32224860042333603\n",
            "Training loss:  \t 0.2671773426234722\n",
            "---------------\n",
            "Processing epoch: 1373 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29468077048659325\n",
            "Training loss:  \t 0.272929010540247\n",
            "---------------\n",
            "Processing epoch: 1374 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27633777633309364\n",
            "Training loss:  \t 0.27085862271487715\n",
            "---------------\n",
            "Processing epoch: 1375 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28427116945385933\n",
            "Training loss:  \t 0.2737879004329443\n",
            "---------------\n",
            "Processing epoch: 1376 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28315695375204086\n",
            "Training loss:  \t 0.2679644703865051\n",
            "---------------\n",
            "Processing epoch: 1377 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27412399277091026\n",
            "Training loss:  \t 0.26609297208487986\n",
            "---------------\n",
            "Processing epoch: 1378 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2912479266524315\n",
            "Training loss:  \t 0.26416553035378454\n",
            "---------------\n",
            "Processing epoch: 1379 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27845216915011406\n",
            "Training loss:  \t 0.2645369220525026\n",
            "---------------\n",
            "Processing epoch: 1380 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35091356933116913\n",
            "Training loss:  \t 0.27697446905076506\n",
            "---------------\n",
            "Processing epoch: 1381 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2836115453392267\n",
            "Training loss:  \t 0.29287678487598895\n",
            "---------------\n",
            "Processing epoch: 1382 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2944576255977154\n",
            "Training loss:  \t 0.2640715904533863\n",
            "---------------\n",
            "Processing epoch: 1383 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3927943930029869\n",
            "Training loss:  \t 0.2594991371035576\n",
            "---------------\n",
            "Processing epoch: 1384 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3207719996571541\n",
            "Training loss:  \t 0.3047563448548317\n",
            "---------------\n",
            "Processing epoch: 1385 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3646754138171673\n",
            "Training loss:  \t 0.33058963492512705\n",
            "---------------\n",
            "Processing epoch: 1386 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3719794824719429\n",
            "Training loss:  \t 0.3268347106873989\n",
            "---------------\n",
            "Processing epoch: 1387 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3340650238096714\n",
            "Training loss:  \t 0.30728313252329825\n",
            "---------------\n",
            "Processing epoch: 1388 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27235399186611176\n",
            "Training loss:  \t 0.2657410569489002\n",
            "---------------\n",
            "Processing epoch: 1389 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3618527576327324\n",
            "Training loss:  \t 0.2797481507062912\n",
            "---------------\n",
            "Processing epoch: 1390 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3015068471431732\n",
            "Training loss:  \t 0.28246711418032644\n",
            "---------------\n",
            "Processing epoch: 1391 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27860385924577713\n",
            "Training loss:  \t 0.26262767165899276\n",
            "---------------\n",
            "Processing epoch: 1392 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2760654389858246\n",
            "Training loss:  \t 0.2643728394061327\n",
            "---------------\n",
            "Processing epoch: 1393 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2727018818259239\n",
            "Training loss:  \t 0.2631187930703163\n",
            "---------------\n",
            "Processing epoch: 1394 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3808663785457611\n",
            "Training loss:  \t 0.347263054177165\n",
            "---------------\n",
            "Processing epoch: 1395 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38184426352381706\n",
            "Training loss:  \t 0.4186849448829889\n",
            "---------------\n",
            "Processing epoch: 1396 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3666048124432564\n",
            "Training loss:  \t 0.40004215054214\n",
            "---------------\n",
            "Processing epoch: 1397 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36601681262254715\n",
            "Training loss:  \t 0.3816422238945961\n",
            "---------------\n",
            "Processing epoch: 1398 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35799749195575714\n",
            "Training loss:  \t 0.3588853389024734\n",
            "---------------\n",
            "Processing epoch: 1399 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3562645874917507\n",
            "Training loss:  \t 0.345067822188139\n",
            "---------------\n",
            "Processing epoch: 1400 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36024877056479454\n",
            "Training loss:  \t 0.32691129557788373\n",
            "---------------\n",
            "Processing epoch: 1401 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3589427173137665\n",
            "Training loss:  \t 0.31957288905978204\n",
            "---------------\n",
            "Processing epoch: 1402 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36124198883771896\n",
            "Training loss:  \t 0.3126441605389118\n",
            "---------------\n",
            "Processing epoch: 1403 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3618294857442379\n",
            "Training loss:  \t 0.302947149425745\n",
            "---------------\n",
            "Processing epoch: 1404 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32906073331832886\n",
            "Training loss:  \t 0.28440272323787213\n",
            "---------------\n",
            "Processing epoch: 1405 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32240827195346355\n",
            "Training loss:  \t 0.2767432279884815\n",
            "---------------\n",
            "Processing epoch: 1406 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.32649746537208557\n",
            "Training loss:  \t 0.27417191453278067\n",
            "---------------\n",
            "Processing epoch: 1407 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2906927913427353\n",
            "Training loss:  \t 0.268906208127737\n",
            "---------------\n",
            "Processing epoch: 1408 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30558764934539795\n",
            "Training loss:  \t 0.2740656815469265\n",
            "---------------\n",
            "Processing epoch: 1409 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.285406019538641\n",
            "Training loss:  \t 0.26789023652672767\n",
            "---------------\n",
            "Processing epoch: 1410 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2931041717529297\n",
            "Training loss:  \t 0.2641050390899181\n",
            "---------------\n",
            "Processing epoch: 1411 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28430748358368874\n",
            "Training loss:  \t 0.2625364948064089\n",
            "---------------\n",
            "Processing epoch: 1412 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37555666267871857\n",
            "Training loss:  \t 0.32134874537587166\n",
            "---------------\n",
            "Processing epoch: 1413 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37282848358154297\n",
            "Training loss:  \t 0.3460684232413769\n",
            "---------------\n",
            "Processing epoch: 1414 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3671928942203522\n",
            "Training loss:  \t 0.31653193198144436\n",
            "---------------\n",
            "Processing epoch: 1415 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36197174340486526\n",
            "Training loss:  \t 0.30855937860906124\n",
            "---------------\n",
            "Processing epoch: 1416 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3250275142490864\n",
            "Training loss:  \t 0.28883527889847754\n",
            "---------------\n",
            "Processing epoch: 1417 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30823091976344585\n",
            "Training loss:  \t 0.2763495668768883\n",
            "---------------\n",
            "Processing epoch: 1418 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3158007711172104\n",
            "Training loss:  \t 0.26744081303477285\n",
            "---------------\n",
            "Processing epoch: 1419 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3060809187591076\n",
            "Training loss:  \t 0.27188353091478346\n",
            "---------------\n",
            "Processing epoch: 1420 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28191774152219296\n",
            "Training loss:  \t 0.2764109894633293\n",
            "---------------\n",
            "Processing epoch: 1421 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27131226286292076\n",
            "Training loss:  \t 0.2660452276468277\n",
            "---------------\n",
            "Processing epoch: 1422 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3241119608283043\n",
            "Training loss:  \t 0.2609831500798464\n",
            "---------------\n",
            "Processing epoch: 1423 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2823844291269779\n",
            "Training loss:  \t 0.2671678751707077\n",
            "---------------\n",
            "Processing epoch: 1424 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.272395845502615\n",
            "Training loss:  \t 0.2620676845312119\n",
            "---------------\n",
            "Processing epoch: 1425 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2900368794798851\n",
            "Training loss:  \t 0.26903645396232606\n",
            "---------------\n",
            "Processing epoch: 1426 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3656959105283022\n",
            "Training loss:  \t 0.2652238003909588\n",
            "---------------\n",
            "Processing epoch: 1427 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3077867850661278\n",
            "Training loss:  \t 0.28461006581783294\n",
            "---------------\n",
            "Processing epoch: 1428 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3493278734385967\n",
            "Training loss:  \t 0.28079173117876055\n",
            "---------------\n",
            "Processing epoch: 1429 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3782166615128517\n",
            "Training loss:  \t 0.3321560017764568\n",
            "---------------\n",
            "Processing epoch: 1430 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37191368266940117\n",
            "Training loss:  \t 0.32218458503484726\n",
            "---------------\n",
            "Processing epoch: 1431 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35239482671022415\n",
            "Training loss:  \t 0.29860500544309615\n",
            "---------------\n",
            "Processing epoch: 1432 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2754211835563183\n",
            "Training loss:  \t 0.26486263163387774\n",
            "---------------\n",
            "Processing epoch: 1433 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.329117089509964\n",
            "Training loss:  \t 0.2682170242071152\n",
            "---------------\n",
            "Processing epoch: 1434 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29596447199583054\n",
            "Training loss:  \t 0.26930939182639124\n",
            "---------------\n",
            "Processing epoch: 1435 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2756662219762802\n",
            "Training loss:  \t 0.2682629156857729\n",
            "---------------\n",
            "Processing epoch: 1436 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3279178626835346\n",
            "Training loss:  \t 0.2631507307291031\n",
            "---------------\n",
            "Processing epoch: 1437 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6229831427335739\n",
            "Training loss:  \t 0.27426554299890993\n",
            "---------------\n",
            "Processing epoch: 1438 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37727533280849457\n",
            "Training loss:  \t 0.32492115795612336\n",
            "---------------\n",
            "Processing epoch: 1439 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3731697350740433\n",
            "Training loss:  \t 0.3272303488105536\n",
            "---------------\n",
            "Processing epoch: 1440 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.35332016274333\n",
            "Training loss:  \t 0.30022545382380483\n",
            "---------------\n",
            "Processing epoch: 1441 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29205161705613136\n",
            "Training loss:  \t 0.2697935219854116\n",
            "---------------\n",
            "Processing epoch: 1442 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27233050018548965\n",
            "Training loss:  \t 0.2676977217197418\n",
            "---------------\n",
            "Processing epoch: 1443 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3271375447511673\n",
            "Training loss:  \t 0.2781714215874672\n",
            "---------------\n",
            "Processing epoch: 1444 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3176049627363682\n",
            "Training loss:  \t 0.26743717975914477\n",
            "---------------\n",
            "Processing epoch: 1445 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3699842244386673\n",
            "Training loss:  \t 0.29941320717334746\n",
            "---------------\n",
            "Processing epoch: 1446 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33056820929050446\n",
            "Training loss:  \t 0.29549959525465963\n",
            "---------------\n",
            "Processing epoch: 1447 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2712284214794636\n",
            "Training loss:  \t 0.26228866428136827\n",
            "---------------\n",
            "Processing epoch: 1448 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37173259258270264\n",
            "Training loss:  \t 0.27863231375813485\n",
            "---------------\n",
            "Processing epoch: 1449 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3670196458697319\n",
            "Training loss:  \t 0.30754957124590876\n",
            "---------------\n",
            "Processing epoch: 1450 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30127831920981407\n",
            "Training loss:  \t 0.2699057821184397\n",
            "---------------\n",
            "Processing epoch: 1451 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.33872826769948006\n",
            "Training loss:  \t 0.26655296348035334\n",
            "---------------\n",
            "Processing epoch: 1452 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.31073054671287537\n",
            "Training loss:  \t 0.2666136801242828\n",
            "---------------\n",
            "Processing epoch: 1453 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2815885581076145\n",
            "Training loss:  \t 0.27157271951436995\n",
            "---------------\n",
            "Processing epoch: 1454 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36781150847673416\n",
            "Training loss:  \t 0.2901895694434643\n",
            "---------------\n",
            "Processing epoch: 1455 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2743544280529022\n",
            "Training loss:  \t 0.26228668391704557\n",
            "---------------\n",
            "Processing epoch: 1456 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.29727019742131233\n",
            "Training loss:  \t 0.26900784522294996\n",
            "---------------\n",
            "Processing epoch: 1457 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2874540314078331\n",
            "Training loss:  \t 0.2563828568905592\n",
            "---------------\n",
            "Processing epoch: 1458 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2654474079608917\n",
            "Training loss:  \t 0.25653963908553123\n",
            "---------------\n",
            "Processing epoch: 1459 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27813986502587795\n",
            "Training loss:  \t 0.2583793070167303\n",
            "---------------\n",
            "Processing epoch: 1460 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28941820189356804\n",
            "Training loss:  \t 0.25096614807844164\n",
            "---------------\n",
            "Processing epoch: 1461 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3544978555291891\n",
            "Training loss:  \t 0.26946743540465834\n",
            "---------------\n",
            "Processing epoch: 1462 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26961323246359825\n",
            "Training loss:  \t 0.2602542031556368\n",
            "---------------\n",
            "Processing epoch: 1463 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3165198005735874\n",
            "Training loss:  \t 0.25501935593783853\n",
            "---------------\n",
            "Processing epoch: 1464 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27104030549526215\n",
            "Training loss:  \t 0.2571375980973244\n",
            "---------------\n",
            "Processing epoch: 1465 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.307420339435339\n",
            "Training loss:  \t 0.253252112865448\n",
            "---------------\n",
            "Processing epoch: 1466 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.281396996229887\n",
            "Training loss:  \t 0.2672831568866968\n",
            "---------------\n",
            "Processing epoch: 1467 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3006378151476383\n",
            "Training loss:  \t 0.2660871155560017\n",
            "---------------\n",
            "Processing epoch: 1468 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.38825978338718414\n",
            "Training loss:  \t 0.2979638636112213\n",
            "---------------\n",
            "Processing epoch: 1469 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.39343588799238205\n",
            "Training loss:  \t 0.4108275264501572\n",
            "---------------\n",
            "Processing epoch: 1470 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.380607545375824\n",
            "Training loss:  \t 0.42366042360663414\n",
            "---------------\n",
            "Processing epoch: 1471 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.37388935685157776\n",
            "Training loss:  \t 0.40767921395599843\n",
            "---------------\n",
            "Processing epoch: 1472 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3671023100614548\n",
            "Training loss:  \t 0.39265634790062903\n",
            "---------------\n",
            "Processing epoch: 1473 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3667023964226246\n",
            "Training loss:  \t 0.3708378106355667\n",
            "---------------\n",
            "Processing epoch: 1474 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36072883009910583\n",
            "Training loss:  \t 0.34940573051571844\n",
            "---------------\n",
            "Processing epoch: 1475 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3619983159005642\n",
            "Training loss:  \t 0.33763597197830675\n",
            "---------------\n",
            "Processing epoch: 1476 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3637813851237297\n",
            "Training loss:  \t 0.3211502365767956\n",
            "---------------\n",
            "Processing epoch: 1477 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.360941756516695\n",
            "Training loss:  \t 0.3150241494178772\n",
            "---------------\n",
            "Processing epoch: 1478 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.36271319538354874\n",
            "Training loss:  \t 0.3103539295494556\n",
            "---------------\n",
            "Processing epoch: 1479 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.340229831635952\n",
            "Training loss:  \t 0.28476853147149084\n",
            "---------------\n",
            "Processing epoch: 1480 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3103388361632824\n",
            "Training loss:  \t 0.2725846689194441\n",
            "---------------\n",
            "Processing epoch: 1481 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3261248767375946\n",
            "Training loss:  \t 0.26886345595121386\n",
            "---------------\n",
            "Processing epoch: 1482 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27942491322755814\n",
            "Training loss:  \t 0.25957589522004126\n",
            "---------------\n",
            "Processing epoch: 1483 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2819844260811806\n",
            "Training loss:  \t 0.2595398396253586\n",
            "---------------\n",
            "Processing epoch: 1484 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2732740603387356\n",
            "Training loss:  \t 0.25684865452349187\n",
            "---------------\n",
            "Processing epoch: 1485 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3104714900255203\n",
            "Training loss:  \t 0.25734779946506026\n",
            "---------------\n",
            "Processing epoch: 1486 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3818601742386818\n",
            "Training loss:  \t 0.2911912094801664\n",
            "---------------\n",
            "Processing epoch: 1487 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3804352506995201\n",
            "Training loss:  \t 0.33066344261169434\n",
            "---------------\n",
            "Processing epoch: 1488 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3647041395306587\n",
            "Training loss:  \t 0.30115645453333856\n",
            "---------------\n",
            "Processing epoch: 1489 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3130759075284004\n",
            "Training loss:  \t 0.28132856339216233\n",
            "---------------\n",
            "Processing epoch: 1490 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.30092641338706017\n",
            "Training loss:  \t 0.2644518814980984\n",
            "---------------\n",
            "Processing epoch: 1491 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.28941943123936653\n",
            "Training loss:  \t 0.26169020906090734\n",
            "---------------\n",
            "Processing epoch: 1492 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2726366203278303\n",
            "Training loss:  \t 0.2571335032582283\n",
            "---------------\n",
            "Processing epoch: 1493 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2819817438721657\n",
            "Training loss:  \t 0.25470897778868673\n",
            "---------------\n",
            "Processing epoch: 1494 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3470376171171665\n",
            "Training loss:  \t 0.26106500029563906\n",
            "---------------\n",
            "Processing epoch: 1495 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.2861531153321266\n",
            "Training loss:  \t 0.2729436796158552\n",
            "---------------\n",
            "Processing epoch: 1496 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.27745257690548897\n",
            "Training loss:  \t 0.255746454000473\n",
            "---------------\n",
            "Processing epoch: 1497 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.26571242697536945\n",
            "Training loss:  \t 0.2573623687028885\n",
            "---------------\n",
            "Processing epoch: 1498 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3871750980615616\n",
            "Training loss:  \t 0.3296340569853783\n",
            "---------------\n",
            "Processing epoch: 1499 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3750796280801296\n",
            "Training loss:  \t 0.3328956436365843\n",
            "---------------\n",
            "Processing epoch: 1500 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.3689407929778099\n",
            "Training loss:  \t 0.31224341951310636\n",
            "---------------\n",
            "Processing epoch: 1 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.7656012028455734\n",
            "Training loss:  \t 0.7920181721448898\n",
            "---------------\n",
            "Processing epoch: 2 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.7573098689317703\n",
            "Training loss:  \t 0.7820089817047119\n",
            "---------------\n",
            "Processing epoch: 3 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.7409259676933289\n",
            "Training loss:  \t 0.7725628167390823\n",
            "---------------\n",
            "Processing epoch: 4 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.7174432724714279\n",
            "Training loss:  \t 0.7526963979005814\n",
            "---------------\n",
            "Processing epoch: 5 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6953036934137344\n",
            "Training loss:  \t 0.7200556933879853\n",
            "---------------\n",
            "Processing epoch: 6 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.7037660628557205\n",
            "Training loss:  \t 0.711975771188736\n",
            "---------------\n",
            "Processing epoch: 7 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6982869803905487\n",
            "Training loss:  \t 0.7077567219734192\n",
            "---------------\n",
            "Processing epoch: 8 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6934339702129364\n",
            "Training loss:  \t 0.6999969333410263\n",
            "---------------\n",
            "Processing epoch: 9 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6913332045078278\n",
            "Training loss:  \t 0.6978675693273544\n",
            "---------------\n",
            "Processing epoch: 10 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6943925023078918\n",
            "Training loss:  \t 0.6983930021524429\n",
            "---------------\n",
            "Processing epoch: 11 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6929924041032791\n",
            "Training loss:  \t 0.6983523100614548\n",
            "---------------\n",
            "Processing epoch: 12 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6898861676454544\n",
            "Training loss:  \t 0.7062974452972413\n",
            "---------------\n",
            "Processing epoch: 13 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6893933117389679\n",
            "Training loss:  \t 0.6926999926567078\n",
            "---------------\n",
            "Processing epoch: 14 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6889359951019287\n",
            "Training loss:  \t 0.6982605665922165\n",
            "---------------\n",
            "Processing epoch: 15 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6880833208560944\n",
            "Training loss:  \t 0.6919337660074234\n",
            "---------------\n",
            "Processing epoch: 16 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6898126006126404\n",
            "Training loss:  \t 0.709855368733406\n",
            "---------------\n",
            "Processing epoch: 17 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6967988461256027\n",
            "Training loss:  \t 0.698713943362236\n",
            "---------------\n",
            "Processing epoch: 18 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6993115991353989\n",
            "Training loss:  \t 0.7051606506109238\n",
            "---------------\n",
            "Processing epoch: 19 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6972654461860657\n",
            "Training loss:  \t 0.7024876326322556\n",
            "---------------\n",
            "Processing epoch: 20 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6941375732421875\n",
            "Training loss:  \t 0.7008674174547196\n",
            "---------------\n",
            "Processing epoch: 21 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6911323070526123\n",
            "Training loss:  \t 0.698387286067009\n",
            "---------------\n",
            "Processing epoch: 22 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6907329708337784\n",
            "Training loss:  \t 0.703860467672348\n",
            "---------------\n",
            "Processing epoch: 23 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6945066004991531\n",
            "Training loss:  \t 0.6945284873247146\n",
            "---------------\n",
            "Processing epoch: 24 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6952044069766998\n",
            "Training loss:  \t 0.700573006272316\n",
            "---------------\n",
            "Processing epoch: 25 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6924187988042831\n",
            "Training loss:  \t 0.6978061199188232\n",
            "---------------\n",
            "Processing epoch: 26 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6896605938673019\n",
            "Training loss:  \t 0.6935489267110825\n",
            "---------------\n",
            "Processing epoch: 27 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6879890859127045\n",
            "Training loss:  \t 0.6896701484918595\n",
            "---------------\n",
            "Processing epoch: 28 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6886737197637558\n",
            "Training loss:  \t 0.6913953483104706\n",
            "---------------\n",
            "Processing epoch: 29 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6886834055185318\n",
            "Training loss:  \t 0.6920467972755432\n",
            "---------------\n",
            "Processing epoch: 30 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6877268701791763\n",
            "Training loss:  \t 0.6890591144561767\n",
            "---------------\n",
            "Processing epoch: 31 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6869068145751953\n",
            "Training loss:  \t 0.6948892712593079\n",
            "---------------\n",
            "Processing epoch: 32 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6895503848791122\n",
            "Training loss:  \t 0.6874020636081696\n",
            "---------------\n",
            "Processing epoch: 33 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6890742927789688\n",
            "Training loss:  \t 0.693139711022377\n",
            "---------------\n",
            "Processing epoch: 34 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.686735525727272\n",
            "Training loss:  \t 0.6887726783752441\n",
            "---------------\n",
            "Processing epoch: 35 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6858147084712982\n",
            "Training loss:  \t 0.6874255776405335\n",
            "---------------\n",
            "Processing epoch: 36 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6879435032606125\n",
            "Training loss:  \t 0.6897132277488709\n",
            "---------------\n",
            "Processing epoch: 37 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6857542842626572\n",
            "Training loss:  \t 0.688546484708786\n",
            "---------------\n",
            "Processing epoch: 38 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6864603012800217\n",
            "Training loss:  \t 0.6878552854061126\n",
            "---------------\n",
            "Processing epoch: 39 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6860631257295609\n",
            "Training loss:  \t 0.6883423179388046\n",
            "---------------\n",
            "Processing epoch: 40 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6846931129693985\n",
            "Training loss:  \t 0.6862653702497482\n",
            "---------------\n",
            "Processing epoch: 41 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6849144548177719\n",
            "Training loss:  \t 0.6860869228839874\n",
            "---------------\n",
            "Processing epoch: 42 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6864565461874008\n",
            "Training loss:  \t 0.6996761798858643\n",
            "---------------\n",
            "Processing epoch: 43 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6841959804296494\n",
            "Training loss:  \t 0.6931982159614563\n",
            "---------------\n",
            "Processing epoch: 44 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6878746151924133\n",
            "Training loss:  \t 0.6945170611143112\n",
            "---------------\n",
            "Processing epoch: 45 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6847997754812241\n",
            "Training loss:  \t 0.6882337152957916\n",
            "---------------\n",
            "Processing epoch: 46 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6839559376239777\n",
            "Training loss:  \t 0.6856724590063095\n",
            "---------------\n",
            "Processing epoch: 47 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6837219893932343\n",
            "Training loss:  \t 0.6854261368513107\n",
            "---------------\n",
            "Processing epoch: 48 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6837594211101532\n",
            "Training loss:  \t 0.684955021739006\n",
            "---------------\n",
            "Processing epoch: 49 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.68258336186409\n",
            "Training loss:  \t 0.6857248425483704\n",
            "---------------\n",
            "Processing epoch: 50 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6845117956399918\n",
            "Training loss:  \t 0.6893263697624207\n",
            "---------------\n",
            "Processing epoch: 51 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6846202164888382\n",
            "Training loss:  \t 0.6876552373170852\n",
            "---------------\n",
            "Processing epoch: 52 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6821182072162628\n",
            "Training loss:  \t 0.6834818005561829\n",
            "---------------\n",
            "Processing epoch: 53 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6854413151741028\n",
            "Training loss:  \t 0.695466622710228\n",
            "---------------\n",
            "Processing epoch: 54 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6826076656579971\n",
            "Training loss:  \t 0.6967151910066605\n",
            "---------------\n",
            "Processing epoch: 55 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6813265830278397\n",
            "Training loss:  \t 0.6917556434869766\n",
            "---------------\n",
            "Processing epoch: 56 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.685003250837326\n",
            "Training loss:  \t 0.686971464753151\n",
            "---------------\n",
            "Processing epoch: 57 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6836463212966919\n",
            "Training loss:  \t 0.6864489078521728\n",
            "---------------\n",
            "Processing epoch: 58 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6814425885677338\n",
            "Training loss:  \t 0.6821068167686463\n",
            "---------------\n",
            "Processing epoch: 59 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6826168149709702\n",
            "Training loss:  \t 0.6827353060245513\n",
            "---------------\n",
            "Processing epoch: 60 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.683999314904213\n",
            "Training loss:  \t 0.6873470813035965\n",
            "---------------\n",
            "Processing epoch: 61 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6835457980632782\n",
            "Training loss:  \t 0.6863527059555053\n",
            "---------------\n",
            "Processing epoch: 62 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6811865568161011\n",
            "Training loss:  \t 0.6829507648944855\n",
            "---------------\n",
            "Processing epoch: 63 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6798663884401321\n",
            "Training loss:  \t 0.6788807839155198\n",
            "---------------\n",
            "Processing epoch: 64 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6805491149425507\n",
            "Training loss:  \t 0.680799201130867\n",
            "---------------\n",
            "Processing epoch: 65 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6805619597434998\n",
            "Training loss:  \t 0.6825487554073334\n",
            "---------------\n",
            "Processing epoch: 66 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6795263290405273\n",
            "Training loss:  \t 0.6794665426015853\n",
            "---------------\n",
            "Processing epoch: 67 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6789287328720093\n",
            "Training loss:  \t 0.681899431347847\n",
            "---------------\n",
            "Processing epoch: 68 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6805318742990494\n",
            "Training loss:  \t 0.6800849825143814\n",
            "---------------\n",
            "Processing epoch: 69 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6791269332170486\n",
            "Training loss:  \t 0.680056044459343\n",
            "---------------\n",
            "Processing epoch: 70 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6815981715917587\n",
            "Training loss:  \t 0.6951235979795456\n",
            "---------------\n",
            "Processing epoch: 71 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6788636445999146\n",
            "Training loss:  \t 0.6904540419578552\n",
            "---------------\n",
            "Processing epoch: 72 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6782307922840118\n",
            "Training loss:  \t 0.6832217574119568\n",
            "---------------\n",
            "Processing epoch: 73 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6793921589851379\n",
            "Training loss:  \t 0.6805091708898544\n",
            "---------------\n",
            "Processing epoch: 74 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6775266528129578\n",
            "Training loss:  \t 0.6938772886991501\n",
            "---------------\n",
            "Processing epoch: 75 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6805864125490189\n",
            "Training loss:  \t 0.6809215277433396\n",
            "---------------\n",
            "Processing epoch: 76 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6800329685211182\n",
            "Training loss:  \t 0.6817837595939636\n",
            "---------------\n",
            "Processing epoch: 77 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6783354133367538\n",
            "Training loss:  \t 0.6785187989473342\n",
            "---------------\n",
            "Processing epoch: 78 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.677187979221344\n",
            "Training loss:  \t 0.6849223345518112\n",
            "---------------\n",
            "Processing epoch: 79 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6791619211435318\n",
            "Training loss:  \t 0.6786144763231278\n",
            "---------------\n",
            "Processing epoch: 80 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6779059320688248\n",
            "Training loss:  \t 0.6771554082632065\n",
            "---------------\n",
            "Processing epoch: 81 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6759331375360489\n",
            "Training loss:  \t 0.6807810574769974\n",
            "---------------\n",
            "Processing epoch: 82 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.677460253238678\n",
            "Training loss:  \t 0.6757756769657135\n",
            "---------------\n",
            "Processing epoch: 83 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6760173887014389\n",
            "Training loss:  \t 0.6752539277076721\n",
            "---------------\n",
            "Processing epoch: 84 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6748955249786377\n",
            "Training loss:  \t 0.6735995143651963\n",
            "---------------\n",
            "Processing epoch: 85 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6740526258945465\n",
            "Training loss:  \t 0.6785786718130111\n",
            "---------------\n",
            "Processing epoch: 86 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6740413010120392\n",
            "Training loss:  \t 0.6773307681083679\n",
            "---------------\n",
            "Processing epoch: 87 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6759867072105408\n",
            "Training loss:  \t 0.6742426991462708\n",
            "---------------\n",
            "Processing epoch: 88 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6744895130395889\n",
            "Training loss:  \t 0.6737657904624939\n",
            "---------------\n",
            "Processing epoch: 89 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6736463159322739\n",
            "Training loss:  \t 0.6803162515163421\n",
            "---------------\n",
            "Processing epoch: 90 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.676093265414238\n",
            "Training loss:  \t 0.6728754878044129\n",
            "---------------\n",
            "Processing epoch: 91 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6747937351465225\n",
            "Training loss:  \t 0.6725909292697907\n",
            "---------------\n",
            "Processing epoch: 92 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6738974899053574\n",
            "Training loss:  \t 0.6705967336893082\n",
            "---------------\n",
            "Processing epoch: 93 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6723343133926392\n",
            "Training loss:  \t 0.6753566294908524\n",
            "---------------\n",
            "Processing epoch: 94 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6732377111911774\n",
            "Training loss:  \t 0.6728164404630661\n",
            "---------------\n",
            "Processing epoch: 95 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6721299141645432\n",
            "Training loss:  \t 0.6692689776420593\n",
            "---------------\n",
            "Processing epoch: 96 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6723570227622986\n",
            "Training loss:  \t 0.6703431963920593\n",
            "---------------\n",
            "Processing epoch: 97 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6736981719732285\n",
            "Training loss:  \t 0.6701380342245102\n",
            "---------------\n",
            "Processing epoch: 98 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6718546599149704\n",
            "Training loss:  \t 0.6714089691638947\n",
            "---------------\n",
            "Processing epoch: 99 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6717285960912704\n",
            "Training loss:  \t 0.6693958520889283\n",
            "---------------\n",
            "Processing epoch: 100 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6725030243396759\n",
            "Training loss:  \t 0.670028230547905\n",
            "---------------\n",
            "Processing epoch: 101 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6703659296035767\n",
            "Training loss:  \t 0.6676886528730392\n",
            "---------------\n",
            "Processing epoch: 102 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6705260425806046\n",
            "Training loss:  \t 0.6664632946252823\n",
            "---------------\n",
            "Processing epoch: 103 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6711408942937851\n",
            "Training loss:  \t 0.6693106055259704\n",
            "---------------\n",
            "Processing epoch: 104 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6707935929298401\n",
            "Training loss:  \t 0.6678391873836518\n",
            "---------------\n",
            "Processing epoch: 105 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.669703796505928\n",
            "Training loss:  \t 0.6660142183303833\n",
            "---------------\n",
            "Processing epoch: 106 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6709199845790863\n",
            "Training loss:  \t 0.6695561856031418\n",
            "---------------\n",
            "Processing epoch: 107 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6699828505516052\n",
            "Training loss:  \t 0.6663060486316681\n",
            "---------------\n",
            "Processing epoch: 108 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6697629541158676\n",
            "Training loss:  \t 0.6646556288003922\n",
            "---------------\n",
            "Processing epoch: 109 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6679435223340988\n",
            "Training loss:  \t 0.6720077455043793\n",
            "---------------\n",
            "Processing epoch: 110 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6685658693313599\n",
            "Training loss:  \t 0.6637261122465133\n",
            "---------------\n",
            "Processing epoch: 111 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.668360248208046\n",
            "Training loss:  \t 0.6646648079156876\n",
            "---------------\n",
            "Processing epoch: 112 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6705632209777832\n",
            "Training loss:  \t 0.6664530754089355\n",
            "---------------\n",
            "Processing epoch: 113 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6685085147619247\n",
            "Training loss:  \t 0.6636193692684174\n",
            "---------------\n",
            "Processing epoch: 114 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6677150577306747\n",
            "Training loss:  \t 0.679448327422142\n",
            "---------------\n",
            "Processing epoch: 115 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.667366161942482\n",
            "Training loss:  \t 0.6702797442674637\n",
            "---------------\n",
            "Processing epoch: 116 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6724224984645844\n",
            "Training loss:  \t 0.6682144999504089\n",
            "---------------\n",
            "Processing epoch: 117 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6702709048986435\n",
            "Training loss:  \t 0.6677656501531601\n",
            "---------------\n",
            "Processing epoch: 118 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6672985553741455\n",
            "Training loss:  \t 0.6647335231304169\n",
            "---------------\n",
            "Processing epoch: 119 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6669327318668365\n",
            "Training loss:  \t 0.6609382629394531\n",
            "---------------\n",
            "Processing epoch: 120 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.666458860039711\n",
            "Training loss:  \t 0.6612773358821868\n",
            "---------------\n",
            "Processing epoch: 121 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6665122956037521\n",
            "Training loss:  \t 0.6619087517261505\n",
            "---------------\n",
            "Processing epoch: 122 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6660303771495819\n",
            "Training loss:  \t 0.6628489881753922\n",
            "---------------\n",
            "Processing epoch: 123 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6681871116161346\n",
            "Training loss:  \t 0.6674582481384277\n",
            "---------------\n",
            "Processing epoch: 124 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6657426208257675\n",
            "Training loss:  \t 0.659371018409729\n",
            "---------------\n",
            "Processing epoch: 125 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6648105531930923\n",
            "Training loss:  \t 0.6676873356103897\n",
            "---------------\n",
            "Processing epoch: 126 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6677922308444977\n",
            "Training loss:  \t 0.6677850842475891\n",
            "---------------\n",
            "Processing epoch: 127 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.668024867773056\n",
            "Training loss:  \t 0.6619817405939102\n",
            "---------------\n",
            "Processing epoch: 128 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6666771024465561\n",
            "Training loss:  \t 0.6593476235866547\n",
            "---------------\n",
            "Processing epoch: 129 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6653812229633331\n",
            "Training loss:  \t 0.6604410707950592\n",
            "---------------\n",
            "Processing epoch: 130 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6679062843322754\n",
            "Training loss:  \t 0.6620667546987533\n",
            "---------------\n",
            "Processing epoch: 131 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6662650406360626\n",
            "Training loss:  \t 0.6587093353271485\n",
            "---------------\n",
            "Processing epoch: 132 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6642089635133743\n",
            "Training loss:  \t 0.6626408100128174\n",
            "---------------\n",
            "Processing epoch: 133 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6631124913692474\n",
            "Training loss:  \t 0.6623530745506286\n",
            "---------------\n",
            "Processing epoch: 134 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6641668826341629\n",
            "Training loss:  \t 0.66217440366745\n",
            "---------------\n",
            "Processing epoch: 135 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6633220463991165\n",
            "Training loss:  \t 0.6572587460279464\n",
            "---------------\n",
            "Processing epoch: 136 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6648571938276291\n",
            "Training loss:  \t 0.6618592798709869\n",
            "---------------\n",
            "Processing epoch: 137 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6640327125787735\n",
            "Training loss:  \t 0.6562163829803467\n",
            "---------------\n",
            "Processing epoch: 138 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6640544384717941\n",
            "Training loss:  \t 0.6578467786312103\n",
            "---------------\n",
            "Processing epoch: 139 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6626381129026413\n",
            "Training loss:  \t 0.6556957215070724\n",
            "---------------\n",
            "Processing epoch: 140 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6642241030931473\n",
            "Training loss:  \t 0.655756139755249\n",
            "---------------\n",
            "Processing epoch: 141 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6614265292882919\n",
            "Training loss:  \t 0.6539228230714798\n",
            "---------------\n",
            "Processing epoch: 142 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.662806361913681\n",
            "Training loss:  \t 0.6548464924097062\n",
            "---------------\n",
            "Processing epoch: 143 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6622774451971054\n",
            "Training loss:  \t 0.6550794184207916\n",
            "---------------\n",
            "Processing epoch: 144 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6613786816596985\n",
            "Training loss:  \t 0.6582575291395187\n",
            "---------------\n",
            "Processing epoch: 145 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6642410308122635\n",
            "Training loss:  \t 0.6534144520759583\n",
            "---------------\n",
            "Processing epoch: 146 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6632484942674637\n",
            "Training loss:  \t 0.6573631316423416\n",
            "---------------\n",
            "Processing epoch: 147 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6600583493709564\n",
            "Training loss:  \t 0.6536039173603058\n",
            "---------------\n",
            "Processing epoch: 148 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.660710483789444\n",
            "Training loss:  \t 0.6552307486534119\n",
            "---------------\n",
            "Processing epoch: 149 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6625431925058365\n",
            "Training loss:  \t 0.6532210677862167\n",
            "---------------\n",
            "Processing epoch: 150 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6621104329824448\n",
            "Training loss:  \t 0.6539149463176728\n",
            "---------------\n",
            "Processing epoch: 151 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6593012660741806\n",
            "Training loss:  \t 0.6665262341499328\n",
            "---------------\n",
            "Processing epoch: 152 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.657440796494484\n",
            "Training loss:  \t 0.6654579490423203\n",
            "---------------\n",
            "Processing epoch: 153 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6574823558330536\n",
            "Training loss:  \t 0.6619821965694428\n",
            "---------------\n",
            "Processing epoch: 154 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6579110771417618\n",
            "Training loss:  \t 0.6640375643968582\n",
            "---------------\n",
            "Processing epoch: 155 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6586224585771561\n",
            "Training loss:  \t 0.6580898731946945\n",
            "---------------\n",
            "Processing epoch: 156 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6602362245321274\n",
            "Training loss:  \t 0.6543430358171463\n",
            "---------------\n",
            "Processing epoch: 157 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6631492525339127\n",
            "Training loss:  \t 0.6576180338859559\n",
            "---------------\n",
            "Processing epoch: 158 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.661798745393753\n",
            "Training loss:  \t 0.653344652056694\n",
            "---------------\n",
            "Processing epoch: 159 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6593730747699738\n",
            "Training loss:  \t 0.6584424108266831\n",
            "---------------\n",
            "Processing epoch: 160 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6581379771232605\n",
            "Training loss:  \t 0.6565900266170501\n",
            "---------------\n",
            "Processing epoch: 161 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6597648561000824\n",
            "Training loss:  \t 0.6619010537862777\n",
            "---------------\n",
            "Processing epoch: 162 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6578974574804306\n",
            "Training loss:  \t 0.6615632593631744\n",
            "---------------\n",
            "Processing epoch: 163 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6591294407844543\n",
            "Training loss:  \t 0.6578706711530685\n",
            "---------------\n",
            "Processing epoch: 164 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.66050124168396\n",
            "Training loss:  \t 0.6547773241996765\n",
            "---------------\n",
            "Processing epoch: 165 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6590131223201752\n",
            "Training loss:  \t 0.6491041928529739\n",
            "---------------\n",
            "Processing epoch: 166 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6582853198051453\n",
            "Training loss:  \t 0.6510903775691986\n",
            "---------------\n",
            "Processing epoch: 167 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6595928072929382\n",
            "Training loss:  \t 0.6483887821435929\n",
            "---------------\n",
            "Processing epoch: 168 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.660522922873497\n",
            "Training loss:  \t 0.6486379474401474\n",
            "---------------\n",
            "Processing epoch: 169 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.658018171787262\n",
            "Training loss:  \t 0.6476988077163697\n",
            "---------------\n",
            "Processing epoch: 170 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6622381955385208\n",
            "Training loss:  \t 0.6508768975734711\n",
            "---------------\n",
            "Processing epoch: 171 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6592091768980026\n",
            "Training loss:  \t 0.6504906117916107\n",
            "---------------\n",
            "Processing epoch: 172 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6577646285295486\n",
            "Training loss:  \t 0.6490063160657883\n",
            "---------------\n",
            "Processing epoch: 173 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6581161022186279\n",
            "Training loss:  \t 0.6546861529350281\n",
            "---------------\n",
            "Processing epoch: 174 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6594280153512955\n",
            "Training loss:  \t 0.6502279251813888\n",
            "---------------\n",
            "Processing epoch: 175 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6565006673336029\n",
            "Training loss:  \t 0.6482208609580994\n",
            "---------------\n",
            "Processing epoch: 176 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6592617034912109\n",
            "Training loss:  \t 0.6482409596443176\n",
            "---------------\n",
            "Processing epoch: 177 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6562725305557251\n",
            "Training loss:  \t 0.6464509606361389\n",
            "---------------\n",
            "Processing epoch: 178 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.658277228474617\n",
            "Training loss:  \t 0.6481624841690063\n",
            "---------------\n",
            "Processing epoch: 179 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6592121720314026\n",
            "Training loss:  \t 0.6463612616062164\n",
            "---------------\n",
            "Processing epoch: 180 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6587826013565063\n",
            "Training loss:  \t 0.6468671828508377\n",
            "---------------\n",
            "Processing epoch: 181 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6592544913291931\n",
            "Training loss:  \t 0.6507576823234558\n",
            "---------------\n",
            "Processing epoch: 182 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6584177911281586\n",
            "Training loss:  \t 0.6478117525577545\n",
            "---------------\n",
            "Processing epoch: 183 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6595970988273621\n",
            "Training loss:  \t 0.6475910931825638\n",
            "---------------\n",
            "Processing epoch: 184 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6576669812202454\n",
            "Training loss:  \t 0.6466002643108368\n",
            "---------------\n",
            "Processing epoch: 185 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6555936485528946\n",
            "Training loss:  \t 0.6465444266796112\n",
            "---------------\n",
            "Processing epoch: 186 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6560764163732529\n",
            "Training loss:  \t 0.646726268529892\n",
            "---------------\n",
            "Processing epoch: 187 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6554206162691116\n",
            "Training loss:  \t 0.6443999409675598\n",
            "---------------\n",
            "Processing epoch: 188 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6546224802732468\n",
            "Training loss:  \t 0.6500824123620987\n",
            "---------------\n",
            "Processing epoch: 189 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6563555151224136\n",
            "Training loss:  \t 0.6449444472789765\n",
            "---------------\n",
            "Processing epoch: 190 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6564468592405319\n",
            "Training loss:  \t 0.6474316596984864\n",
            "---------------\n",
            "Processing epoch: 191 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6563853174448013\n",
            "Training loss:  \t 0.6444852232933045\n",
            "---------------\n",
            "Processing epoch: 192 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6563190221786499\n",
            "Training loss:  \t 0.6436413407325745\n",
            "---------------\n",
            "Processing epoch: 193 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6556765288114548\n",
            "Training loss:  \t 0.6522182285785675\n",
            "---------------\n",
            "Processing epoch: 194 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6577213406562805\n",
            "Training loss:  \t 0.6419915646314621\n",
            "---------------\n",
            "Processing epoch: 195 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6543562859296799\n",
            "Training loss:  \t 0.6438904792070389\n",
            "---------------\n",
            "Processing epoch: 196 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6558615565299988\n",
            "Training loss:  \t 0.6429188907146454\n",
            "---------------\n",
            "Processing epoch: 197 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6547476202249527\n",
            "Training loss:  \t 0.6434355527162552\n",
            "---------------\n",
            "Processing epoch: 198 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6556379944086075\n",
            "Training loss:  \t 0.6446696847677231\n",
            "---------------\n",
            "Processing epoch: 199 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6552733927965164\n",
            "Training loss:  \t 0.6443215817213058\n",
            "---------------\n",
            "Processing epoch: 200 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6548216938972473\n",
            "Training loss:  \t 0.6446607261896133\n",
            "---------------\n",
            "Processing epoch: 201 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6539233028888702\n",
            "Training loss:  \t 0.6409285128116607\n",
            "---------------\n",
            "Processing epoch: 202 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6548098474740982\n",
            "Training loss:  \t 0.6450697809457779\n",
            "---------------\n",
            "Processing epoch: 203 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6543893665075302\n",
            "Training loss:  \t 0.6432708412408829\n",
            "---------------\n",
            "Processing epoch: 204 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6567794680595398\n",
            "Training loss:  \t 0.6441404789686203\n",
            "---------------\n",
            "Processing epoch: 205 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.655362531542778\n",
            "Training loss:  \t 0.643383476138115\n",
            "---------------\n",
            "Processing epoch: 206 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.653548002243042\n",
            "Training loss:  \t 0.6398104518651963\n",
            "---------------\n",
            "Processing epoch: 207 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6544958055019379\n",
            "Training loss:  \t 0.643324562907219\n",
            "---------------\n",
            "Processing epoch: 208 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6553218364715576\n",
            "Training loss:  \t 0.6427649110555649\n",
            "---------------\n",
            "Processing epoch: 209 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6552346497774124\n",
            "Training loss:  \t 0.6424649000167847\n",
            "---------------\n",
            "Processing epoch: 210 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.655710831284523\n",
            "Training loss:  \t 0.6410477608442307\n",
            "---------------\n",
            "Processing epoch: 211 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6542460322380066\n",
            "Training loss:  \t 0.6441796302795411\n",
            "---------------\n",
            "Processing epoch: 212 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6562489718198776\n",
            "Training loss:  \t 0.6404395133256913\n",
            "---------------\n",
            "Processing epoch: 213 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.655399277806282\n",
            "Training loss:  \t 0.6431352168321609\n",
            "---------------\n",
            "Processing epoch: 214 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6577496975660324\n",
            "Training loss:  \t 0.6427703529596329\n",
            "---------------\n",
            "Processing epoch: 215 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6542842239141464\n",
            "Training loss:  \t 0.6418454051017761\n",
            "---------------\n",
            "Processing epoch: 216 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6554091274738312\n",
            "Training loss:  \t 0.6411654978990555\n",
            "---------------\n",
            "Processing epoch: 217 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.652261033654213\n",
            "Training loss:  \t 0.6530748337507248\n",
            "---------------\n",
            "Processing epoch: 218 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6538877338171005\n",
            "Training loss:  \t 0.6459301978349685\n",
            "---------------\n",
            "Processing epoch: 219 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6564881056547165\n",
            "Training loss:  \t 0.6451507568359375\n",
            "---------------\n",
            "Processing epoch: 220 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6547051966190338\n",
            "Training loss:  \t 0.6410423398017884\n",
            "---------------\n",
            "Processing epoch: 221 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6534164398908615\n",
            "Training loss:  \t 0.6398417383432389\n",
            "---------------\n",
            "Processing epoch: 222 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6558121591806412\n",
            "Training loss:  \t 0.6414053082466126\n",
            "---------------\n",
            "Processing epoch: 223 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6549081057310104\n",
            "Training loss:  \t 0.6406130820512772\n",
            "---------------\n",
            "Processing epoch: 224 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6531427204608917\n",
            "Training loss:  \t 0.6399000197649002\n",
            "---------------\n",
            "Processing epoch: 225 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6546713262796402\n",
            "Training loss:  \t 0.6461785286664963\n",
            "---------------\n",
            "Processing epoch: 226 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6552375704050064\n",
            "Training loss:  \t 0.6403592467308045\n",
            "---------------\n",
            "Processing epoch: 227 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6537105590105057\n",
            "Training loss:  \t 0.6399626076221466\n",
            "---------------\n",
            "Processing epoch: 228 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.652524933218956\n",
            "Training loss:  \t 0.6391227722167969\n",
            "---------------\n",
            "Processing epoch: 229 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6530732065439224\n",
            "Training loss:  \t 0.6385445058345794\n",
            "---------------\n",
            "Processing epoch: 230 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6523796916007996\n",
            "Training loss:  \t 0.6457828521728516\n",
            "---------------\n",
            "Processing epoch: 231 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6508056670427322\n",
            "Training loss:  \t 0.6481227219104767\n",
            "---------------\n",
            "Processing epoch: 232 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6550680845975876\n",
            "Training loss:  \t 0.6430442482233047\n",
            "---------------\n",
            "Processing epoch: 233 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6524131000041962\n",
            "Training loss:  \t 0.6401881694793701\n",
            "---------------\n",
            "Processing epoch: 234 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.65284763276577\n",
            "Training loss:  \t 0.6426040172576905\n",
            "---------------\n",
            "Processing epoch: 235 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.653988778591156\n",
            "Training loss:  \t 0.6401498258113861\n",
            "---------------\n",
            "Processing epoch: 236 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.655756488442421\n",
            "Training loss:  \t 0.6379615902900696\n",
            "---------------\n",
            "Processing epoch: 237 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6535511761903763\n",
            "Training loss:  \t 0.6389287769794464\n",
            "---------------\n",
            "Processing epoch: 238 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6526622474193573\n",
            "Training loss:  \t 0.6459088623523712\n",
            "---------------\n",
            "Processing epoch: 239 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6543172150850296\n",
            "Training loss:  \t 0.6387868404388428\n",
            "---------------\n",
            "Processing epoch: 240 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6527076810598373\n",
            "Training loss:  \t 0.638086062669754\n",
            "---------------\n",
            "Processing epoch: 241 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6537007242441177\n",
            "Training loss:  \t 0.6361415803432464\n",
            "---------------\n",
            "Processing epoch: 242 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6532201170921326\n",
            "Training loss:  \t 0.6361122518777848\n",
            "---------------\n",
            "Processing epoch: 243 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6534004211425781\n",
            "Training loss:  \t 0.6421047687530518\n",
            "---------------\n",
            "Processing epoch: 244 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.654374897480011\n",
            "Training loss:  \t 0.639912611246109\n",
            "---------------\n",
            "Processing epoch: 245 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6516048610210419\n",
            "Training loss:  \t 0.6390948057174682\n",
            "---------------\n",
            "Processing epoch: 246 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6523008346557617\n",
            "Training loss:  \t 0.6355865508317947\n",
            "---------------\n",
            "Processing epoch: 247 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6525497734546661\n",
            "Training loss:  \t 0.6365718841552734\n",
            "---------------\n",
            "Processing epoch: 248 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6539445370435715\n",
            "Training loss:  \t 0.6365123838186264\n",
            "---------------\n",
            "Processing epoch: 249 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.651904508471489\n",
            "Training loss:  \t 0.6392217308282853\n",
            "---------------\n",
            "Processing epoch: 250 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.651840090751648\n",
            "Training loss:  \t 0.6370935529470444\n",
            "---------------\n",
            "Processing epoch: 251 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6530207246541977\n",
            "Training loss:  \t 0.6360420465469361\n",
            "---------------\n",
            "Processing epoch: 252 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.654683455824852\n",
            "Training loss:  \t 0.6378058344125748\n",
            "---------------\n",
            "Processing epoch: 253 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6527143716812134\n",
            "Training loss:  \t 0.6361241221427918\n",
            "---------------\n",
            "Processing epoch: 254 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6510292738676071\n",
            "Training loss:  \t 0.6363468676805496\n",
            "---------------\n",
            "Processing epoch: 255 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6516385525465012\n",
            "Training loss:  \t 0.6356685489416123\n",
            "---------------\n",
            "Processing epoch: 256 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6533867418766022\n",
            "Training loss:  \t 0.6370655745267868\n",
            "---------------\n",
            "Processing epoch: 257 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6542545258998871\n",
            "Training loss:  \t 0.6363019347190857\n",
            "---------------\n",
            "Processing epoch: 258 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6533688902854919\n",
            "Training loss:  \t 0.6379613190889358\n",
            "---------------\n",
            "Processing epoch: 259 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6529447138309479\n",
            "Training loss:  \t 0.6394340515136718\n",
            "---------------\n",
            "Processing epoch: 260 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6522118598222733\n",
            "Training loss:  \t 0.6345480293035507\n",
            "---------------\n",
            "Processing epoch: 261 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6512461304664612\n",
            "Training loss:  \t 0.6388234376907349\n",
            "---------------\n",
            "Processing epoch: 262 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6529800891876221\n",
            "Training loss:  \t 0.636715418100357\n",
            "---------------\n",
            "Processing epoch: 263 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6521431654691696\n",
            "Training loss:  \t 0.6364781886339188\n",
            "---------------\n",
            "Processing epoch: 264 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6512860208749771\n",
            "Training loss:  \t 0.6359951138496399\n",
            "---------------\n",
            "Processing epoch: 265 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6513524204492569\n",
            "Training loss:  \t 0.6362372964620591\n",
            "---------------\n",
            "Processing epoch: 266 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6517319530248642\n",
            "Training loss:  \t 0.639601981639862\n",
            "---------------\n",
            "Processing epoch: 267 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6548652648925781\n",
            "Training loss:  \t 0.6398391276597977\n",
            "---------------\n",
            "Processing epoch: 268 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6512549072504044\n",
            "Training loss:  \t 0.6347827136516571\n",
            "---------------\n",
            "Processing epoch: 269 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6500930935144424\n",
            "Training loss:  \t 0.6360154703259469\n",
            "---------------\n",
            "Processing epoch: 270 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6510834842920303\n",
            "Training loss:  \t 0.6358860522508621\n",
            "---------------\n",
            "Processing epoch: 271 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.65168197453022\n",
            "Training loss:  \t 0.6347209334373474\n",
            "---------------\n",
            "Processing epoch: 272 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6521705538034439\n",
            "Training loss:  \t 0.633844980597496\n",
            "---------------\n",
            "Processing epoch: 273 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6514576822519302\n",
            "Training loss:  \t 0.634781864285469\n",
            "---------------\n",
            "Processing epoch: 274 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6495745629072189\n",
            "Training loss:  \t 0.6345665842294693\n",
            "---------------\n",
            "Processing epoch: 275 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6499657481908798\n",
            "Training loss:  \t 0.6335456788539886\n",
            "---------------\n",
            "Processing epoch: 276 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6509382873773575\n",
            "Training loss:  \t 0.6356337338685989\n",
            "---------------\n",
            "Processing epoch: 277 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6513845473527908\n",
            "Training loss:  \t 0.6337109744548798\n",
            "---------------\n",
            "Processing epoch: 278 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6524501740932465\n",
            "Training loss:  \t 0.6353951275348664\n",
            "---------------\n",
            "Processing epoch: 279 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.649833083152771\n",
            "Training loss:  \t 0.6372834086418152\n",
            "---------------\n",
            "Processing epoch: 280 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6517532467842102\n",
            "Training loss:  \t 0.633488553762436\n",
            "---------------\n",
            "Processing epoch: 281 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6483446061611176\n",
            "Training loss:  \t 0.6358310848474502\n",
            "---------------\n",
            "Processing epoch: 282 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6499269753694534\n",
            "Training loss:  \t 0.6341079086065292\n",
            "---------------\n",
            "Processing epoch: 283 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6498709321022034\n",
            "Training loss:  \t 0.6351694405078888\n",
            "---------------\n",
            "Processing epoch: 284 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6485469937324524\n",
            "Training loss:  \t 0.6344773501157761\n",
            "---------------\n",
            "Processing epoch: 285 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6500564366579056\n",
            "Training loss:  \t 0.6348619490861893\n",
            "---------------\n",
            "Processing epoch: 286 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6517715305089951\n",
            "Training loss:  \t 0.6324961692094803\n",
            "---------------\n",
            "Processing epoch: 287 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6521690487861633\n",
            "Training loss:  \t 0.6350436955690384\n",
            "---------------\n",
            "Processing epoch: 288 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6487373113632202\n",
            "Training loss:  \t 0.6357488095760345\n",
            "---------------\n",
            "Processing epoch: 289 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6512171179056168\n",
            "Training loss:  \t 0.6365386039018631\n",
            "---------------\n",
            "Processing epoch: 290 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6484276205301285\n",
            "Training loss:  \t 0.6343700081110001\n",
            "---------------\n",
            "Processing epoch: 291 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6503502279520035\n",
            "Training loss:  \t 0.6328872799873352\n",
            "---------------\n",
            "Processing epoch: 292 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6508667171001434\n",
            "Training loss:  \t 0.6339336663484574\n",
            "---------------\n",
            "Processing epoch: 293 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6510165929794312\n",
            "Training loss:  \t 0.6348440617322921\n",
            "---------------\n",
            "Processing epoch: 294 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6490020453929901\n",
            "Training loss:  \t 0.6351931780576706\n",
            "---------------\n",
            "Processing epoch: 295 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6512293666601181\n",
            "Training loss:  \t 0.633089330792427\n",
            "---------------\n",
            "Processing epoch: 296 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6501352041959763\n",
            "Training loss:  \t 0.6370223879814148\n",
            "---------------\n",
            "Processing epoch: 297 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6541438549757004\n",
            "Training loss:  \t 0.6370920240879059\n",
            "---------------\n",
            "Processing epoch: 298 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6508062183856964\n",
            "Training loss:  \t 0.6347819805145264\n",
            "---------------\n",
            "Processing epoch: 299 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6503629237413406\n",
            "Training loss:  \t 0.6351485401391983\n",
            "---------------\n",
            "Processing epoch: 300 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6488633900880814\n",
            "Training loss:  \t 0.6314468055963516\n",
            "---------------\n",
            "Processing epoch: 301 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6481859087944031\n",
            "Training loss:  \t 0.6336066514253617\n",
            "---------------\n",
            "Processing epoch: 302 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6504067331552505\n",
            "Training loss:  \t 0.631813645362854\n",
            "---------------\n",
            "Processing epoch: 303 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6519511342048645\n",
            "Training loss:  \t 0.6343503177165986\n",
            "---------------\n",
            "Processing epoch: 304 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6493658572435379\n",
            "Training loss:  \t 0.6332191616296768\n",
            "---------------\n",
            "Processing epoch: 305 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6523286551237106\n",
            "Training loss:  \t 0.6357156276702881\n",
            "---------------\n",
            "Processing epoch: 306 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6479597240686417\n",
            "Training loss:  \t 0.6334374219179153\n",
            "---------------\n",
            "Processing epoch: 307 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6489610373973846\n",
            "Training loss:  \t 0.6324912220239639\n",
            "---------------\n",
            "Processing epoch: 308 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6468756645917892\n",
            "Training loss:  \t 0.6322072565555572\n",
            "---------------\n",
            "Processing epoch: 309 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6494508236646652\n",
            "Training loss:  \t 0.6352838724851608\n",
            "---------------\n",
            "Processing epoch: 310 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6490878760814667\n",
            "Training loss:  \t 0.6359628051519394\n",
            "---------------\n",
            "Processing epoch: 311 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6486898064613342\n",
            "Training loss:  \t 0.6317017823457718\n",
            "---------------\n",
            "Processing epoch: 312 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6501895189285278\n",
            "Training loss:  \t 0.6329402238130569\n",
            "---------------\n",
            "Processing epoch: 313 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6483985781669617\n",
            "Training loss:  \t 0.6312920987606049\n",
            "---------------\n",
            "Processing epoch: 314 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6482781022787094\n",
            "Training loss:  \t 0.6342479199171066\n",
            "---------------\n",
            "Processing epoch: 315 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6494688987731934\n",
            "Training loss:  \t 0.6307182282209396\n",
            "---------------\n",
            "Processing epoch: 316 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6475638002157211\n",
            "Training loss:  \t 0.6340907663106918\n",
            "---------------\n",
            "Processing epoch: 317 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6495522558689117\n",
            "Training loss:  \t 0.6315037816762924\n",
            "---------------\n",
            "Processing epoch: 318 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6466964930295944\n",
            "Training loss:  \t 0.6314575374126434\n",
            "---------------\n",
            "Processing epoch: 319 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6474274694919586\n",
            "Training loss:  \t 0.6326596885919571\n",
            "---------------\n",
            "Processing epoch: 320 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.649463102221489\n",
            "Training loss:  \t 0.6315251171588898\n",
            "---------------\n",
            "Processing epoch: 321 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6495219469070435\n",
            "Training loss:  \t 0.6311019659042358\n",
            "---------------\n",
            "Processing epoch: 322 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6473652422428131\n",
            "Training loss:  \t 0.637245187163353\n",
            "---------------\n",
            "Processing epoch: 323 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6487037241458893\n",
            "Training loss:  \t 0.6291162192821502\n",
            "---------------\n",
            "Processing epoch: 324 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6486401259899139\n",
            "Training loss:  \t 0.6311886578798294\n",
            "---------------\n",
            "Processing epoch: 325 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6474177539348602\n",
            "Training loss:  \t 0.6311905413866044\n",
            "---------------\n",
            "Processing epoch: 326 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.649359330534935\n",
            "Training loss:  \t 0.6318869352340698\n",
            "---------------\n",
            "Processing epoch: 327 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6469964534044266\n",
            "Training loss:  \t 0.6299432426691055\n",
            "---------------\n",
            "Processing epoch: 328 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6496923863887787\n",
            "Training loss:  \t 0.634093526005745\n",
            "---------------\n",
            "Processing epoch: 329 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6483762860298157\n",
            "Training loss:  \t 0.6288456052541733\n",
            "---------------\n",
            "Processing epoch: 330 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.646106943488121\n",
            "Training loss:  \t 0.6332744926214218\n",
            "---------------\n",
            "Processing epoch: 331 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6472667306661606\n",
            "Training loss:  \t 0.6289598435163498\n",
            "---------------\n",
            "Processing epoch: 332 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6484362185001373\n",
            "Training loss:  \t 0.630461785197258\n",
            "---------------\n",
            "Processing epoch: 333 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6475690305233002\n",
            "Training loss:  \t 0.6318948954343796\n",
            "---------------\n",
            "Processing epoch: 334 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6482733339071274\n",
            "Training loss:  \t 0.6301804512739182\n",
            "---------------\n",
            "Processing epoch: 335 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6475187242031097\n",
            "Training loss:  \t 0.6305786937475204\n",
            "---------------\n",
            "Processing epoch: 336 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6478560864925385\n",
            "Training loss:  \t 0.6294494807720185\n",
            "---------------\n",
            "Processing epoch: 337 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6477803140878677\n",
            "Training loss:  \t 0.6326883047819137\n",
            "---------------\n",
            "Processing epoch: 338 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6470979303121567\n",
            "Training loss:  \t 0.633716133236885\n",
            "---------------\n",
            "Processing epoch: 339 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6501497179269791\n",
            "Training loss:  \t 0.6355961948633194\n",
            "---------------\n",
            "Processing epoch: 340 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6485626697540283\n",
            "Training loss:  \t 0.6313003480434418\n",
            "---------------\n",
            "Processing epoch: 341 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6481451243162155\n",
            "Training loss:  \t 0.6292243480682373\n",
            "---------------\n",
            "Processing epoch: 342 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6485382467508316\n",
            "Training loss:  \t 0.6312978059053421\n",
            "---------------\n",
            "Processing epoch: 343 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6483955234289169\n",
            "Training loss:  \t 0.6309031754732132\n",
            "---------------\n",
            "Processing epoch: 344 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6478189080953598\n",
            "Training loss:  \t 0.6290904521942139\n",
            "---------------\n",
            "Processing epoch: 345 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6487139016389847\n",
            "Training loss:  \t 0.6319714277982712\n",
            "---------------\n",
            "Processing epoch: 346 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6470319777727127\n",
            "Training loss:  \t 0.6298725783824921\n",
            "---------------\n",
            "Processing epoch: 347 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6469180732965469\n",
            "Training loss:  \t 0.632685199379921\n",
            "---------------\n",
            "Processing epoch: 348 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6480961889028549\n",
            "Training loss:  \t 0.6306097686290741\n",
            "---------------\n",
            "Processing epoch: 349 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6491570025682449\n",
            "Training loss:  \t 0.6318337172269821\n",
            "---------------\n",
            "Processing epoch: 350 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.647630050778389\n",
            "Training loss:  \t 0.6336003452539444\n",
            "---------------\n",
            "Processing epoch: 351 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6473669707775116\n",
            "Training loss:  \t 0.6291672855615615\n",
            "---------------\n",
            "Processing epoch: 352 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6473151594400406\n",
            "Training loss:  \t 0.6289040952920913\n",
            "---------------\n",
            "Processing epoch: 353 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6494766920804977\n",
            "Training loss:  \t 0.6349102884531022\n",
            "---------------\n",
            "Processing epoch: 354 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6475583761930466\n",
            "Training loss:  \t 0.6328903555870056\n",
            "---------------\n",
            "Processing epoch: 355 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6475650370121002\n",
            "Training loss:  \t 0.6291670382022858\n",
            "---------------\n",
            "Processing epoch: 356 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6488267481327057\n",
            "Training loss:  \t 0.6305040389299392\n",
            "---------------\n",
            "Processing epoch: 357 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6455798298120499\n",
            "Training loss:  \t 0.6270804986357689\n",
            "---------------\n",
            "Processing epoch: 358 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6472413688898087\n",
            "Training loss:  \t 0.6295186936855316\n",
            "---------------\n",
            "Processing epoch: 359 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6457105278968811\n",
            "Training loss:  \t 0.6297947645187378\n",
            "---------------\n",
            "Processing epoch: 360 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6470022797584534\n",
            "Training loss:  \t 0.6280673891305923\n",
            "---------------\n",
            "Processing epoch: 361 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6482219398021698\n",
            "Training loss:  \t 0.6308159053325653\n",
            "---------------\n",
            "Processing epoch: 362 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.648286983370781\n",
            "Training loss:  \t 0.6297522366046906\n",
            "---------------\n",
            "Processing epoch: 363 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6463117599487305\n",
            "Training loss:  \t 0.628555628657341\n",
            "---------------\n",
            "Processing epoch: 364 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6464045345783234\n",
            "Training loss:  \t 0.6284070581197738\n",
            "---------------\n",
            "Processing epoch: 365 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6446836739778519\n",
            "Training loss:  \t 0.6298210024833679\n",
            "---------------\n",
            "Processing epoch: 366 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6469966620206833\n",
            "Training loss:  \t 0.6276355385780334\n",
            "---------------\n",
            "Processing epoch: 367 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6465352922677994\n",
            "Training loss:  \t 0.6299602657556533\n",
            "---------------\n",
            "Processing epoch: 368 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6479511260986328\n",
            "Training loss:  \t 0.6296911656856536\n",
            "---------------\n",
            "Processing epoch: 369 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6456128805875778\n",
            "Training loss:  \t 0.6282903671264648\n",
            "---------------\n",
            "Processing epoch: 370 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6453079581260681\n",
            "Training loss:  \t 0.6282143831253052\n",
            "---------------\n",
            "Processing epoch: 371 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6465171128511429\n",
            "Training loss:  \t 0.6284675598144531\n",
            "---------------\n",
            "Processing epoch: 372 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6447082757949829\n",
            "Training loss:  \t 0.6277813524007797\n",
            "---------------\n",
            "Processing epoch: 373 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6475688219070435\n",
            "Training loss:  \t 0.6275347799062729\n",
            "---------------\n",
            "Processing epoch: 374 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6466004401445389\n",
            "Training loss:  \t 0.627682027220726\n",
            "---------------\n",
            "Processing epoch: 375 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6478717625141144\n",
            "Training loss:  \t 0.6294823914766312\n",
            "---------------\n",
            "Processing epoch: 376 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6477541774511337\n",
            "Training loss:  \t 0.6282856434583663\n",
            "---------------\n",
            "Processing epoch: 377 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6464225500822067\n",
            "Training loss:  \t 0.6270506471395493\n",
            "---------------\n",
            "Processing epoch: 378 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6449411362409592\n",
            "Training loss:  \t 0.6266622990369797\n",
            "---------------\n",
            "Processing epoch: 379 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6464458256959915\n",
            "Training loss:  \t 0.6335035920143127\n",
            "---------------\n",
            "Processing epoch: 380 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6448973715305328\n",
            "Training loss:  \t 0.6285987049341202\n",
            "---------------\n",
            "Processing epoch: 381 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6454441994428635\n",
            "Training loss:  \t 0.6273590505123139\n",
            "---------------\n",
            "Processing epoch: 382 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.646696999669075\n",
            "Training loss:  \t 0.6273127257823944\n",
            "---------------\n",
            "Processing epoch: 383 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6454662531614304\n",
            "Training loss:  \t 0.6278291761875152\n",
            "---------------\n",
            "Processing epoch: 384 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6439634412527084\n",
            "Training loss:  \t 0.6281269609928131\n",
            "---------------\n",
            "Processing epoch: 385 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6453509628772736\n",
            "Training loss:  \t 0.628064313530922\n",
            "---------------\n",
            "Processing epoch: 386 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6453128308057785\n",
            "Training loss:  \t 0.6295044392347335\n",
            "---------------\n",
            "Processing epoch: 387 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6454680263996124\n",
            "Training loss:  \t 0.6262567579746247\n",
            "---------------\n",
            "Processing epoch: 388 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6444471329450607\n",
            "Training loss:  \t 0.6291066616773605\n",
            "---------------\n",
            "Processing epoch: 389 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6455310434103012\n",
            "Training loss:  \t 0.6292976677417755\n",
            "---------------\n",
            "Processing epoch: 390 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6442791372537613\n",
            "Training loss:  \t 0.6264112025499344\n",
            "---------------\n",
            "Processing epoch: 391 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6456978172063828\n",
            "Training loss:  \t 0.6272196441888809\n",
            "---------------\n",
            "Processing epoch: 392 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6453036367893219\n",
            "Training loss:  \t 0.6254212349653244\n",
            "---------------\n",
            "Processing epoch: 393 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6432521045207977\n",
            "Training loss:  \t 0.6287629902362823\n",
            "---------------\n",
            "Processing epoch: 394 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6467599719762802\n",
            "Training loss:  \t 0.6268167972564698\n",
            "---------------\n",
            "Processing epoch: 395 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.645896703004837\n",
            "Training loss:  \t 0.6282803028821945\n",
            "---------------\n",
            "Processing epoch: 396 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6464961618185043\n",
            "Training loss:  \t 0.6262205302715301\n",
            "---------------\n",
            "Processing epoch: 397 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6435343474149704\n",
            "Training loss:  \t 0.6268953323364258\n",
            "---------------\n",
            "Processing epoch: 398 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6437186300754547\n",
            "Training loss:  \t 0.6263871192932129\n",
            "---------------\n",
            "Processing epoch: 399 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6446856558322906\n",
            "Training loss:  \t 0.6298115283250809\n",
            "---------------\n",
            "Processing epoch: 400 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6438196897506714\n",
            "Training loss:  \t 0.6271314501762391\n",
            "---------------\n",
            "Processing epoch: 401 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6443473845720291\n",
            "Training loss:  \t 0.627488887310028\n",
            "---------------\n",
            "Processing epoch: 402 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6447532773017883\n",
            "Training loss:  \t 0.6268480807542801\n",
            "---------------\n",
            "Processing epoch: 403 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6473964154720306\n",
            "Training loss:  \t 0.6262338101863861\n",
            "---------------\n",
            "Processing epoch: 404 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6452831327915192\n",
            "Training loss:  \t 0.6261502951383591\n",
            "---------------\n",
            "Processing epoch: 405 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440446674823761\n",
            "Training loss:  \t 0.6261720031499862\n",
            "---------------\n",
            "Processing epoch: 406 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6432809829711914\n",
            "Training loss:  \t 0.6266577512025833\n",
            "---------------\n",
            "Processing epoch: 407 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436478495597839\n",
            "Training loss:  \t 0.625807136297226\n",
            "---------------\n",
            "Processing epoch: 408 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6443391889333725\n",
            "Training loss:  \t 0.6259758681058883\n",
            "---------------\n",
            "Processing epoch: 409 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6448292285203934\n",
            "Training loss:  \t 0.6274288326501847\n",
            "---------------\n",
            "Processing epoch: 410 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440457701683044\n",
            "Training loss:  \t 0.6258683383464814\n",
            "---------------\n",
            "Processing epoch: 411 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6442644894123077\n",
            "Training loss:  \t 0.6268022209405899\n",
            "---------------\n",
            "Processing epoch: 412 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6411852836608887\n",
            "Training loss:  \t 0.6269665777683258\n",
            "---------------\n",
            "Processing epoch: 413 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6470810770988464\n",
            "Training loss:  \t 0.6277795612812043\n",
            "---------------\n",
            "Processing epoch: 414 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6456520706415176\n",
            "Training loss:  \t 0.6248365551233291\n",
            "---------------\n",
            "Processing epoch: 415 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6446726769208908\n",
            "Training loss:  \t 0.6264062881469726\n",
            "---------------\n",
            "Processing epoch: 416 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6447981297969818\n",
            "Training loss:  \t 0.6261202722787857\n",
            "---------------\n",
            "Processing epoch: 417 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6459795534610748\n",
            "Training loss:  \t 0.6261093154549598\n",
            "---------------\n",
            "Processing epoch: 418 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.644668236374855\n",
            "Training loss:  \t 0.6247642546892166\n",
            "---------------\n",
            "Processing epoch: 419 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.644349068403244\n",
            "Training loss:  \t 0.6259425520896912\n",
            "---------------\n",
            "Processing epoch: 420 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.644428089261055\n",
            "Training loss:  \t 0.6283335089683533\n",
            "---------------\n",
            "Processing epoch: 421 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.645033985376358\n",
            "Training loss:  \t 0.6257639646530151\n",
            "---------------\n",
            "Processing epoch: 422 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6437347084283829\n",
            "Training loss:  \t 0.6239721596240997\n",
            "---------------\n",
            "Processing epoch: 423 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6435603648424149\n",
            "Training loss:  \t 0.629063880443573\n",
            "---------------\n",
            "Processing epoch: 424 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6426848024129868\n",
            "Training loss:  \t 0.6293086111545563\n",
            "---------------\n",
            "Processing epoch: 425 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6449948996305466\n",
            "Training loss:  \t 0.6281753242015838\n",
            "---------------\n",
            "Processing epoch: 426 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6439518183469772\n",
            "Training loss:  \t 0.6268886744976043\n",
            "---------------\n",
            "Processing epoch: 427 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440406888723373\n",
            "Training loss:  \t 0.6265981584787369\n",
            "---------------\n",
            "Processing epoch: 428 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6429461240768433\n",
            "Training loss:  \t 0.6255968034267425\n",
            "---------------\n",
            "Processing epoch: 429 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6429412811994553\n",
            "Training loss:  \t 0.625413891673088\n",
            "---------------\n",
            "Processing epoch: 430 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6439221054315567\n",
            "Training loss:  \t 0.6258992284536362\n",
            "---------------\n",
            "Processing epoch: 431 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6439192146062851\n",
            "Training loss:  \t 0.6258780896663666\n",
            "---------------\n",
            "Processing epoch: 432 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6449205279350281\n",
            "Training loss:  \t 0.6275016844272614\n",
            "---------------\n",
            "Processing epoch: 433 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6433832049369812\n",
            "Training loss:  \t 0.6255830749869347\n",
            "---------------\n",
            "Processing epoch: 434 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6434320509433746\n",
            "Training loss:  \t 0.6243296802043915\n",
            "---------------\n",
            "Processing epoch: 435 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425182074308395\n",
            "Training loss:  \t 0.6256526291370392\n",
            "---------------\n",
            "Processing epoch: 436 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6460388749837875\n",
            "Training loss:  \t 0.6272511899471283\n",
            "---------------\n",
            "Processing epoch: 437 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6432670056819916\n",
            "Training loss:  \t 0.6252057164907455\n",
            "---------------\n",
            "Processing epoch: 438 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6432865262031555\n",
            "Training loss:  \t 0.6251049995422363\n",
            "---------------\n",
            "Processing epoch: 439 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6411383002996445\n",
            "Training loss:  \t 0.6253153443336487\n",
            "---------------\n",
            "Processing epoch: 440 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6418477594852448\n",
            "Training loss:  \t 0.6251893728971482\n",
            "---------------\n",
            "Processing epoch: 441 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6446542590856552\n",
            "Training loss:  \t 0.6227066040039062\n",
            "---------------\n",
            "Processing epoch: 442 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.64437136054039\n",
            "Training loss:  \t 0.6227741092443466\n",
            "---------------\n",
            "Processing epoch: 443 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436482518911362\n",
            "Training loss:  \t 0.6348499327898025\n",
            "---------------\n",
            "Processing epoch: 444 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6442631483078003\n",
            "Training loss:  \t 0.624923712015152\n",
            "---------------\n",
            "Processing epoch: 445 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6456807106733322\n",
            "Training loss:  \t 0.6247790902853012\n",
            "---------------\n",
            "Processing epoch: 446 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6432908475399017\n",
            "Training loss:  \t 0.6258174777030945\n",
            "---------------\n",
            "Processing epoch: 447 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6450092941522598\n",
            "Training loss:  \t 0.6247414737939835\n",
            "---------------\n",
            "Processing epoch: 448 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436328589916229\n",
            "Training loss:  \t 0.6275062650442124\n",
            "---------------\n",
            "Processing epoch: 449 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419258117675781\n",
            "Training loss:  \t 0.6246100723743438\n",
            "---------------\n",
            "Processing epoch: 450 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427184343338013\n",
            "Training loss:  \t 0.623474457859993\n",
            "---------------\n",
            "Processing epoch: 451 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6421731859445572\n",
            "Training loss:  \t 0.6255241692066192\n",
            "---------------\n",
            "Processing epoch: 452 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6433282494544983\n",
            "Training loss:  \t 0.6262693107128143\n",
            "---------------\n",
            "Processing epoch: 453 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6467230916023254\n",
            "Training loss:  \t 0.6260874748229981\n",
            "---------------\n",
            "Processing epoch: 454 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6426244080066681\n",
            "Training loss:  \t 0.6249989479780197\n",
            "---------------\n",
            "Processing epoch: 455 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427884101867676\n",
            "Training loss:  \t 0.6228200882673264\n",
            "---------------\n",
            "Processing epoch: 456 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6424527019262314\n",
            "Training loss:  \t 0.6245331972837448\n",
            "---------------\n",
            "Processing epoch: 457 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6443000733852386\n",
            "Training loss:  \t 0.6246531262993813\n",
            "---------------\n",
            "Processing epoch: 458 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427429914474487\n",
            "Training loss:  \t 0.6226718008518219\n",
            "---------------\n",
            "Processing epoch: 459 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6411643922328949\n",
            "Training loss:  \t 0.6239844590425492\n",
            "---------------\n",
            "Processing epoch: 460 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6423516720533371\n",
            "Training loss:  \t 0.6273058950901031\n",
            "---------------\n",
            "Processing epoch: 461 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425681114196777\n",
            "Training loss:  \t 0.623648276925087\n",
            "---------------\n",
            "Processing epoch: 462 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6454086154699326\n",
            "Training loss:  \t 0.6261389821767807\n",
            "---------------\n",
            "Processing epoch: 463 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6461121886968613\n",
            "Training loss:  \t 0.6254168063402176\n",
            "---------------\n",
            "Processing epoch: 464 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431613713502884\n",
            "Training loss:  \t 0.622029161453247\n",
            "---------------\n",
            "Processing epoch: 465 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6417147815227509\n",
            "Training loss:  \t 0.624624228477478\n",
            "---------------\n",
            "Processing epoch: 466 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6433584094047546\n",
            "Training loss:  \t 0.6220127165317535\n",
            "---------------\n",
            "Processing epoch: 467 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419419944286346\n",
            "Training loss:  \t 0.623091222345829\n",
            "---------------\n",
            "Processing epoch: 468 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642409160733223\n",
            "Training loss:  \t 0.6217310458421708\n",
            "---------------\n",
            "Processing epoch: 469 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419202536344528\n",
            "Training loss:  \t 0.6218724429607392\n",
            "---------------\n",
            "Processing epoch: 470 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6439119130373001\n",
            "Training loss:  \t 0.6241867482662201\n",
            "---------------\n",
            "Processing epoch: 471 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425264775753021\n",
            "Training loss:  \t 0.6265398830175399\n",
            "---------------\n",
            "Processing epoch: 472 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412420868873596\n",
            "Training loss:  \t 0.6213539153337478\n",
            "---------------\n",
            "Processing epoch: 473 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6433428227901459\n",
            "Training loss:  \t 0.6203529834747314\n",
            "---------------\n",
            "Processing epoch: 474 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.640696719288826\n",
            "Training loss:  \t 0.6226897925138474\n",
            "---------------\n",
            "Processing epoch: 475 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6429108381271362\n",
            "Training loss:  \t 0.6254161238670349\n",
            "---------------\n",
            "Processing epoch: 476 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6470334827899933\n",
            "Training loss:  \t 0.6242667436599731\n",
            "---------------\n",
            "Processing epoch: 477 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440240442752838\n",
            "Training loss:  \t 0.6227723509073257\n",
            "---------------\n",
            "Processing epoch: 478 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428310424089432\n",
            "Training loss:  \t 0.6231830388307571\n",
            "---------------\n",
            "Processing epoch: 479 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.64157535135746\n",
            "Training loss:  \t 0.6233183100819588\n",
            "---------------\n",
            "Processing epoch: 480 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431131809949875\n",
            "Training loss:  \t 0.6245901167392731\n",
            "---------------\n",
            "Processing epoch: 481 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6442565619945526\n",
            "Training loss:  \t 0.6231933832168579\n",
            "---------------\n",
            "Processing epoch: 482 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6430166959762573\n",
            "Training loss:  \t 0.6226098328828812\n",
            "---------------\n",
            "Processing epoch: 483 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422264128923416\n",
            "Training loss:  \t 0.6215887159109116\n",
            "---------------\n",
            "Processing epoch: 484 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6417856812477112\n",
            "Training loss:  \t 0.6222001165151596\n",
            "---------------\n",
            "Processing epoch: 485 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408370286226273\n",
            "Training loss:  \t 0.6230061948299408\n",
            "---------------\n",
            "Processing epoch: 486 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6420222818851471\n",
            "Training loss:  \t 0.6211244314908981\n",
            "---------------\n",
            "Processing epoch: 487 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6417252719402313\n",
            "Training loss:  \t 0.6228136479854584\n",
            "---------------\n",
            "Processing epoch: 488 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422148793935776\n",
            "Training loss:  \t 0.6228676408529281\n",
            "---------------\n",
            "Processing epoch: 489 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.643795445561409\n",
            "Training loss:  \t 0.6221137464046478\n",
            "---------------\n",
            "Processing epoch: 490 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6423787921667099\n",
            "Training loss:  \t 0.6235808461904526\n",
            "---------------\n",
            "Processing epoch: 491 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431740373373032\n",
            "Training loss:  \t 0.6262275159358979\n",
            "---------------\n",
            "Processing epoch: 492 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6442179381847382\n",
            "Training loss:  \t 0.6225058197975158\n",
            "---------------\n",
            "Processing epoch: 493 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641944482922554\n",
            "Training loss:  \t 0.6216325521469116\n",
            "---------------\n",
            "Processing epoch: 494 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402144581079483\n",
            "Training loss:  \t 0.6210870563983917\n",
            "---------------\n",
            "Processing epoch: 495 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6404789537191391\n",
            "Training loss:  \t 0.6245911180973053\n",
            "---------------\n",
            "Processing epoch: 496 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.644204393029213\n",
            "Training loss:  \t 0.6230668991804122\n",
            "---------------\n",
            "Processing epoch: 497 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.643790066242218\n",
            "Training loss:  \t 0.6231256693601608\n",
            "---------------\n",
            "Processing epoch: 498 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414744257926941\n",
            "Training loss:  \t 0.6205923736095429\n",
            "---------------\n",
            "Processing epoch: 499 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403787285089493\n",
            "Training loss:  \t 0.622763267159462\n",
            "---------------\n",
            "Processing epoch: 500 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422637850046158\n",
            "Training loss:  \t 0.6235343933105468\n",
            "---------------\n",
            "Processing epoch: 501 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.643996387720108\n",
            "Training loss:  \t 0.6214876592159271\n",
            "---------------\n",
            "Processing epoch: 502 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6445958465337753\n",
            "Training loss:  \t 0.6208782285451889\n",
            "---------------\n",
            "Processing epoch: 503 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408564299345016\n",
            "Training loss:  \t 0.6204633951187134\n",
            "---------------\n",
            "Processing epoch: 504 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642364427447319\n",
            "Training loss:  \t 0.6208020359277725\n",
            "---------------\n",
            "Processing epoch: 505 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6429783999919891\n",
            "Training loss:  \t 0.6225305497646332\n",
            "---------------\n",
            "Processing epoch: 506 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428663730621338\n",
            "Training loss:  \t 0.6201775014400482\n",
            "---------------\n",
            "Processing epoch: 507 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436392515897751\n",
            "Training loss:  \t 0.6207547754049301\n",
            "---------------\n",
            "Processing epoch: 508 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427784711122513\n",
            "Training loss:  \t 0.6209608912467957\n",
            "---------------\n",
            "Processing epoch: 509 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414207518100739\n",
            "Training loss:  \t 0.6231987565755844\n",
            "---------------\n",
            "Processing epoch: 510 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427814364433289\n",
            "Training loss:  \t 0.6211943805217743\n",
            "---------------\n",
            "Processing epoch: 511 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6435705721378326\n",
            "Training loss:  \t 0.6207791417837143\n",
            "---------------\n",
            "Processing epoch: 512 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440275013446808\n",
            "Training loss:  \t 0.6211670100688934\n",
            "---------------\n",
            "Processing epoch: 513 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431506723165512\n",
            "Training loss:  \t 0.6210359692573547\n",
            "---------------\n",
            "Processing epoch: 514 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414522677659988\n",
            "Training loss:  \t 0.6230915009975433\n",
            "---------------\n",
            "Processing epoch: 515 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6416553854942322\n",
            "Training loss:  \t 0.621605709195137\n",
            "---------------\n",
            "Processing epoch: 516 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6435661613941193\n",
            "Training loss:  \t 0.6218124657869339\n",
            "---------------\n",
            "Processing epoch: 517 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428433954715729\n",
            "Training loss:  \t 0.6203130006790161\n",
            "---------------\n",
            "Processing epoch: 518 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6423096060752869\n",
            "Training loss:  \t 0.6220298141241074\n",
            "---------------\n",
            "Processing epoch: 519 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641694188117981\n",
            "Training loss:  \t 0.6212717562913894\n",
            "---------------\n",
            "Processing epoch: 520 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425389498472214\n",
            "Training loss:  \t 0.6209544509649276\n",
            "---------------\n",
            "Processing epoch: 521 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6424337476491928\n",
            "Training loss:  \t 0.6203189790248871\n",
            "---------------\n",
            "Processing epoch: 522 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6445071250200272\n",
            "Training loss:  \t 0.6194599613547325\n",
            "---------------\n",
            "Processing epoch: 523 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6434304416179657\n",
            "Training loss:  \t 0.6207045421004296\n",
            "---------------\n",
            "Processing epoch: 524 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6434205770492554\n",
            "Training loss:  \t 0.6205234408378602\n",
            "---------------\n",
            "Processing epoch: 525 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409970819950104\n",
            "Training loss:  \t 0.6197562932968139\n",
            "---------------\n",
            "Processing epoch: 526 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403997391462326\n",
            "Training loss:  \t 0.6189161568880082\n",
            "---------------\n",
            "Processing epoch: 527 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419494450092316\n",
            "Training loss:  \t 0.6206837087869644\n",
            "---------------\n",
            "Processing epoch: 528 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6424854248762131\n",
            "Training loss:  \t 0.6210776537656784\n",
            "---------------\n",
            "Processing epoch: 529 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6424523293972015\n",
            "Training loss:  \t 0.6202592432498932\n",
            "---------------\n",
            "Processing epoch: 530 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425324976444244\n",
            "Training loss:  \t 0.6206903204321861\n",
            "---------------\n",
            "Processing epoch: 531 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412851363420486\n",
            "Training loss:  \t 0.6210296869277954\n",
            "---------------\n",
            "Processing epoch: 532 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6420271247625351\n",
            "Training loss:  \t 0.6198343217372895\n",
            "---------------\n",
            "Processing epoch: 533 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403478980064392\n",
            "Training loss:  \t 0.6225516885519028\n",
            "---------------\n",
            "Processing epoch: 534 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408354938030243\n",
            "Training loss:  \t 0.6187443271279335\n",
            "---------------\n",
            "Processing epoch: 535 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642131894826889\n",
            "Training loss:  \t 0.6223921090364456\n",
            "---------------\n",
            "Processing epoch: 536 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6434661448001862\n",
            "Training loss:  \t 0.6190353572368622\n",
            "---------------\n",
            "Processing epoch: 537 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6426656991243362\n",
            "Training loss:  \t 0.6202627539634704\n",
            "---------------\n",
            "Processing epoch: 538 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440249532461166\n",
            "Training loss:  \t 0.6186774671077728\n",
            "---------------\n",
            "Processing epoch: 539 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419903188943863\n",
            "Training loss:  \t 0.6231047183275222\n",
            "---------------\n",
            "Processing epoch: 540 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.645325556397438\n",
            "Training loss:  \t 0.6270158618688584\n",
            "---------------\n",
            "Processing epoch: 541 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6411137729883194\n",
            "Training loss:  \t 0.6215014606714249\n",
            "---------------\n",
            "Processing epoch: 542 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6423550695180893\n",
            "Training loss:  \t 0.6223820179700852\n",
            "---------------\n",
            "Processing epoch: 543 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400043666362762\n",
            "Training loss:  \t 0.6210433214902877\n",
            "---------------\n",
            "Processing epoch: 544 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427228897809982\n",
            "Training loss:  \t 0.6195548832416534\n",
            "---------------\n",
            "Processing epoch: 545 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422867476940155\n",
            "Training loss:  \t 0.6180005431175232\n",
            "---------------\n",
            "Processing epoch: 546 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6443745195865631\n",
            "Training loss:  \t 0.6183074921369552\n",
            "---------------\n",
            "Processing epoch: 547 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642120823264122\n",
            "Training loss:  \t 0.6194432020187378\n",
            "---------------\n",
            "Processing epoch: 548 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414354294538498\n",
            "Training loss:  \t 0.6201854780316353\n",
            "---------------\n",
            "Processing epoch: 549 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6441219300031662\n",
            "Training loss:  \t 0.6191038817167283\n",
            "---------------\n",
            "Processing epoch: 550 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397385746240616\n",
            "Training loss:  \t 0.6192137837409973\n",
            "---------------\n",
            "Processing epoch: 551 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642124742269516\n",
            "Training loss:  \t 0.6198803573846817\n",
            "---------------\n",
            "Processing epoch: 552 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6430743038654327\n",
            "Training loss:  \t 0.6180716037750245\n",
            "---------------\n",
            "Processing epoch: 553 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412189602851868\n",
            "Training loss:  \t 0.618781965970993\n",
            "---------------\n",
            "Processing epoch: 554 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6418909728527069\n",
            "Training loss:  \t 0.6210718363523483\n",
            "---------------\n",
            "Processing epoch: 555 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414940655231476\n",
            "Training loss:  \t 0.6191532343626023\n",
            "---------------\n",
            "Processing epoch: 556 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6417256444692612\n",
            "Training loss:  \t 0.6198767960071564\n",
            "---------------\n",
            "Processing epoch: 557 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6435629278421402\n",
            "Training loss:  \t 0.6187496751546859\n",
            "---------------\n",
            "Processing epoch: 558 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406014561653137\n",
            "Training loss:  \t 0.6181286096572876\n",
            "---------------\n",
            "Processing epoch: 559 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419666260480881\n",
            "Training loss:  \t 0.6203013241291047\n",
            "---------------\n",
            "Processing epoch: 560 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398302912712097\n",
            "Training loss:  \t 0.6186255425214767\n",
            "---------------\n",
            "Processing epoch: 561 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412315368652344\n",
            "Training loss:  \t 0.6205556064844131\n",
            "---------------\n",
            "Processing epoch: 562 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422078609466553\n",
            "Training loss:  \t 0.6171802371740341\n",
            "---------------\n",
            "Processing epoch: 563 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409157365560532\n",
            "Training loss:  \t 0.6174237489700317\n",
            "---------------\n",
            "Processing epoch: 564 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408440619707108\n",
            "Training loss:  \t 0.6184478282928467\n",
            "---------------\n",
            "Processing epoch: 565 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425958573818207\n",
            "Training loss:  \t 0.6195978462696076\n",
            "---------------\n",
            "Processing epoch: 566 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6420397162437439\n",
            "Training loss:  \t 0.6178981870412826\n",
            "---------------\n",
            "Processing epoch: 567 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6416175216436386\n",
            "Training loss:  \t 0.6177682608366013\n",
            "---------------\n",
            "Processing epoch: 568 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436220556497574\n",
            "Training loss:  \t 0.6193506985902786\n",
            "---------------\n",
            "Processing epoch: 569 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402946561574936\n",
            "Training loss:  \t 0.61916543841362\n",
            "---------------\n",
            "Processing epoch: 570 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406411975622177\n",
            "Training loss:  \t 0.6185563027858734\n",
            "---------------\n",
            "Processing epoch: 571 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6426517814397812\n",
            "Training loss:  \t 0.6204149603843689\n",
            "---------------\n",
            "Processing epoch: 572 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641720324754715\n",
            "Training loss:  \t 0.6177599146962166\n",
            "---------------\n",
            "Processing epoch: 573 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642430454492569\n",
            "Training loss:  \t 0.6189992070198059\n",
            "---------------\n",
            "Processing epoch: 574 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409941464662552\n",
            "Training loss:  \t 0.619114165008068\n",
            "---------------\n",
            "Processing epoch: 575 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641587644815445\n",
            "Training loss:  \t 0.6186477094888687\n",
            "---------------\n",
            "Processing epoch: 576 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641749233007431\n",
            "Training loss:  \t 0.6180829286575318\n",
            "---------------\n",
            "Processing epoch: 577 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419394761323929\n",
            "Training loss:  \t 0.6166642606258392\n",
            "---------------\n",
            "Processing epoch: 578 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425716131925583\n",
            "Training loss:  \t 0.6180843532085418\n",
            "---------------\n",
            "Processing epoch: 579 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412683576345444\n",
            "Training loss:  \t 0.618351373076439\n",
            "---------------\n",
            "Processing epoch: 580 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6411621272563934\n",
            "Training loss:  \t 0.6175486251711846\n",
            "---------------\n",
            "Processing epoch: 581 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642886221408844\n",
            "Training loss:  \t 0.616027046740055\n",
            "---------------\n",
            "Processing epoch: 582 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408668458461761\n",
            "Training loss:  \t 0.61896832883358\n",
            "---------------\n",
            "Processing epoch: 583 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428337395191193\n",
            "Training loss:  \t 0.6196387439966202\n",
            "---------------\n",
            "Processing epoch: 584 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431849896907806\n",
            "Training loss:  \t 0.6157986089587212\n",
            "---------------\n",
            "Processing epoch: 585 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408792287111282\n",
            "Training loss:  \t 0.6180943757295608\n",
            "---------------\n",
            "Processing epoch: 586 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406607031822205\n",
            "Training loss:  \t 0.6163162976503372\n",
            "---------------\n",
            "Processing epoch: 587 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6443640142679214\n",
            "Training loss:  \t 0.6169191300868988\n",
            "---------------\n",
            "Processing epoch: 588 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6433338075876236\n",
            "Training loss:  \t 0.6166321754455566\n",
            "---------------\n",
            "Processing epoch: 589 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409383565187454\n",
            "Training loss:  \t 0.6152815341949462\n",
            "---------------\n",
            "Processing epoch: 590 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.640234962105751\n",
            "Training loss:  \t 0.6192860186100007\n",
            "---------------\n",
            "Processing epoch: 591 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6426921039819717\n",
            "Training loss:  \t 0.6171567857265472\n",
            "---------------\n",
            "Processing epoch: 592 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400247365236282\n",
            "Training loss:  \t 0.61979338824749\n",
            "---------------\n",
            "Processing epoch: 593 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436315774917603\n",
            "Training loss:  \t 0.6186961531639099\n",
            "---------------\n",
            "Processing epoch: 594 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422746479511261\n",
            "Training loss:  \t 0.6158374726772309\n",
            "---------------\n",
            "Processing epoch: 595 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6415953934192657\n",
            "Training loss:  \t 0.6166831269860268\n",
            "---------------\n",
            "Processing epoch: 596 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422930806875229\n",
            "Training loss:  \t 0.6222853779792785\n",
            "---------------\n",
            "Processing epoch: 597 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431149244308472\n",
            "Training loss:  \t 0.6163881659507752\n",
            "---------------\n",
            "Processing epoch: 598 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6415106356143951\n",
            "Training loss:  \t 0.6184891074895859\n",
            "---------------\n",
            "Processing epoch: 599 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419488340616226\n",
            "Training loss:  \t 0.6149877339601517\n",
            "---------------\n",
            "Processing epoch: 600 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6426487267017365\n",
            "Training loss:  \t 0.6173085987567901\n",
            "---------------\n",
            "Processing epoch: 601 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6394065618515015\n",
            "Training loss:  \t 0.6173329934477806\n",
            "---------------\n",
            "Processing epoch: 602 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414561718702316\n",
            "Training loss:  \t 0.6184832841157913\n",
            "---------------\n",
            "Processing epoch: 603 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440314054489136\n",
            "Training loss:  \t 0.6197958648204803\n",
            "---------------\n",
            "Processing epoch: 604 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642078697681427\n",
            "Training loss:  \t 0.6169526427984238\n",
            "---------------\n",
            "Processing epoch: 605 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639363244175911\n",
            "Training loss:  \t 0.6168213099241256\n",
            "---------------\n",
            "Processing epoch: 606 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406087875366211\n",
            "Training loss:  \t 0.6159297972917557\n",
            "---------------\n",
            "Processing epoch: 607 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428768634796143\n",
            "Training loss:  \t 0.6178911119699478\n",
            "---------------\n",
            "Processing epoch: 608 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419830620288849\n",
            "Training loss:  \t 0.6166173577308655\n",
            "---------------\n",
            "Processing epoch: 609 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409325152635574\n",
            "Training loss:  \t 0.615995991230011\n",
            "---------------\n",
            "Processing epoch: 610 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6417001783847809\n",
            "Training loss:  \t 0.6193326726555825\n",
            "---------------\n",
            "Processing epoch: 611 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6448139697313309\n",
            "Training loss:  \t 0.6152916729450226\n",
            "---------------\n",
            "Processing epoch: 612 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.64005146920681\n",
            "Training loss:  \t 0.6165563136339187\n",
            "---------------\n",
            "Processing epoch: 613 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414650678634644\n",
            "Training loss:  \t 0.616309005022049\n",
            "---------------\n",
            "Processing epoch: 614 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403652429580688\n",
            "Training loss:  \t 0.61395972520113\n",
            "---------------\n",
            "Processing epoch: 615 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6424664407968521\n",
            "Training loss:  \t 0.6165425479412079\n",
            "---------------\n",
            "Processing epoch: 616 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400624513626099\n",
            "Training loss:  \t 0.6167268604040146\n",
            "---------------\n",
            "Processing epoch: 617 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422538012266159\n",
            "Training loss:  \t 0.6148333698511124\n",
            "---------------\n",
            "Processing epoch: 618 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422520726919174\n",
            "Training loss:  \t 0.6217007249593735\n",
            "---------------\n",
            "Processing epoch: 619 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6416047960519791\n",
            "Training loss:  \t 0.6166360914707184\n",
            "---------------\n",
            "Processing epoch: 620 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397021412849426\n",
            "Training loss:  \t 0.6151285707950592\n",
            "---------------\n",
            "Processing epoch: 621 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6420817375183105\n",
            "Training loss:  \t 0.6170676857233047\n",
            "---------------\n",
            "Processing epoch: 622 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402813345193863\n",
            "Training loss:  \t 0.6162442803382874\n",
            "---------------\n",
            "Processing epoch: 623 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6405226439237595\n",
            "Training loss:  \t 0.6165102928876877\n",
            "---------------\n",
            "Processing epoch: 624 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6432101726531982\n",
            "Training loss:  \t 0.6170518800616265\n",
            "---------------\n",
            "Processing epoch: 625 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6445378214120865\n",
            "Training loss:  \t 0.6192855119705201\n",
            "---------------\n",
            "Processing epoch: 626 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410348117351532\n",
            "Training loss:  \t 0.6147144645452499\n",
            "---------------\n",
            "Processing epoch: 627 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407277137041092\n",
            "Training loss:  \t 0.6152635186910629\n",
            "---------------\n",
            "Processing epoch: 628 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422786712646484\n",
            "Training loss:  \t 0.6146400928497314\n",
            "---------------\n",
            "Processing epoch: 629 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414547115564346\n",
            "Training loss:  \t 0.614836597442627\n",
            "---------------\n",
            "Processing epoch: 630 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6396457701921463\n",
            "Training loss:  \t 0.6158881843090057\n",
            "---------------\n",
            "Processing epoch: 631 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402968913316727\n",
            "Training loss:  \t 0.6141773730516433\n",
            "---------------\n",
            "Processing epoch: 632 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414914578199387\n",
            "Training loss:  \t 0.6154671549797058\n",
            "---------------\n",
            "Processing epoch: 633 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639037549495697\n",
            "Training loss:  \t 0.6165739327669144\n",
            "---------------\n",
            "Processing epoch: 634 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401801258325577\n",
            "Training loss:  \t 0.6157184630632401\n",
            "---------------\n",
            "Processing epoch: 635 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403326541185379\n",
            "Training loss:  \t 0.6138762772083283\n",
            "---------------\n",
            "Processing epoch: 636 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428457796573639\n",
            "Training loss:  \t 0.6153611689805984\n",
            "---------------\n",
            "Processing epoch: 637 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401084214448929\n",
            "Training loss:  \t 0.6140448540449143\n",
            "---------------\n",
            "Processing epoch: 638 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407281160354614\n",
            "Training loss:  \t 0.6136008828878403\n",
            "---------------\n",
            "Processing epoch: 639 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6405700296163559\n",
            "Training loss:  \t 0.6148829817771911\n",
            "---------------\n",
            "Processing epoch: 640 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641449972987175\n",
            "Training loss:  \t 0.616305336356163\n",
            "---------------\n",
            "Processing epoch: 641 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406934708356857\n",
            "Training loss:  \t 0.6159157902002335\n",
            "---------------\n",
            "Processing epoch: 642 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419456601142883\n",
            "Training loss:  \t 0.6146281510591507\n",
            "---------------\n",
            "Processing epoch: 643 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419076323509216\n",
            "Training loss:  \t 0.6167204886674881\n",
            "---------------\n",
            "Processing epoch: 644 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398023217916489\n",
            "Training loss:  \t 0.6152128130197525\n",
            "---------------\n",
            "Processing epoch: 645 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419662088155746\n",
            "Training loss:  \t 0.6144063472747803\n",
            "---------------\n",
            "Processing epoch: 646 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6418308615684509\n",
            "Training loss:  \t 0.61519595682621\n",
            "---------------\n",
            "Processing epoch: 647 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398794203996658\n",
            "Training loss:  \t 0.6162387937307358\n",
            "---------------\n",
            "Processing epoch: 648 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406710743904114\n",
            "Training loss:  \t 0.6144577831029892\n",
            "---------------\n",
            "Processing epoch: 649 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641546830534935\n",
            "Training loss:  \t 0.6174714654684067\n",
            "---------------\n",
            "Processing epoch: 650 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431927531957626\n",
            "Training loss:  \t 0.6138077944517135\n",
            "---------------\n",
            "Processing epoch: 651 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641269326210022\n",
            "Training loss:  \t 0.6153926461935043\n",
            "---------------\n",
            "Processing epoch: 652 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6417758613824844\n",
            "Training loss:  \t 0.6135625630617142\n",
            "---------------\n",
            "Processing epoch: 653 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6404754966497421\n",
            "Training loss:  \t 0.614484629034996\n",
            "---------------\n",
            "Processing epoch: 654 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6415619105100632\n",
            "Training loss:  \t 0.6134507596492768\n",
            "---------------\n",
            "Processing epoch: 655 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409491449594498\n",
            "Training loss:  \t 0.6147057831287384\n",
            "---------------\n",
            "Processing epoch: 656 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6418962627649307\n",
            "Training loss:  \t 0.6138337910175323\n",
            "---------------\n",
            "Processing epoch: 657 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6424499750137329\n",
            "Training loss:  \t 0.6128547787666321\n",
            "---------------\n",
            "Processing epoch: 658 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393813341856003\n",
            "Training loss:  \t 0.6135346546769143\n",
            "---------------\n",
            "Processing epoch: 659 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641306608915329\n",
            "Training loss:  \t 0.6136869966983796\n",
            "---------------\n",
            "Processing epoch: 660 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412130147218704\n",
            "Training loss:  \t 0.6149370729923248\n",
            "---------------\n",
            "Processing epoch: 661 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412435472011566\n",
            "Training loss:  \t 0.6144638299942017\n",
            "---------------\n",
            "Processing epoch: 662 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398700177669525\n",
            "Training loss:  \t 0.6152787983417511\n",
            "---------------\n",
            "Processing epoch: 663 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6389695256948471\n",
            "Training loss:  \t 0.6142541527748108\n",
            "---------------\n",
            "Processing epoch: 664 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6429319828748703\n",
            "Training loss:  \t 0.6139772355556488\n",
            "---------------\n",
            "Processing epoch: 665 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419974863529205\n",
            "Training loss:  \t 0.6147233128547669\n",
            "---------------\n",
            "Processing epoch: 666 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427166908979416\n",
            "Training loss:  \t 0.6120129123330116\n",
            "---------------\n",
            "Processing epoch: 667 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409753113985062\n",
            "Training loss:  \t 0.6129996657371521\n",
            "---------------\n",
            "Processing epoch: 668 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397239863872528\n",
            "Training loss:  \t 0.611963203549385\n",
            "---------------\n",
            "Processing epoch: 669 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419976055622101\n",
            "Training loss:  \t 0.6135795041918755\n",
            "---------------\n",
            "Processing epoch: 670 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6395595371723175\n",
            "Training loss:  \t 0.6136223882436752\n",
            "---------------\n",
            "Processing epoch: 671 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408262401819229\n",
            "Training loss:  \t 0.6177717000246048\n",
            "---------------\n",
            "Processing epoch: 672 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6424938589334488\n",
            "Training loss:  \t 0.6144233822822571\n",
            "---------------\n",
            "Processing epoch: 673 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6413048505783081\n",
            "Training loss:  \t 0.6138270884752274\n",
            "---------------\n",
            "Processing epoch: 674 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642622634768486\n",
            "Training loss:  \t 0.6134032785892487\n",
            "---------------\n",
            "Processing epoch: 675 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391355246305466\n",
            "Training loss:  \t 0.6139122068881988\n",
            "---------------\n",
            "Processing epoch: 676 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6430216580629349\n",
            "Training loss:  \t 0.6137188106775284\n",
            "---------------\n",
            "Processing epoch: 677 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.640974834561348\n",
            "Training loss:  \t 0.6122976690530777\n",
            "---------------\n",
            "Processing epoch: 678 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407913714647293\n",
            "Training loss:  \t 0.6129805892705917\n",
            "---------------\n",
            "Processing epoch: 679 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414280086755753\n",
            "Training loss:  \t 0.6146744728088379\n",
            "---------------\n",
            "Processing epoch: 680 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6389050185680389\n",
            "Training loss:  \t 0.6127607941627502\n",
            "---------------\n",
            "Processing epoch: 681 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6423878818750381\n",
            "Training loss:  \t 0.6122245401144027\n",
            "---------------\n",
            "Processing epoch: 682 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641213908791542\n",
            "Training loss:  \t 0.6136777311563492\n",
            "---------------\n",
            "Processing epoch: 683 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427092403173447\n",
            "Training loss:  \t 0.6148795783519745\n",
            "---------------\n",
            "Processing epoch: 684 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638900637626648\n",
            "Training loss:  \t 0.6133951127529145\n",
            "---------------\n",
            "Processing epoch: 685 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412864625453949\n",
            "Training loss:  \t 0.6133066803216934\n",
            "---------------\n",
            "Processing epoch: 686 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428230702877045\n",
            "Training loss:  \t 0.612892997264862\n",
            "---------------\n",
            "Processing epoch: 687 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6405021846294403\n",
            "Training loss:  \t 0.614759761095047\n",
            "---------------\n",
            "Processing epoch: 688 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422917991876602\n",
            "Training loss:  \t 0.6171155154705048\n",
            "---------------\n",
            "Processing epoch: 689 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410449296236038\n",
            "Training loss:  \t 0.6131916716694832\n",
            "---------------\n",
            "Processing epoch: 690 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6433705687522888\n",
            "Training loss:  \t 0.6125609666109085\n",
            "---------------\n",
            "Processing epoch: 691 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428215950727463\n",
            "Training loss:  \t 0.6149528622627258\n",
            "---------------\n",
            "Processing epoch: 692 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638312503695488\n",
            "Training loss:  \t 0.6129826366901397\n",
            "---------------\n",
            "Processing epoch: 693 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408120691776276\n",
            "Training loss:  \t 0.613144439458847\n",
            "---------------\n",
            "Processing epoch: 694 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642324686050415\n",
            "Training loss:  \t 0.613246139883995\n",
            "---------------\n",
            "Processing epoch: 695 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6396288573741913\n",
            "Training loss:  \t 0.6135961383581161\n",
            "---------------\n",
            "Processing epoch: 696 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6425133794546127\n",
            "Training loss:  \t 0.6135411024093628\n",
            "---------------\n",
            "Processing epoch: 697 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6423006057739258\n",
            "Training loss:  \t 0.611250364780426\n",
            "---------------\n",
            "Processing epoch: 698 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410745978355408\n",
            "Training loss:  \t 0.6110132962465287\n",
            "---------------\n",
            "Processing epoch: 699 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6411849558353424\n",
            "Training loss:  \t 0.614228469133377\n",
            "---------------\n",
            "Processing epoch: 700 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412055492401123\n",
            "Training loss:  \t 0.611992084980011\n",
            "---------------\n",
            "Processing epoch: 701 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400356441736221\n",
            "Training loss:  \t 0.613960012793541\n",
            "---------------\n",
            "Processing epoch: 702 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641217976808548\n",
            "Training loss:  \t 0.6120787471532821\n",
            "---------------\n",
            "Processing epoch: 703 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406102180480957\n",
            "Training loss:  \t 0.6126380950212479\n",
            "---------------\n",
            "Processing epoch: 704 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397429257631302\n",
            "Training loss:  \t 0.6131180167198181\n",
            "---------------\n",
            "Processing epoch: 705 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6413150876760483\n",
            "Training loss:  \t 0.611466321349144\n",
            "---------------\n",
            "Processing epoch: 706 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638826996088028\n",
            "Training loss:  \t 0.6120309829711914\n",
            "---------------\n",
            "Processing epoch: 707 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414308845996857\n",
            "Training loss:  \t 0.6137819588184357\n",
            "---------------\n",
            "Processing epoch: 708 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6418338268995285\n",
            "Training loss:  \t 0.6109251797199249\n",
            "---------------\n",
            "Processing epoch: 709 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6404226422309875\n",
            "Training loss:  \t 0.6123614042997361\n",
            "---------------\n",
            "Processing epoch: 710 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412513107061386\n",
            "Training loss:  \t 0.6107038050889969\n",
            "---------------\n",
            "Processing epoch: 711 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406536102294922\n",
            "Training loss:  \t 0.6117876529693603\n",
            "---------------\n",
            "Processing epoch: 712 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402621567249298\n",
            "Training loss:  \t 0.6123793870210648\n",
            "---------------\n",
            "Processing epoch: 713 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406892091035843\n",
            "Training loss:  \t 0.6121982097625732\n",
            "---------------\n",
            "Processing epoch: 714 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6440975964069366\n",
            "Training loss:  \t 0.6151289969682694\n",
            "---------------\n",
            "Processing epoch: 715 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6415651887655258\n",
            "Training loss:  \t 0.6125318497419358\n",
            "---------------\n",
            "Processing epoch: 716 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414403170347214\n",
            "Training loss:  \t 0.6139619588851929\n",
            "---------------\n",
            "Processing epoch: 717 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6418170928955078\n",
            "Training loss:  \t 0.6119476735591889\n",
            "---------------\n",
            "Processing epoch: 718 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408900618553162\n",
            "Training loss:  \t 0.61228406727314\n",
            "---------------\n",
            "Processing epoch: 719 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6392758190631866\n",
            "Training loss:  \t 0.6132436141371727\n",
            "---------------\n",
            "Processing epoch: 720 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6416923552751541\n",
            "Training loss:  \t 0.6123232066631317\n",
            "---------------\n",
            "Processing epoch: 721 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.640062689781189\n",
            "Training loss:  \t 0.6145285367965698\n",
            "---------------\n",
            "Processing epoch: 722 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.643292561173439\n",
            "Training loss:  \t 0.6124937415122986\n",
            "---------------\n",
            "Processing epoch: 723 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401536166667938\n",
            "Training loss:  \t 0.6117944777011871\n",
            "---------------\n",
            "Processing epoch: 724 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402921676635742\n",
            "Training loss:  \t 0.6101808995008469\n",
            "---------------\n",
            "Processing epoch: 725 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6390729248523712\n",
            "Training loss:  \t 0.6115095317363739\n",
            "---------------\n",
            "Processing epoch: 726 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422142386436462\n",
            "Training loss:  \t 0.6131884157657623\n",
            "---------------\n",
            "Processing epoch: 727 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408663839101791\n",
            "Training loss:  \t 0.6125666320323944\n",
            "---------------\n",
            "Processing epoch: 728 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398219466209412\n",
            "Training loss:  \t 0.6108630746603012\n",
            "---------------\n",
            "Processing epoch: 729 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6405489593744278\n",
            "Training loss:  \t 0.6177666485309601\n",
            "---------------\n",
            "Processing epoch: 730 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407931596040726\n",
            "Training loss:  \t 0.6113463819026947\n",
            "---------------\n",
            "Processing epoch: 731 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6384366750717163\n",
            "Training loss:  \t 0.6104002147912979\n",
            "---------------\n",
            "Processing epoch: 732 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412251740694046\n",
            "Training loss:  \t 0.6137716323137283\n",
            "---------------\n",
            "Processing epoch: 733 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407018154859543\n",
            "Training loss:  \t 0.6110090672969818\n",
            "---------------\n",
            "Processing epoch: 734 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6405799686908722\n",
            "Training loss:  \t 0.6128076627850533\n",
            "---------------\n",
            "Processing epoch: 735 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6416947841644287\n",
            "Training loss:  \t 0.613565793633461\n",
            "---------------\n",
            "Processing epoch: 736 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393322050571442\n",
            "Training loss:  \t 0.6123846739530563\n",
            "---------------\n",
            "Processing epoch: 737 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6441958844661713\n",
            "Training loss:  \t 0.6105254054069519\n",
            "---------------\n",
            "Processing epoch: 738 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6429504156112671\n",
            "Training loss:  \t 0.6117348700761795\n",
            "---------------\n",
            "Processing epoch: 739 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6395486891269684\n",
            "Training loss:  \t 0.6134860992431641\n",
            "---------------\n",
            "Processing epoch: 740 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428909301757812\n",
            "Training loss:  \t 0.6149608284235001\n",
            "---------------\n",
            "Processing epoch: 741 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410440653562546\n",
            "Training loss:  \t 0.6085004881024361\n",
            "---------------\n",
            "Processing epoch: 742 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6394930481910706\n",
            "Training loss:  \t 0.6115133851766587\n",
            "---------------\n",
            "Processing epoch: 743 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6386230140924454\n",
            "Training loss:  \t 0.6121748507022857\n",
            "---------------\n",
            "Processing epoch: 744 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400519460439682\n",
            "Training loss:  \t 0.6152472779154777\n",
            "---------------\n",
            "Processing epoch: 745 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6392724961042404\n",
            "Training loss:  \t 0.611158873140812\n",
            "---------------\n",
            "Processing epoch: 746 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410310119390488\n",
            "Training loss:  \t 0.6128672868013382\n",
            "---------------\n",
            "Processing epoch: 747 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414596736431122\n",
            "Training loss:  \t 0.6140445604920387\n",
            "---------------\n",
            "Processing epoch: 748 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422451138496399\n",
            "Training loss:  \t 0.6120899990200996\n",
            "---------------\n",
            "Processing epoch: 749 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6413522958755493\n",
            "Training loss:  \t 0.6084739193320274\n",
            "---------------\n",
            "Processing epoch: 750 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6384375840425491\n",
            "Training loss:  \t 0.6121719688177109\n",
            "---------------\n",
            "Processing epoch: 751 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638929083943367\n",
            "Training loss:  \t 0.6120531857013702\n",
            "---------------\n",
            "Processing epoch: 752 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6415451169013977\n",
            "Training loss:  \t 0.6120951414108277\n",
            "---------------\n",
            "Processing epoch: 753 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6399782299995422\n",
            "Training loss:  \t 0.6107415050268173\n",
            "---------------\n",
            "Processing epoch: 754 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407126933336258\n",
            "Training loss:  \t 0.6118087053298951\n",
            "---------------\n",
            "Processing epoch: 755 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422303915023804\n",
            "Training loss:  \t 0.6170135408639907\n",
            "---------------\n",
            "Processing epoch: 756 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.64129838347435\n",
            "Training loss:  \t 0.6149304434657097\n",
            "---------------\n",
            "Processing epoch: 757 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6421860009431839\n",
            "Training loss:  \t 0.6123237937688828\n",
            "---------------\n",
            "Processing epoch: 758 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401610672473907\n",
            "Training loss:  \t 0.6110176652669906\n",
            "---------------\n",
            "Processing epoch: 759 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6421678960323334\n",
            "Training loss:  \t 0.6109790146350861\n",
            "---------------\n",
            "Processing epoch: 760 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400135904550552\n",
            "Training loss:  \t 0.608960497379303\n",
            "---------------\n",
            "Processing epoch: 761 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397754997014999\n",
            "Training loss:  \t 0.6115330994129181\n",
            "---------------\n",
            "Processing epoch: 762 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6439471691846848\n",
            "Training loss:  \t 0.6105275362730026\n",
            "---------------\n",
            "Processing epoch: 763 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431514769792557\n",
            "Training loss:  \t 0.6117948651313782\n",
            "---------------\n",
            "Processing epoch: 764 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401848047971725\n",
            "Training loss:  \t 0.6087326437234879\n",
            "---------------\n",
            "Processing epoch: 765 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410204917192459\n",
            "Training loss:  \t 0.6103525042533875\n",
            "---------------\n",
            "Processing epoch: 766 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412412524223328\n",
            "Training loss:  \t 0.61030592918396\n",
            "---------------\n",
            "Processing epoch: 767 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409429460763931\n",
            "Training loss:  \t 0.6109582155942916\n",
            "---------------\n",
            "Processing epoch: 768 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6377806961536407\n",
            "Training loss:  \t 0.610084056854248\n",
            "---------------\n",
            "Processing epoch: 769 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6394891738891602\n",
            "Training loss:  \t 0.6093895673751831\n",
            "---------------\n",
            "Processing epoch: 770 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407184600830078\n",
            "Training loss:  \t 0.6109387069940567\n",
            "---------------\n",
            "Processing epoch: 771 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414017826318741\n",
            "Training loss:  \t 0.6101280957460403\n",
            "---------------\n",
            "Processing epoch: 772 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406101137399673\n",
            "Training loss:  \t 0.609228128194809\n",
            "---------------\n",
            "Processing epoch: 773 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403606832027435\n",
            "Training loss:  \t 0.6104481548070908\n",
            "---------------\n",
            "Processing epoch: 774 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402331739664078\n",
            "Training loss:  \t 0.6099620729684829\n",
            "---------------\n",
            "Processing epoch: 775 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6387455463409424\n",
            "Training loss:  \t 0.6099690198898315\n",
            "---------------\n",
            "Processing epoch: 776 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6379176080226898\n",
            "Training loss:  \t 0.6093001008033753\n",
            "---------------\n",
            "Processing epoch: 777 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406131237745285\n",
            "Training loss:  \t 0.6106004029512405\n",
            "---------------\n",
            "Processing epoch: 778 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.64029860496521\n",
            "Training loss:  \t 0.6088041752576828\n",
            "---------------\n",
            "Processing epoch: 779 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6414107531309128\n",
            "Training loss:  \t 0.6110441297292709\n",
            "---------------\n",
            "Processing epoch: 780 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6419082880020142\n",
            "Training loss:  \t 0.6111028969287873\n",
            "---------------\n",
            "Processing epoch: 781 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401677280664444\n",
            "Training loss:  \t 0.6097501665353775\n",
            "---------------\n",
            "Processing epoch: 782 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6378157585859299\n",
            "Training loss:  \t 0.612167875468731\n",
            "---------------\n",
            "Processing epoch: 783 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6438543200492859\n",
            "Training loss:  \t 0.6101334393024445\n",
            "---------------\n",
            "Processing epoch: 784 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639924556016922\n",
            "Training loss:  \t 0.6100390166044235\n",
            "---------------\n",
            "Processing epoch: 785 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6375552266836166\n",
            "Training loss:  \t 0.6081542924046517\n",
            "---------------\n",
            "Processing epoch: 786 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6430826485157013\n",
            "Training loss:  \t 0.6110118269920349\n",
            "---------------\n",
            "Processing epoch: 787 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397988796234131\n",
            "Training loss:  \t 0.610507795214653\n",
            "---------------\n",
            "Processing epoch: 788 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401640027761459\n",
            "Training loss:  \t 0.6090636998414993\n",
            "---------------\n",
            "Processing epoch: 789 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.640412300825119\n",
            "Training loss:  \t 0.6089301526546478\n",
            "---------------\n",
            "Processing epoch: 790 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6369668543338776\n",
            "Training loss:  \t 0.6093584895133972\n",
            "---------------\n",
            "Processing epoch: 791 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6385050714015961\n",
            "Training loss:  \t 0.6107401639223099\n",
            "---------------\n",
            "Processing epoch: 792 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.642242044210434\n",
            "Training loss:  \t 0.6080670788884163\n",
            "---------------\n",
            "Processing epoch: 793 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6418473571538925\n",
            "Training loss:  \t 0.610601669549942\n",
            "---------------\n",
            "Processing epoch: 794 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403877437114716\n",
            "Training loss:  \t 0.6087899953126907\n",
            "---------------\n",
            "Processing epoch: 795 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6431004554033279\n",
            "Training loss:  \t 0.6092921108007431\n",
            "---------------\n",
            "Processing epoch: 796 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6392718404531479\n",
            "Training loss:  \t 0.6089430660009384\n",
            "---------------\n",
            "Processing epoch: 797 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410363018512726\n",
            "Training loss:  \t 0.6091724455356597\n",
            "---------------\n",
            "Processing epoch: 798 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6390663683414459\n",
            "Training loss:  \t 0.6101486951112747\n",
            "---------------\n",
            "Processing epoch: 799 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400410830974579\n",
            "Training loss:  \t 0.6078390926122665\n",
            "---------------\n",
            "Processing epoch: 800 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.640068769454956\n",
            "Training loss:  \t 0.6100268989801407\n",
            "---------------\n",
            "Processing epoch: 801 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409134268760681\n",
            "Training loss:  \t 0.6089767813682556\n",
            "---------------\n",
            "Processing epoch: 802 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393202990293503\n",
            "Training loss:  \t 0.6087518602609634\n",
            "---------------\n",
            "Processing epoch: 803 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6421462446451187\n",
            "Training loss:  \t 0.6097077339887619\n",
            "---------------\n",
            "Processing epoch: 804 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6387075036764145\n",
            "Training loss:  \t 0.6108457192778587\n",
            "---------------\n",
            "Processing epoch: 805 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6422458440065384\n",
            "Training loss:  \t 0.6090293884277344\n",
            "---------------\n",
            "Processing epoch: 806 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393954753875732\n",
            "Training loss:  \t 0.6084083080291748\n",
            "---------------\n",
            "Processing epoch: 807 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412105709314346\n",
            "Training loss:  \t 0.6089673429727555\n",
            "---------------\n",
            "Processing epoch: 808 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6387839466333389\n",
            "Training loss:  \t 0.6084032252430915\n",
            "---------------\n",
            "Processing epoch: 809 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6394992619752884\n",
            "Training loss:  \t 0.6086642444133759\n",
            "---------------\n",
            "Processing epoch: 810 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6428480744361877\n",
            "Training loss:  \t 0.609595388174057\n",
            "---------------\n",
            "Processing epoch: 811 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6369219869375229\n",
            "Training loss:  \t 0.6109688013792038\n",
            "---------------\n",
            "Processing epoch: 812 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639588251709938\n",
            "Training loss:  \t 0.6090202778577805\n",
            "---------------\n",
            "Processing epoch: 813 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6410712748765945\n",
            "Training loss:  \t 0.6083812147378922\n",
            "---------------\n",
            "Processing epoch: 814 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407133340835571\n",
            "Training loss:  \t 0.6097979784011841\n",
            "---------------\n",
            "Processing epoch: 815 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391503065824509\n",
            "Training loss:  \t 0.607403390109539\n",
            "---------------\n",
            "Processing epoch: 816 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6413671970367432\n",
            "Training loss:  \t 0.6088998198509217\n",
            "---------------\n",
            "Processing epoch: 817 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391410082578659\n",
            "Training loss:  \t 0.6071380764245987\n",
            "---------------\n",
            "Processing epoch: 818 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6415799111127853\n",
            "Training loss:  \t 0.6090836554765702\n",
            "---------------\n",
            "Processing epoch: 819 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6394256204366684\n",
            "Training loss:  \t 0.6101582139730454\n",
            "---------------\n",
            "Processing epoch: 820 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6390519738197327\n",
            "Training loss:  \t 0.6099620908498764\n",
            "---------------\n",
            "Processing epoch: 821 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391305327415466\n",
            "Training loss:  \t 0.6069348871707916\n",
            "---------------\n",
            "Processing epoch: 822 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6421287208795547\n",
            "Training loss:  \t 0.6080253690481185\n",
            "---------------\n",
            "Processing epoch: 823 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381324678659439\n",
            "Training loss:  \t 0.6068955838680268\n",
            "---------------\n",
            "Processing epoch: 824 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401103883981705\n",
            "Training loss:  \t 0.6117053478956223\n",
            "---------------\n",
            "Processing epoch: 825 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436221450567245\n",
            "Training loss:  \t 0.6133360952138901\n",
            "---------------\n",
            "Processing epoch: 826 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6389555335044861\n",
            "Training loss:  \t 0.6094636589288711\n",
            "---------------\n",
            "Processing epoch: 827 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391246914863586\n",
            "Training loss:  \t 0.6082042306661606\n",
            "---------------\n",
            "Processing epoch: 828 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6370754390954971\n",
            "Training loss:  \t 0.6103468805551528\n",
            "---------------\n",
            "Processing epoch: 829 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412364840507507\n",
            "Training loss:  \t 0.6069086343050003\n",
            "---------------\n",
            "Processing epoch: 830 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6399544924497604\n",
            "Training loss:  \t 0.6097806587815284\n",
            "---------------\n",
            "Processing epoch: 831 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638680636882782\n",
            "Training loss:  \t 0.6099353432655334\n",
            "---------------\n",
            "Processing epoch: 832 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6427128463983536\n",
            "Training loss:  \t 0.611333817243576\n",
            "---------------\n",
            "Processing epoch: 833 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393412947654724\n",
            "Training loss:  \t 0.6079578578472138\n",
            "---------------\n",
            "Processing epoch: 834 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6376800984144211\n",
            "Training loss:  \t 0.6092316389083863\n",
            "---------------\n",
            "Processing epoch: 835 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408875435590744\n",
            "Training loss:  \t 0.6080663084983826\n",
            "---------------\n",
            "Processing epoch: 836 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6382217109203339\n",
            "Training loss:  \t 0.606859914958477\n",
            "---------------\n",
            "Processing epoch: 837 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6380002051591873\n",
            "Training loss:  \t 0.6074548035860061\n",
            "---------------\n",
            "Processing epoch: 838 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639896959066391\n",
            "Training loss:  \t 0.6067890226840973\n",
            "---------------\n",
            "Processing epoch: 839 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6394459158182144\n",
            "Training loss:  \t 0.6079725116491318\n",
            "---------------\n",
            "Processing epoch: 840 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398893147706985\n",
            "Training loss:  \t 0.6140223890542984\n",
            "---------------\n",
            "Processing epoch: 841 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6420212835073471\n",
            "Training loss:  \t 0.6049930095672608\n",
            "---------------\n",
            "Processing epoch: 842 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407118439674377\n",
            "Training loss:  \t 0.607641227543354\n",
            "---------------\n",
            "Processing epoch: 843 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391153335571289\n",
            "Training loss:  \t 0.6095633178949356\n",
            "---------------\n",
            "Processing epoch: 844 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6380318254232407\n",
            "Training loss:  \t 0.6094772279262543\n",
            "---------------\n",
            "Processing epoch: 845 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6421299278736115\n",
            "Training loss:  \t 0.6092362523078918\n",
            "---------------\n",
            "Processing epoch: 846 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407096683979034\n",
            "Training loss:  \t 0.6090936124324798\n",
            "---------------\n",
            "Processing epoch: 847 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398330926895142\n",
            "Training loss:  \t 0.6060519397258759\n",
            "---------------\n",
            "Processing epoch: 848 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6395300030708313\n",
            "Training loss:  \t 0.6097544372081757\n",
            "---------------\n",
            "Processing epoch: 849 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6389386355876923\n",
            "Training loss:  \t 0.6082096308469772\n",
            "---------------\n",
            "Processing epoch: 850 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6386243999004364\n",
            "Training loss:  \t 0.6077318578958512\n",
            "---------------\n",
            "Processing epoch: 851 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6396118849515915\n",
            "Training loss:  \t 0.6064623355865478\n",
            "---------------\n",
            "Processing epoch: 852 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6408222317695618\n",
            "Training loss:  \t 0.607364884018898\n",
            "---------------\n",
            "Processing epoch: 853 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6364599168300629\n",
            "Training loss:  \t 0.6071610659360885\n",
            "---------------\n",
            "Processing epoch: 854 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6378622949123383\n",
            "Training loss:  \t 0.6092896670103073\n",
            "---------------\n",
            "Processing epoch: 855 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398046910762787\n",
            "Training loss:  \t 0.6116097331047058\n",
            "---------------\n",
            "Processing epoch: 856 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6389862895011902\n",
            "Training loss:  \t 0.6106670707464218\n",
            "---------------\n",
            "Processing epoch: 857 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6373989135026932\n",
            "Training loss:  \t 0.6069769442081452\n",
            "---------------\n",
            "Processing epoch: 858 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6404053419828415\n",
            "Training loss:  \t 0.6067050039768219\n",
            "---------------\n",
            "Processing epoch: 859 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6417626142501831\n",
            "Training loss:  \t 0.6081363320350647\n",
            "---------------\n",
            "Processing epoch: 860 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407632380723953\n",
            "Training loss:  \t 0.6071622312068939\n",
            "---------------\n",
            "Processing epoch: 861 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6375619620084763\n",
            "Training loss:  \t 0.6077565222978591\n",
            "---------------\n",
            "Processing epoch: 862 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6406901627779007\n",
            "Training loss:  \t 0.608400821685791\n",
            "---------------\n",
            "Processing epoch: 863 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6363513022661209\n",
            "Training loss:  \t 0.6052895963191987\n",
            "---------------\n",
            "Processing epoch: 864 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6392045319080353\n",
            "Training loss:  \t 0.6081489294767379\n",
            "---------------\n",
            "Processing epoch: 865 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401806622743607\n",
            "Training loss:  \t 0.6062621951103211\n",
            "---------------\n",
            "Processing epoch: 866 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6388661116361618\n",
            "Training loss:  \t 0.6088035851716995\n",
            "---------------\n",
            "Processing epoch: 867 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6395363062620163\n",
            "Training loss:  \t 0.6068797320127487\n",
            "---------------\n",
            "Processing epoch: 868 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6409067958593369\n",
            "Training loss:  \t 0.606955561041832\n",
            "---------------\n",
            "Processing epoch: 869 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393655389547348\n",
            "Training loss:  \t 0.6063465684652328\n",
            "---------------\n",
            "Processing epoch: 870 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6379569619894028\n",
            "Training loss:  \t 0.605786669254303\n",
            "---------------\n",
            "Processing epoch: 871 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6429291665554047\n",
            "Training loss:  \t 0.608820466697216\n",
            "---------------\n",
            "Processing epoch: 872 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381492912769318\n",
            "Training loss:  \t 0.6081103563308716\n",
            "---------------\n",
            "Processing epoch: 873 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6401343643665314\n",
            "Training loss:  \t 0.6070565074682236\n",
            "---------------\n",
            "Processing epoch: 874 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.636966273188591\n",
            "Training loss:  \t 0.6054860264062881\n",
            "---------------\n",
            "Processing epoch: 875 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6383236348628998\n",
            "Training loss:  \t 0.6097765490412712\n",
            "---------------\n",
            "Processing epoch: 876 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6413474231958389\n",
            "Training loss:  \t 0.6060830086469651\n",
            "---------------\n",
            "Processing epoch: 877 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6385473906993866\n",
            "Training loss:  \t 0.6040675148367882\n",
            "---------------\n",
            "Processing epoch: 878 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.640562117099762\n",
            "Training loss:  \t 0.606020936369896\n",
            "---------------\n",
            "Processing epoch: 879 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6356734037399292\n",
            "Training loss:  \t 0.6051228612661361\n",
            "---------------\n",
            "Processing epoch: 880 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397279053926468\n",
            "Training loss:  \t 0.6053054213523865\n",
            "---------------\n",
            "Processing epoch: 881 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403806805610657\n",
            "Training loss:  \t 0.6066682949662209\n",
            "---------------\n",
            "Processing epoch: 882 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639536663889885\n",
            "Training loss:  \t 0.6035921692848205\n",
            "---------------\n",
            "Processing epoch: 883 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391979902982712\n",
            "Training loss:  \t 0.6068553656339646\n",
            "---------------\n",
            "Processing epoch: 884 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6369941234588623\n",
            "Training loss:  \t 0.605929359793663\n",
            "---------------\n",
            "Processing epoch: 885 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6399289965629578\n",
            "Training loss:  \t 0.6074373811483383\n",
            "---------------\n",
            "Processing epoch: 886 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6400254219770432\n",
            "Training loss:  \t 0.6046444416046143\n",
            "---------------\n",
            "Processing epoch: 887 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.637815847992897\n",
            "Training loss:  \t 0.6060716420412063\n",
            "---------------\n",
            "Processing epoch: 888 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6392692625522614\n",
            "Training loss:  \t 0.6062296062707901\n",
            "---------------\n",
            "Processing epoch: 889 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6412675827741623\n",
            "Training loss:  \t 0.6048959255218506\n",
            "---------------\n",
            "Processing epoch: 890 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638715386390686\n",
            "Training loss:  \t 0.6052928000688553\n",
            "---------------\n",
            "Processing epoch: 891 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6403350234031677\n",
            "Training loss:  \t 0.6068634301424026\n",
            "---------------\n",
            "Processing epoch: 892 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6396678984165192\n",
            "Training loss:  \t 0.6057158857584\n",
            "---------------\n",
            "Processing epoch: 893 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6374422460794449\n",
            "Training loss:  \t 0.6051404535770416\n",
            "---------------\n",
            "Processing epoch: 894 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6384716480970383\n",
            "Training loss:  \t 0.6064878508448601\n",
            "---------------\n",
            "Processing epoch: 895 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6394652426242828\n",
            "Training loss:  \t 0.606524994969368\n",
            "---------------\n",
            "Processing epoch: 896 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6436746269464493\n",
            "Training loss:  \t 0.6080000072717666\n",
            "---------------\n",
            "Processing epoch: 897 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6363838613033295\n",
            "Training loss:  \t 0.6064364820718765\n",
            "---------------\n",
            "Processing epoch: 898 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391977816820145\n",
            "Training loss:  \t 0.6061135113239289\n",
            "---------------\n",
            "Processing epoch: 899 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639183759689331\n",
            "Training loss:  \t 0.6041125923395156\n",
            "---------------\n",
            "Processing epoch: 900 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6413142085075378\n",
            "Training loss:  \t 0.6070371925830841\n",
            "---------------\n",
            "Processing epoch: 901 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6378514617681503\n",
            "Training loss:  \t 0.6058645278215409\n",
            "---------------\n",
            "Processing epoch: 902 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6374643296003342\n",
            "Training loss:  \t 0.6062086910009384\n",
            "---------------\n",
            "Processing epoch: 903 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6369830071926117\n",
            "Training loss:  \t 0.6047868520021439\n",
            "---------------\n",
            "Processing epoch: 904 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381351798772812\n",
            "Training loss:  \t 0.6065373361110687\n",
            "---------------\n",
            "Processing epoch: 905 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.639953151345253\n",
            "Training loss:  \t 0.604063606262207\n",
            "---------------\n",
            "Processing epoch: 906 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638828694820404\n",
            "Training loss:  \t 0.6069501340389252\n",
            "---------------\n",
            "Processing epoch: 907 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6385838538408279\n",
            "Training loss:  \t 0.6061621457338333\n",
            "---------------\n",
            "Processing epoch: 908 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6367996335029602\n",
            "Training loss:  \t 0.606115473806858\n",
            "---------------\n",
            "Processing epoch: 909 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393582224845886\n",
            "Training loss:  \t 0.6071129769086838\n",
            "---------------\n",
            "Processing epoch: 910 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6366524249315262\n",
            "Training loss:  \t 0.6072405070066452\n",
            "---------------\n",
            "Processing epoch: 911 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381074637174606\n",
            "Training loss:  \t 0.6110706210136414\n",
            "---------------\n",
            "Processing epoch: 912 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6371539235115051\n",
            "Training loss:  \t 0.6097719296813011\n",
            "---------------\n",
            "Processing epoch: 913 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6390444338321686\n",
            "Training loss:  \t 0.6043102219700813\n",
            "---------------\n",
            "Processing epoch: 914 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6359659284353256\n",
            "Training loss:  \t 0.6059463262557984\n",
            "---------------\n",
            "Processing epoch: 915 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6362515985965729\n",
            "Training loss:  \t 0.6077952057123184\n",
            "---------------\n",
            "Processing epoch: 916 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6392446011304855\n",
            "Training loss:  \t 0.6077765464782715\n",
            "---------------\n",
            "Processing epoch: 917 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6386871486902237\n",
            "Training loss:  \t 0.6057071089744568\n",
            "---------------\n",
            "Processing epoch: 918 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6384965479373932\n",
            "Training loss:  \t 0.6057838588953018\n",
            "---------------\n",
            "Processing epoch: 919 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6364053189754486\n",
            "Training loss:  \t 0.6108792334794998\n",
            "---------------\n",
            "Processing epoch: 920 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.635888859629631\n",
            "Training loss:  \t 0.6053158491849899\n",
            "---------------\n",
            "Processing epoch: 921 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6379139721393585\n",
            "Training loss:  \t 0.60896215736866\n",
            "---------------\n",
            "Processing epoch: 922 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6349596530199051\n",
            "Training loss:  \t 0.6043251901865005\n",
            "---------------\n",
            "Processing epoch: 923 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.637170672416687\n",
            "Training loss:  \t 0.604766309261322\n",
            "---------------\n",
            "Processing epoch: 924 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6355742961168289\n",
            "Training loss:  \t 0.6061839312314987\n",
            "---------------\n",
            "Processing epoch: 925 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6350409165024757\n",
            "Training loss:  \t 0.6054833561182023\n",
            "---------------\n",
            "Processing epoch: 926 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6364366710186005\n",
            "Training loss:  \t 0.6064111456274986\n",
            "---------------\n",
            "Processing epoch: 927 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.641552522778511\n",
            "Training loss:  \t 0.6081323444843292\n",
            "---------------\n",
            "Processing epoch: 928 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6386973112821579\n",
            "Training loss:  \t 0.6063233882188797\n",
            "---------------\n",
            "Processing epoch: 929 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6375572383403778\n",
            "Training loss:  \t 0.604003083705902\n",
            "---------------\n",
            "Processing epoch: 930 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6338236182928085\n",
            "Training loss:  \t 0.605125880241394\n",
            "---------------\n",
            "Processing epoch: 931 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6357018947601318\n",
            "Training loss:  \t 0.6049980819225311\n",
            "---------------\n",
            "Processing epoch: 932 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6345243901014328\n",
            "Training loss:  \t 0.6045173913240433\n",
            "---------------\n",
            "Processing epoch: 933 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6365863382816315\n",
            "Training loss:  \t 0.6058754354715348\n",
            "---------------\n",
            "Processing epoch: 934 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6365775316953659\n",
            "Training loss:  \t 0.6043228596448899\n",
            "---------------\n",
            "Processing epoch: 935 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6341882944107056\n",
            "Training loss:  \t 0.6042615890502929\n",
            "---------------\n",
            "Processing epoch: 936 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6361765712499619\n",
            "Training loss:  \t 0.6046908348798752\n",
            "---------------\n",
            "Processing epoch: 937 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6392830312252045\n",
            "Training loss:  \t 0.604984900355339\n",
            "---------------\n",
            "Processing epoch: 938 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.634331226348877\n",
            "Training loss:  \t 0.6049816995859146\n",
            "---------------\n",
            "Processing epoch: 939 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393951773643494\n",
            "Training loss:  \t 0.6040123596787452\n",
            "---------------\n",
            "Processing epoch: 940 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6357793509960175\n",
            "Training loss:  \t 0.6035599142313004\n",
            "---------------\n",
            "Processing epoch: 941 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6380247622728348\n",
            "Training loss:  \t 0.6048662886023521\n",
            "---------------\n",
            "Processing epoch: 942 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6383986175060272\n",
            "Training loss:  \t 0.6033766299486161\n",
            "---------------\n",
            "Processing epoch: 943 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6387038677930832\n",
            "Training loss:  \t 0.6022185415029526\n",
            "---------------\n",
            "Processing epoch: 944 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6362507790327072\n",
            "Training loss:  \t 0.6051343500614166\n",
            "---------------\n",
            "Processing epoch: 945 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6366625130176544\n",
            "Training loss:  \t 0.6047137618064881\n",
            "---------------\n",
            "Processing epoch: 946 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6347997784614563\n",
            "Training loss:  \t 0.6049406975507736\n",
            "---------------\n",
            "Processing epoch: 947 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6374856382608414\n",
            "Training loss:  \t 0.6067716300487518\n",
            "---------------\n",
            "Processing epoch: 948 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6367145925760269\n",
            "Training loss:  \t 0.6054538011550903\n",
            "---------------\n",
            "Processing epoch: 949 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397963166236877\n",
            "Training loss:  \t 0.6052889883518219\n",
            "---------------\n",
            "Processing epoch: 950 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381263434886932\n",
            "Training loss:  \t 0.6070749193429947\n",
            "---------------\n",
            "Processing epoch: 951 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.637632355093956\n",
            "Training loss:  \t 0.6044263988733292\n",
            "---------------\n",
            "Processing epoch: 952 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6362011432647705\n",
            "Training loss:  \t 0.6065674096345901\n",
            "---------------\n",
            "Processing epoch: 953 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6370909065008163\n",
            "Training loss:  \t 0.6044721990823746\n",
            "---------------\n",
            "Processing epoch: 954 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6357748955488205\n",
            "Training loss:  \t 0.6059430703520775\n",
            "---------------\n",
            "Processing epoch: 955 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6372841596603394\n",
            "Training loss:  \t 0.6036883592605591\n",
            "---------------\n",
            "Processing epoch: 956 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.635699138045311\n",
            "Training loss:  \t 0.6048873826861382\n",
            "---------------\n",
            "Processing epoch: 957 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6372225731611252\n",
            "Training loss:  \t 0.6017897188663482\n",
            "---------------\n",
            "Processing epoch: 958 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6362841576337814\n",
            "Training loss:  \t 0.6039103820919991\n",
            "---------------\n",
            "Processing epoch: 959 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6383822411298752\n",
            "Training loss:  \t 0.6079644799232483\n",
            "---------------\n",
            "Processing epoch: 960 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6386325359344482\n",
            "Training loss:  \t 0.605702567100525\n",
            "---------------\n",
            "Processing epoch: 961 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6380346119403839\n",
            "Training loss:  \t 0.6074745208024979\n",
            "---------------\n",
            "Processing epoch: 962 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6390498727560043\n",
            "Training loss:  \t 0.6052682220935821\n",
            "---------------\n",
            "Processing epoch: 963 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6352085918188095\n",
            "Training loss:  \t 0.6033510565757751\n",
            "---------------\n",
            "Processing epoch: 964 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6378274708986282\n",
            "Training loss:  \t 0.6021260768175125\n",
            "---------------\n",
            "Processing epoch: 965 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6349667012691498\n",
            "Training loss:  \t 0.6038297146558762\n",
            "---------------\n",
            "Processing epoch: 966 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6383273005485535\n",
            "Training loss:  \t 0.6061707466840744\n",
            "---------------\n",
            "Processing epoch: 967 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6332709789276123\n",
            "Training loss:  \t 0.6019178092479706\n",
            "---------------\n",
            "Processing epoch: 968 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6345405578613281\n",
            "Training loss:  \t 0.603433421254158\n",
            "---------------\n",
            "Processing epoch: 969 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.63605035841465\n",
            "Training loss:  \t 0.6049662798643112\n",
            "---------------\n",
            "Processing epoch: 970 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381756365299225\n",
            "Training loss:  \t 0.6034034043550491\n",
            "---------------\n",
            "Processing epoch: 971 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6342137902975082\n",
            "Training loss:  \t 0.6053929418325424\n",
            "---------------\n",
            "Processing epoch: 972 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6373009085655212\n",
            "Training loss:  \t 0.6046554148197174\n",
            "---------------\n",
            "Processing epoch: 973 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6370439529418945\n",
            "Training loss:  \t 0.6039210453629493\n",
            "---------------\n",
            "Processing epoch: 974 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6364281326532364\n",
            "Training loss:  \t 0.6020202741026879\n",
            "---------------\n",
            "Processing epoch: 975 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6376517415046692\n",
            "Training loss:  \t 0.6077201396226883\n",
            "---------------\n",
            "Processing epoch: 976 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6380519717931747\n",
            "Training loss:  \t 0.6043758913874626\n",
            "---------------\n",
            "Processing epoch: 977 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6333110481500626\n",
            "Training loss:  \t 0.6039936035871506\n",
            "---------------\n",
            "Processing epoch: 978 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.634702205657959\n",
            "Training loss:  \t 0.6059745281934739\n",
            "---------------\n",
            "Processing epoch: 979 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6402193158864975\n",
            "Training loss:  \t 0.6051840275526047\n",
            "---------------\n",
            "Processing epoch: 980 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6360295414924622\n",
            "Training loss:  \t 0.604859621822834\n",
            "---------------\n",
            "Processing epoch: 981 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638319656252861\n",
            "Training loss:  \t 0.6046437427401543\n",
            "---------------\n",
            "Processing epoch: 982 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6343047171831131\n",
            "Training loss:  \t 0.6027627795934677\n",
            "---------------\n",
            "Processing epoch: 983 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6391158699989319\n",
            "Training loss:  \t 0.6017784774303436\n",
            "---------------\n",
            "Processing epoch: 984 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6340900212526321\n",
            "Training loss:  \t 0.6031492084264756\n",
            "---------------\n",
            "Processing epoch: 985 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6365002691745758\n",
            "Training loss:  \t 0.6039463341236114\n",
            "---------------\n",
            "Processing epoch: 986 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6362763196229935\n",
            "Training loss:  \t 0.6052382409572601\n",
            "---------------\n",
            "Processing epoch: 987 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6381756663322449\n",
            "Training loss:  \t 0.6046422153711319\n",
            "---------------\n",
            "Processing epoch: 988 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6359160095453262\n",
            "Training loss:  \t 0.6041196301579476\n",
            "---------------\n",
            "Processing epoch: 989 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6338102221488953\n",
            "Training loss:  \t 0.6025020390748977\n",
            "---------------\n",
            "Processing epoch: 990 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6397432535886765\n",
            "Training loss:  \t 0.6032748490571975\n",
            "---------------\n",
            "Processing epoch: 991 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6340562254190445\n",
            "Training loss:  \t 0.610643221437931\n",
            "---------------\n",
            "Processing epoch: 992 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.636762723326683\n",
            "Training loss:  \t 0.6032411873340606\n",
            "---------------\n",
            "Processing epoch: 993 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6358593106269836\n",
            "Training loss:  \t 0.6038422048091888\n",
            "---------------\n",
            "Processing epoch: 994 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6398353278636932\n",
            "Training loss:  \t 0.6037123382091523\n",
            "---------------\n",
            "Processing epoch: 995 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6364689618349075\n",
            "Training loss:  \t 0.6030811816453934\n",
            "---------------\n",
            "Processing epoch: 996 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6354781985282898\n",
            "Training loss:  \t 0.6044609561562538\n",
            "---------------\n",
            "Processing epoch: 997 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6359089463949203\n",
            "Training loss:  \t 0.6038758486509324\n",
            "---------------\n",
            "Processing epoch: 998 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6407753229141235\n",
            "Training loss:  \t 0.6031993567943573\n",
            "---------------\n",
            "Processing epoch: 999 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.638574555516243\n",
            "Training loss:  \t 0.60852010846138\n",
            "---------------\n",
            "Processing epoch: 1000 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.637270450592041\n",
            "Training loss:  \t 0.6057480096817016\n",
            "---------------\n",
            "Processing epoch: 1001 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.636634573340416\n",
            "Training loss:  \t 0.603091961145401\n",
            "---------------\n",
            "Processing epoch: 1002 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6354858577251434\n",
            "Training loss:  \t 0.6024098932743073\n",
            "---------------\n",
            "Processing epoch: 1003 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.636022761464119\n",
            "Training loss:  \t 0.6037383273243904\n",
            "---------------\n",
            "Processing epoch: 1004 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6349477022886276\n",
            "Training loss:  \t 0.6033887684345245\n",
            "---------------\n",
            "Processing epoch: 1005 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6371735334396362\n",
            "Training loss:  \t 0.6040450647473335\n",
            "---------------\n",
            "Processing epoch: 1006 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.636461615562439\n",
            "Training loss:  \t 0.6033002287149429\n",
            "---------------\n",
            "Processing epoch: 1007 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6370951682329178\n",
            "Training loss:  \t 0.6031517028808594\n",
            "---------------\n",
            "Processing epoch: 1008 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6376506090164185\n",
            "Training loss:  \t 0.6011673331260681\n",
            "---------------\n",
            "Processing epoch: 1009 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6368470937013626\n",
            "Training loss:  \t 0.6011832535266877\n",
            "---------------\n",
            "Processing epoch: 1010 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6352856904268265\n",
            "Training loss:  \t 0.6016853123903274\n",
            "---------------\n",
            "Processing epoch: 1011 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6352480798959732\n",
            "Training loss:  \t 0.6031207472085953\n",
            "---------------\n",
            "Processing epoch: 1012 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6384888589382172\n",
            "Training loss:  \t 0.6025683358311653\n",
            "---------------\n",
            "Processing epoch: 1013 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6342605352401733\n",
            "Training loss:  \t 0.601898068189621\n",
            "---------------\n",
            "Processing epoch: 1014 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.637428030371666\n",
            "Training loss:  \t 0.5997048616409302\n",
            "---------------\n",
            "Processing epoch: 1015 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6349466443061829\n",
            "Training loss:  \t 0.6039689779281616\n",
            "---------------\n",
            "Processing epoch: 1016 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6336993724107742\n",
            "Training loss:  \t 0.6039563626050949\n",
            "---------------\n",
            "Processing epoch: 1017 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6361084580421448\n",
            "Training loss:  \t 0.6009884119033814\n",
            "---------------\n",
            "Processing epoch: 1018 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6367999762296677\n",
            "Training loss:  \t 0.6031907290220261\n",
            "---------------\n",
            "Processing epoch: 1019 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6350786238908768\n",
            "Training loss:  \t 0.6007546305656433\n",
            "---------------\n",
            "Processing epoch: 1020 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6333827078342438\n",
            "Training loss:  \t 0.6012849628925323\n",
            "---------------\n",
            "Processing epoch: 1021 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6362095326185226\n",
            "Training loss:  \t 0.6017834424972535\n",
            "---------------\n",
            "Processing epoch: 1022 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6358669102191925\n",
            "Training loss:  \t 0.604774834215641\n",
            "---------------\n",
            "Processing epoch: 1023 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6330013424158096\n",
            "Training loss:  \t 0.6031598150730133\n",
            "---------------\n",
            "Processing epoch: 1024 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6393241584300995\n",
            "Training loss:  \t 0.6017597734928131\n",
            "---------------\n",
            "Processing epoch: 1025 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6378800570964813\n",
            "Training loss:  \t 0.6015559613704682\n",
            "---------------\n",
            "Processing epoch: 1026 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.635763019323349\n",
            "Training loss:  \t 0.6015101939439773\n",
            "---------------\n",
            "Processing epoch: 1027 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6367500722408295\n",
            "Training loss:  \t 0.6032130002975464\n",
            "---------------\n",
            "Processing epoch: 1028 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6351083666086197\n",
            "Training loss:  \t 0.6014550596475601\n",
            "---------------\n",
            "Processing epoch: 1029 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6343525499105453\n",
            "Training loss:  \t 0.6022077113389969\n",
            "---------------\n",
            "Processing epoch: 1030 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6366485804319382\n",
            "Training loss:  \t 0.6021133005619049\n",
            "---------------\n",
            "Processing epoch: 1031 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6341929733753204\n",
            "Training loss:  \t 0.6015950322151185\n",
            "---------------\n",
            "Processing epoch: 1032 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6357962787151337\n",
            "Training loss:  \t 0.6004222333431244\n",
            "---------------\n",
            "Processing epoch: 1033 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6340301334857941\n",
            "Training loss:  \t 0.6003728210926056\n",
            "---------------\n",
            "Processing epoch: 1034 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6363409608602524\n",
            "Training loss:  \t 0.6018016442656517\n",
            "---------------\n",
            "Processing epoch: 1035 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6324431300163269\n",
            "Training loss:  \t 0.6016681343317032\n",
            "---------------\n",
            "Processing epoch: 1036 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6351190209388733\n",
            "Training loss:  \t 0.6016203731298446\n",
            "---------------\n",
            "Processing epoch: 1037 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6367725431919098\n",
            "Training loss:  \t 0.6004360869526864\n",
            "---------------\n",
            "Processing epoch: 1038 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6341835707426071\n",
            "Training loss:  \t 0.5995937347412109\n",
            "---------------\n",
            "Processing epoch: 1039 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.635840505361557\n",
            "Training loss:  \t 0.5997482925653458\n",
            "---------------\n",
            "Processing epoch: 1040 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6340952813625336\n",
            "Training loss:  \t 0.6010784819722176\n",
            "---------------\n",
            "Processing epoch: 1041 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6325829476118088\n",
            "Training loss:  \t 0.6005298078060151\n",
            "---------------\n",
            "Processing epoch: 1042 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6324744820594788\n",
            "Training loss:  \t 0.6016541719436646\n",
            "---------------\n",
            "Processing epoch: 1043 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6343682557344437\n",
            "Training loss:  \t 0.5995533153414726\n",
            "---------------\n",
            "Processing epoch: 1044 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6354740560054779\n",
            "Training loss:  \t 0.6005227506160736\n",
            "---------------\n",
            "Processing epoch: 1045 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6345510631799698\n",
            "Training loss:  \t 0.6025020852684975\n",
            "---------------\n",
            "Processing epoch: 1046 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6329713761806488\n",
            "Training loss:  \t 0.5994910880923271\n",
            "---------------\n",
            "Processing epoch: 1047 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6331009566783905\n",
            "Training loss:  \t 0.6038186311721802\n",
            "---------------\n",
            "Processing epoch: 1048 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6335152387619019\n",
            "Training loss:  \t 0.5998233199119568\n",
            "---------------\n",
            "Processing epoch: 1049 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6360255479812622\n",
            "Training loss:  \t 0.6007935538887977\n",
            "---------------\n",
            "Processing epoch: 1050 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6326989233493805\n",
            "Training loss:  \t 0.6004247978329659\n",
            "---------------\n",
            "Processing epoch: 1051 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6323015540838242\n",
            "Training loss:  \t 0.6005837619304657\n",
            "---------------\n",
            "Processing epoch: 1052 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6347323954105377\n",
            "Training loss:  \t 0.6002413541078567\n",
            "---------------\n",
            "Processing epoch: 1053 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6352537423372269\n",
            "Training loss:  \t 0.6016760110855103\n",
            "---------------\n",
            "Processing epoch: 1054 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6331065893173218\n",
            "Training loss:  \t 0.5990668416023255\n",
            "---------------\n",
            "Processing epoch: 1055 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6348103582859039\n",
            "Training loss:  \t 0.600619162619114\n",
            "---------------\n",
            "Processing epoch: 1056 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.634225994348526\n",
            "Training loss:  \t 0.6002332076430321\n",
            "---------------\n",
            "Processing epoch: 1057 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6362437605857849\n",
            "Training loss:  \t 0.6015676438808442\n",
            "---------------\n",
            "Processing epoch: 1058 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.633828654885292\n",
            "Training loss:  \t 0.5999060124158859\n",
            "---------------\n",
            "Processing epoch: 1059 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6338302493095398\n",
            "Training loss:  \t 0.6003012806177139\n",
            "---------------\n",
            "Processing epoch: 1060 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.636613130569458\n",
            "Training loss:  \t 0.604478657245636\n",
            "---------------\n",
            "Processing epoch: 1061 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6357342302799225\n",
            "Training loss:  \t 0.6020456373691558\n",
            "---------------\n",
            "Processing epoch: 1062 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6301621943712234\n",
            "Training loss:  \t 0.6008655428886414\n",
            "---------------\n",
            "Processing epoch: 1063 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6341272443532944\n",
            "Training loss:  \t 0.5995418429374695\n",
            "---------------\n",
            "Processing epoch: 1064 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6389019638299942\n",
            "Training loss:  \t 0.6023231118917465\n",
            "---------------\n",
            "Processing epoch: 1065 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6358621418476105\n",
            "Training loss:  \t 0.5999796897172928\n",
            "---------------\n",
            "Processing epoch: 1066 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6338871419429779\n",
            "Training loss:  \t 0.5999887943267822\n",
            "---------------\n",
            "Processing epoch: 1067 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6360510736703873\n",
            "Training loss:  \t 0.6019136220216751\n",
            "---------------\n",
            "Processing epoch: 1068 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6348055303096771\n",
            "Training loss:  \t 0.5996754229068756\n",
            "---------------\n",
            "Processing epoch: 1069 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6373979896306992\n",
            "Training loss:  \t 0.6020977765321731\n",
            "---------------\n",
            "Processing epoch: 1070 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6372680068016052\n",
            "Training loss:  \t 0.605233745276928\n",
            "---------------\n",
            "Processing epoch: 1071 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6317794173955917\n",
            "Training loss:  \t 0.5989532336592674\n",
            "---------------\n",
            "Processing epoch: 1072 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6325773298740387\n",
            "Training loss:  \t 0.6011811047792435\n",
            "---------------\n",
            "Processing epoch: 1073 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6383558213710785\n",
            "Training loss:  \t 0.5972213476896286\n",
            "---------------\n",
            "Processing epoch: 1074 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6349181979894638\n",
            "Training loss:  \t 0.600785280764103\n",
            "---------------\n",
            "Processing epoch: 1075 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6317214667797089\n",
            "Training loss:  \t 0.6020098924636841\n",
            "---------------\n",
            "Processing epoch: 1076 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6303116679191589\n",
            "Training loss:  \t 0.6018802195787429\n",
            "---------------\n",
            "Processing epoch: 1077 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.634139895439148\n",
            "Training loss:  \t 0.6004247039556503\n",
            "---------------\n",
            "Processing epoch: 1078 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6300999671220779\n",
            "Training loss:  \t 0.6009025394916534\n",
            "---------------\n",
            "Processing epoch: 1079 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6325456947088242\n",
            "Training loss:  \t 0.5991658210754395\n",
            "---------------\n",
            "Processing epoch: 1080 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6327047646045685\n",
            "Training loss:  \t 0.6002251207828522\n",
            "---------------\n",
            "Processing epoch: 1081 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6327688694000244\n",
            "Training loss:  \t 0.5996146261692047\n",
            "---------------\n",
            "Processing epoch: 1082 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6340249180793762\n",
            "Training loss:  \t 0.5993554532527924\n",
            "---------------\n",
            "Processing epoch: 1083 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6304357200860977\n",
            "Training loss:  \t 0.5985305547714234\n",
            "---------------\n",
            "Processing epoch: 1084 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6322363168001175\n",
            "Training loss:  \t 0.5996819347143173\n",
            "---------------\n",
            "Processing epoch: 1085 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6345771551132202\n",
            "Training loss:  \t 0.6010467678308486\n",
            "---------------\n",
            "Processing epoch: 1086 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6281418651342392\n",
            "Training loss:  \t 0.6008550494909286\n",
            "---------------\n",
            "Processing epoch: 1087 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6350462585687637\n",
            "Training loss:  \t 0.6010265499353409\n",
            "---------------\n",
            "Processing epoch: 1088 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6322514861822128\n",
            "Training loss:  \t 0.5969903916120529\n",
            "---------------\n",
            "Processing epoch: 1089 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6369778364896774\n",
            "Training loss:  \t 0.6032377690076828\n",
            "---------------\n",
            "Processing epoch: 1090 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6325837522745132\n",
            "Training loss:  \t 0.6006252497434617\n",
            "---------------\n",
            "Processing epoch: 1091 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6322136670351028\n",
            "Training loss:  \t 0.6000411689281464\n",
            "---------------\n",
            "Processing epoch: 1092 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6315689980983734\n",
            "Training loss:  \t 0.5991394490003585\n",
            "---------------\n",
            "Processing epoch: 1093 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6345990747213364\n",
            "Training loss:  \t 0.5988722115755081\n",
            "---------------\n",
            "Processing epoch: 1094 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.632362499833107\n",
            "Training loss:  \t 0.5983791753649712\n",
            "---------------\n",
            "Processing epoch: 1095 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6317517906427383\n",
            "Training loss:  \t 0.601062074303627\n",
            "---------------\n",
            "Processing epoch: 1096 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6318760365247726\n",
            "Training loss:  \t 0.6005091100931168\n",
            "---------------\n",
            "Processing epoch: 1097 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.628704622387886\n",
            "Training loss:  \t 0.5991877496242524\n",
            "---------------\n",
            "Processing epoch: 1098 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6287832260131836\n",
            "Training loss:  \t 0.5987220168113708\n",
            "---------------\n",
            "Processing epoch: 1099 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6292589157819748\n",
            "Training loss:  \t 0.598379197716713\n",
            "---------------\n",
            "Processing epoch: 1100 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6324877887964249\n",
            "Training loss:  \t 0.597961887717247\n",
            "---------------\n",
            "Processing epoch: 1101 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.630706712603569\n",
            "Training loss:  \t 0.5994453266263008\n",
            "---------------\n",
            "Processing epoch: 1102 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6257884800434113\n",
            "Training loss:  \t 0.5999880746006966\n",
            "---------------\n",
            "Processing epoch: 1103 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277363300323486\n",
            "Training loss:  \t 0.5991079986095429\n",
            "---------------\n",
            "Processing epoch: 1104 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6319670379161835\n",
            "Training loss:  \t 0.5980603635311127\n",
            "---------------\n",
            "Processing epoch: 1105 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6253646910190582\n",
            "Training loss:  \t 0.6026775389909744\n",
            "---------------\n",
            "Processing epoch: 1106 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6337767839431763\n",
            "Training loss:  \t 0.5999603658914566\n",
            "---------------\n",
            "Processing epoch: 1107 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6276419758796692\n",
            "Training loss:  \t 0.5988177463412285\n",
            "---------------\n",
            "Processing epoch: 1108 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6324540972709656\n",
            "Training loss:  \t 0.5992134004831314\n",
            "---------------\n",
            "Processing epoch: 1109 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263320744037628\n",
            "Training loss:  \t 0.5987649142742157\n",
            "---------------\n",
            "Processing epoch: 1110 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6304792016744614\n",
            "Training loss:  \t 0.6008963644504547\n",
            "---------------\n",
            "Processing epoch: 1111 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6306753009557724\n",
            "Training loss:  \t 0.5970386773347854\n",
            "---------------\n",
            "Processing epoch: 1112 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6305793225765228\n",
            "Training loss:  \t 0.5984288558363915\n",
            "---------------\n",
            "Processing epoch: 1113 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6305670738220215\n",
            "Training loss:  \t 0.6002178281545639\n",
            "---------------\n",
            "Processing epoch: 1114 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.626105397939682\n",
            "Training loss:  \t 0.5997602999210357\n",
            "---------------\n",
            "Processing epoch: 1115 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6328451633453369\n",
            "Training loss:  \t 0.5990299135446548\n",
            "---------------\n",
            "Processing epoch: 1116 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.626272663474083\n",
            "Training loss:  \t 0.5976497948169708\n",
            "---------------\n",
            "Processing epoch: 1117 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6270092278718948\n",
            "Training loss:  \t 0.5972255825996399\n",
            "---------------\n",
            "Processing epoch: 1118 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6217833235859871\n",
            "Training loss:  \t 0.5981051698327065\n",
            "---------------\n",
            "Processing epoch: 1119 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277303546667099\n",
            "Training loss:  \t 0.6000611037015915\n",
            "---------------\n",
            "Processing epoch: 1120 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6232460141181946\n",
            "Training loss:  \t 0.5971912443637848\n",
            "---------------\n",
            "Processing epoch: 1121 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6264830231666565\n",
            "Training loss:  \t 0.5973816812038422\n",
            "---------------\n",
            "Processing epoch: 1122 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258534491062164\n",
            "Training loss:  \t 0.5977327525615692\n",
            "---------------\n",
            "Processing epoch: 1123 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6274817287921906\n",
            "Training loss:  \t 0.5979432120919228\n",
            "---------------\n",
            "Processing epoch: 1124 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6250497102737427\n",
            "Training loss:  \t 0.5964309602975846\n",
            "---------------\n",
            "Processing epoch: 1125 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6254350394010544\n",
            "Training loss:  \t 0.5965604096651077\n",
            "---------------\n",
            "Processing epoch: 1126 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6260922402143478\n",
            "Training loss:  \t 0.5992714464664459\n",
            "---------------\n",
            "Processing epoch: 1127 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258379369974136\n",
            "Training loss:  \t 0.5985565632581711\n",
            "---------------\n",
            "Processing epoch: 1128 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6249526143074036\n",
            "Training loss:  \t 0.5983025148510933\n",
            "---------------\n",
            "Processing epoch: 1129 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6249407976865768\n",
            "Training loss:  \t 0.599872088432312\n",
            "---------------\n",
            "Processing epoch: 1130 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6265512406826019\n",
            "Training loss:  \t 0.5978399783372879\n",
            "---------------\n",
            "Processing epoch: 1131 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6247197240591049\n",
            "Training loss:  \t 0.5999705836176872\n",
            "---------------\n",
            "Processing epoch: 1132 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6278477758169174\n",
            "Training loss:  \t 0.5981544017791748\n",
            "---------------\n",
            "Processing epoch: 1133 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6287584900856018\n",
            "Training loss:  \t 0.5991846591234207\n",
            "---------------\n",
            "Processing epoch: 1134 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246783137321472\n",
            "Training loss:  \t 0.5982804730534553\n",
            "---------------\n",
            "Processing epoch: 1135 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6236685961484909\n",
            "Training loss:  \t 0.5970235466957092\n",
            "---------------\n",
            "Processing epoch: 1136 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6262280642986298\n",
            "Training loss:  \t 0.5956963062286377\n",
            "---------------\n",
            "Processing epoch: 1137 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6275953501462936\n",
            "Training loss:  \t 0.5974381268024445\n",
            "---------------\n",
            "Processing epoch: 1138 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6284322887659073\n",
            "Training loss:  \t 0.5985984474420547\n",
            "---------------\n",
            "Processing epoch: 1139 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6303861737251282\n",
            "Training loss:  \t 0.5978779375553132\n",
            "---------------\n",
            "Processing epoch: 1140 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6272022426128387\n",
            "Training loss:  \t 0.598478364944458\n",
            "---------------\n",
            "Processing epoch: 1141 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6264211684465408\n",
            "Training loss:  \t 0.5987686216831207\n",
            "---------------\n",
            "Processing epoch: 1142 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6268717646598816\n",
            "Training loss:  \t 0.5970133945345879\n",
            "---------------\n",
            "Processing epoch: 1143 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6298490315675735\n",
            "Training loss:  \t 0.5978575348854065\n",
            "---------------\n",
            "Processing epoch: 1144 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6235661953687668\n",
            "Training loss:  \t 0.5966486781835556\n",
            "---------------\n",
            "Processing epoch: 1145 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6332053244113922\n",
            "Training loss:  \t 0.5963509410619736\n",
            "---------------\n",
            "Processing epoch: 1146 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258253008127213\n",
            "Training loss:  \t 0.600136724114418\n",
            "---------------\n",
            "Processing epoch: 1147 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251665204763412\n",
            "Training loss:  \t 0.5939576372504234\n",
            "---------------\n",
            "Processing epoch: 1148 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6221837997436523\n",
            "Training loss:  \t 0.5993938997387886\n",
            "---------------\n",
            "Processing epoch: 1149 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6268088668584824\n",
            "Training loss:  \t 0.5989698618650436\n",
            "---------------\n",
            "Processing epoch: 1150 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6256585121154785\n",
            "Training loss:  \t 0.5975152820348739\n",
            "---------------\n",
            "Processing epoch: 1151 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6302124112844467\n",
            "Training loss:  \t 0.5988464012742043\n",
            "---------------\n",
            "Processing epoch: 1152 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6368239670991898\n",
            "Training loss:  \t 0.602761635184288\n",
            "---------------\n",
            "Processing epoch: 1153 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.629932627081871\n",
            "Training loss:  \t 0.5991510853171349\n",
            "---------------\n",
            "Processing epoch: 1154 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6341982632875443\n",
            "Training loss:  \t 0.5976628005504608\n",
            "---------------\n",
            "Processing epoch: 1155 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6276627033948898\n",
            "Training loss:  \t 0.5977581173181534\n",
            "---------------\n",
            "Processing epoch: 1156 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6325849145650864\n",
            "Training loss:  \t 0.5956018745899201\n",
            "---------------\n",
            "Processing epoch: 1157 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6328425854444504\n",
            "Training loss:  \t 0.5961879879236222\n",
            "---------------\n",
            "Processing epoch: 1158 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.622868686914444\n",
            "Training loss:  \t 0.5980061948299408\n",
            "---------------\n",
            "Processing epoch: 1159 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6257428973913193\n",
            "Training loss:  \t 0.5951018273830414\n",
            "---------------\n",
            "Processing epoch: 1160 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6281184405088425\n",
            "Training loss:  \t 0.5979479014873504\n",
            "---------------\n",
            "Processing epoch: 1161 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6299760639667511\n",
            "Training loss:  \t 0.5954630881547928\n",
            "---------------\n",
            "Processing epoch: 1162 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.625603124499321\n",
            "Training loss:  \t 0.5948273330926895\n",
            "---------------\n",
            "Processing epoch: 1163 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6235888451337814\n",
            "Training loss:  \t 0.5932628124952316\n",
            "---------------\n",
            "Processing epoch: 1164 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6244781762361526\n",
            "Training loss:  \t 0.5952642470598221\n",
            "---------------\n",
            "Processing epoch: 1165 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6229874044656754\n",
            "Training loss:  \t 0.5975456669926643\n",
            "---------------\n",
            "Processing epoch: 1166 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6253854632377625\n",
            "Training loss:  \t 0.5976730465888977\n",
            "---------------\n",
            "Processing epoch: 1167 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263540685176849\n",
            "Training loss:  \t 0.5971513390541077\n",
            "---------------\n",
            "Processing epoch: 1168 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6259595975279808\n",
            "Training loss:  \t 0.5943357050418854\n",
            "---------------\n",
            "Processing epoch: 1169 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258236467838287\n",
            "Training loss:  \t 0.595736189186573\n",
            "---------------\n",
            "Processing epoch: 1170 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6256638765335083\n",
            "Training loss:  \t 0.5963535904884338\n",
            "---------------\n",
            "Processing epoch: 1171 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.629663497209549\n",
            "Training loss:  \t 0.5964919000864028\n",
            "---------------\n",
            "Processing epoch: 1172 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251571625471115\n",
            "Training loss:  \t 0.5944723814725876\n",
            "---------------\n",
            "Processing epoch: 1173 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.625426173210144\n",
            "Training loss:  \t 0.5943773955106735\n",
            "---------------\n",
            "Processing epoch: 1174 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6272322237491608\n",
            "Training loss:  \t 0.596993950009346\n",
            "---------------\n",
            "Processing epoch: 1175 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6214776337146759\n",
            "Training loss:  \t 0.594741415977478\n",
            "---------------\n",
            "Processing epoch: 1176 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6294012665748596\n",
            "Training loss:  \t 0.5954695224761963\n",
            "---------------\n",
            "Processing epoch: 1177 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6230205297470093\n",
            "Training loss:  \t 0.5937862157821655\n",
            "---------------\n",
            "Processing epoch: 1178 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6298094689846039\n",
            "Training loss:  \t 0.594967620074749\n",
            "---------------\n",
            "Processing epoch: 1179 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251200139522552\n",
            "Training loss:  \t 0.5964754194021225\n",
            "---------------\n",
            "Processing epoch: 1180 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6260165274143219\n",
            "Training loss:  \t 0.5973798602819442\n",
            "---------------\n",
            "Processing epoch: 1181 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6244485974311829\n",
            "Training loss:  \t 0.5978308320045471\n",
            "---------------\n",
            "Processing epoch: 1182 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6273848563432693\n",
            "Training loss:  \t 0.59493088722229\n",
            "---------------\n",
            "Processing epoch: 1183 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6248590499162674\n",
            "Training loss:  \t 0.5940314084291458\n",
            "---------------\n",
            "Processing epoch: 1184 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6242648810148239\n",
            "Training loss:  \t 0.5963768497109413\n",
            "---------------\n",
            "Processing epoch: 1185 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6295522749423981\n",
            "Training loss:  \t 0.5977450311183929\n",
            "---------------\n",
            "Processing epoch: 1186 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277444809675217\n",
            "Training loss:  \t 0.5960328608751297\n",
            "---------------\n",
            "Processing epoch: 1187 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6256889402866364\n",
            "Training loss:  \t 0.5937035575509071\n",
            "---------------\n",
            "Processing epoch: 1188 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6242643445730209\n",
            "Training loss:  \t 0.5953362613916398\n",
            "---------------\n",
            "Processing epoch: 1189 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6222828030586243\n",
            "Training loss:  \t 0.5940778374671936\n",
            "---------------\n",
            "Processing epoch: 1190 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6250395029783249\n",
            "Training loss:  \t 0.5934228837490082\n",
            "---------------\n",
            "Processing epoch: 1191 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6250574141740799\n",
            "Training loss:  \t 0.5956129491329193\n",
            "---------------\n",
            "Processing epoch: 1192 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6330900490283966\n",
            "Training loss:  \t 0.5987142235040664\n",
            "---------------\n",
            "Processing epoch: 1193 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6245724409818649\n",
            "Training loss:  \t 0.5944070503115654\n",
            "---------------\n",
            "Processing epoch: 1194 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6296178549528122\n",
            "Training loss:  \t 0.5945595860481262\n",
            "---------------\n",
            "Processing epoch: 1195 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6270723342895508\n",
            "Training loss:  \t 0.59484483897686\n",
            "---------------\n",
            "Processing epoch: 1196 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6245363801717758\n",
            "Training loss:  \t 0.5928656131029129\n",
            "---------------\n",
            "Processing epoch: 1197 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6303097456693649\n",
            "Training loss:  \t 0.5956569075584411\n",
            "---------------\n",
            "Processing epoch: 1198 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6265807151794434\n",
            "Training loss:  \t 0.5943495973944664\n",
            "---------------\n",
            "Processing epoch: 1199 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6232069879770279\n",
            "Training loss:  \t 0.5948481395840645\n",
            "---------------\n",
            "Processing epoch: 1200 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6254293322563171\n",
            "Training loss:  \t 0.596956804394722\n",
            "---------------\n",
            "Processing epoch: 1201 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6245167851448059\n",
            "Training loss:  \t 0.5940696656703949\n",
            "---------------\n",
            "Processing epoch: 1202 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6243424713611603\n",
            "Training loss:  \t 0.5959047466516495\n",
            "---------------\n",
            "Processing epoch: 1203 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6278275102376938\n",
            "Training loss:  \t 0.5949856549501419\n",
            "---------------\n",
            "Processing epoch: 1204 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6280225515365601\n",
            "Training loss:  \t 0.597744682431221\n",
            "---------------\n",
            "Processing epoch: 1205 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6266487836837769\n",
            "Training loss:  \t 0.5977926790714264\n",
            "---------------\n",
            "Processing epoch: 1206 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6303649395704269\n",
            "Training loss:  \t 0.5936186075210571\n",
            "---------------\n",
            "Processing epoch: 1207 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6233717650175095\n",
            "Training loss:  \t 0.5930751353502274\n",
            "---------------\n",
            "Processing epoch: 1208 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6286803930997849\n",
            "Training loss:  \t 0.59515390843153\n",
            "---------------\n",
            "Processing epoch: 1209 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6273440718650818\n",
            "Training loss:  \t 0.5943712264299392\n",
            "---------------\n",
            "Processing epoch: 1210 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6286789178848267\n",
            "Training loss:  \t 0.5935282915830612\n",
            "---------------\n",
            "Processing epoch: 1211 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6247940510511398\n",
            "Training loss:  \t 0.595801268517971\n",
            "---------------\n",
            "Processing epoch: 1212 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6195574253797531\n",
            "Training loss:  \t 0.5988202899694443\n",
            "---------------\n",
            "Processing epoch: 1213 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6283063590526581\n",
            "Training loss:  \t 0.59391018897295\n",
            "---------------\n",
            "Processing epoch: 1214 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6267491579055786\n",
            "Training loss:  \t 0.5948276564478874\n",
            "---------------\n",
            "Processing epoch: 1215 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6294919401407242\n",
            "Training loss:  \t 0.5929780825972557\n",
            "---------------\n",
            "Processing epoch: 1216 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6218436062335968\n",
            "Training loss:  \t 0.5921954363584518\n",
            "---------------\n",
            "Processing epoch: 1217 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263979524374008\n",
            "Training loss:  \t 0.592884361743927\n",
            "---------------\n",
            "Processing epoch: 1218 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6231694221496582\n",
            "Training loss:  \t 0.5916441261768342\n",
            "---------------\n",
            "Processing epoch: 1219 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.621477335691452\n",
            "Training loss:  \t 0.594695097208023\n",
            "---------------\n",
            "Processing epoch: 1220 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6265278160572052\n",
            "Training loss:  \t 0.5941225767135621\n",
            "---------------\n",
            "Processing epoch: 1221 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6267660856246948\n",
            "Training loss:  \t 0.5950576841831208\n",
            "---------------\n",
            "Processing epoch: 1222 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6227881908416748\n",
            "Training loss:  \t 0.5942191481590271\n",
            "---------------\n",
            "Processing epoch: 1223 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6261003613471985\n",
            "Training loss:  \t 0.593267934024334\n",
            "---------------\n",
            "Processing epoch: 1224 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6257975399494171\n",
            "Training loss:  \t 0.5934774369001389\n",
            "---------------\n",
            "Processing epoch: 1225 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6196958869695663\n",
            "Training loss:  \t 0.5935958325862885\n",
            "---------------\n",
            "Processing epoch: 1226 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6257633864879608\n",
            "Training loss:  \t 0.5913450747728348\n",
            "---------------\n",
            "Processing epoch: 1227 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251496374607086\n",
            "Training loss:  \t 0.5943294778466225\n",
            "---------------\n",
            "Processing epoch: 1228 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6238230764865875\n",
            "Training loss:  \t 0.5952875807881355\n",
            "---------------\n",
            "Processing epoch: 1229 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6254168152809143\n",
            "Training loss:  \t 0.5925147950649261\n",
            "---------------\n",
            "Processing epoch: 1230 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6269501447677612\n",
            "Training loss:  \t 0.5956434726715087\n",
            "---------------\n",
            "Processing epoch: 1231 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6253575682640076\n",
            "Training loss:  \t 0.5944449841976166\n",
            "---------------\n",
            "Processing epoch: 1232 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6233532577753067\n",
            "Training loss:  \t 0.590662369132042\n",
            "---------------\n",
            "Processing epoch: 1233 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6216701120138168\n",
            "Training loss:  \t 0.594181127846241\n",
            "---------------\n",
            "Processing epoch: 1234 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6294050514698029\n",
            "Training loss:  \t 0.5956086605787277\n",
            "---------------\n",
            "Processing epoch: 1235 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6247488707304001\n",
            "Training loss:  \t 0.5938497990369797\n",
            "---------------\n",
            "Processing epoch: 1236 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6268147528171539\n",
            "Training loss:  \t 0.5922396540641784\n",
            "---------------\n",
            "Processing epoch: 1237 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6250595152378082\n",
            "Training loss:  \t 0.591302327811718\n",
            "---------------\n",
            "Processing epoch: 1238 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.627608984708786\n",
            "Training loss:  \t 0.5958331614732743\n",
            "---------------\n",
            "Processing epoch: 1239 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6225176155567169\n",
            "Training loss:  \t 0.5925309807062149\n",
            "---------------\n",
            "Processing epoch: 1240 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6235481649637222\n",
            "Training loss:  \t 0.5947655737400055\n",
            "---------------\n",
            "Processing epoch: 1241 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6236157119274139\n",
            "Training loss:  \t 0.5936197519302369\n",
            "---------------\n",
            "Processing epoch: 1242 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6247803717851639\n",
            "Training loss:  \t 0.5917857140302658\n",
            "---------------\n",
            "Processing epoch: 1243 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6235880255699158\n",
            "Training loss:  \t 0.5928464964032173\n",
            "---------------\n",
            "Processing epoch: 1244 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6282884478569031\n",
            "Training loss:  \t 0.595837214589119\n",
            "---------------\n",
            "Processing epoch: 1245 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6303671002388\n",
            "Training loss:  \t 0.5927513301372528\n",
            "---------------\n",
            "Processing epoch: 1246 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6247942000627518\n",
            "Training loss:  \t 0.5920223534107208\n",
            "---------------\n",
            "Processing epoch: 1247 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6287743598222733\n",
            "Training loss:  \t 0.5907445624470711\n",
            "---------------\n",
            "Processing epoch: 1248 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6262410581111908\n",
            "Training loss:  \t 0.5905658721923828\n",
            "---------------\n",
            "Processing epoch: 1249 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6276933699846268\n",
            "Training loss:  \t 0.5907544419169426\n",
            "---------------\n",
            "Processing epoch: 1250 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6274166852235794\n",
            "Training loss:  \t 0.5905360817909241\n",
            "---------------\n",
            "Processing epoch: 1251 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258307099342346\n",
            "Training loss:  \t 0.5918021976947785\n",
            "---------------\n",
            "Processing epoch: 1252 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6266027092933655\n",
            "Training loss:  \t 0.5927909672260284\n",
            "---------------\n",
            "Processing epoch: 1253 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6308907270431519\n",
            "Training loss:  \t 0.5963321104645729\n",
            "---------------\n",
            "Processing epoch: 1254 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6325300335884094\n",
            "Training loss:  \t 0.5933566391468048\n",
            "---------------\n",
            "Processing epoch: 1255 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6282116919755936\n",
            "Training loss:  \t 0.591003666818142\n",
            "---------------\n",
            "Processing epoch: 1256 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6287114322185516\n",
            "Training loss:  \t 0.591846588253975\n",
            "---------------\n",
            "Processing epoch: 1257 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6267794370651245\n",
            "Training loss:  \t 0.5960923969745636\n",
            "---------------\n",
            "Processing epoch: 1258 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6271038800477982\n",
            "Training loss:  \t 0.5908752903342247\n",
            "---------------\n",
            "Processing epoch: 1259 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6240750849246979\n",
            "Training loss:  \t 0.5902996689081192\n",
            "---------------\n",
            "Processing epoch: 1260 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6256908178329468\n",
            "Training loss:  \t 0.590183536708355\n",
            "---------------\n",
            "Processing epoch: 1261 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6295160353183746\n",
            "Training loss:  \t 0.5903921633958816\n",
            "---------------\n",
            "Processing epoch: 1262 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6262346804141998\n",
            "Training loss:  \t 0.5920978501439095\n",
            "---------------\n",
            "Processing epoch: 1263 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6271898001432419\n",
            "Training loss:  \t 0.5898768752813339\n",
            "---------------\n",
            "Processing epoch: 1264 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6215764135122299\n",
            "Training loss:  \t 0.5915408194065094\n",
            "---------------\n",
            "Processing epoch: 1265 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6312937885522842\n",
            "Training loss:  \t 0.5942017018795014\n",
            "---------------\n",
            "Processing epoch: 1266 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6243500858545303\n",
            "Training loss:  \t 0.5922016769647598\n",
            "---------------\n",
            "Processing epoch: 1267 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258270442485809\n",
            "Training loss:  \t 0.5894773498177528\n",
            "---------------\n",
            "Processing epoch: 1268 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6275220662355423\n",
            "Training loss:  \t 0.5904222324490547\n",
            "---------------\n",
            "Processing epoch: 1269 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6248698383569717\n",
            "Training loss:  \t 0.5929022163152695\n",
            "---------------\n",
            "Processing epoch: 1270 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6276001930236816\n",
            "Training loss:  \t 0.5919591009616851\n",
            "---------------\n",
            "Processing epoch: 1271 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258199065923691\n",
            "Training loss:  \t 0.5922173470258713\n",
            "---------------\n",
            "Processing epoch: 1272 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6262248307466507\n",
            "Training loss:  \t 0.594042283296585\n",
            "---------------\n",
            "Processing epoch: 1273 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251026391983032\n",
            "Training loss:  \t 0.5891430675983429\n",
            "---------------\n",
            "Processing epoch: 1274 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6298204660415649\n",
            "Training loss:  \t 0.5912955373525619\n",
            "---------------\n",
            "Processing epoch: 1275 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.622027151286602\n",
            "Training loss:  \t 0.592417074739933\n",
            "---------------\n",
            "Processing epoch: 1276 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6238393783569336\n",
            "Training loss:  \t 0.5914626479148865\n",
            "---------------\n",
            "Processing epoch: 1277 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6323498636484146\n",
            "Training loss:  \t 0.5932176098227501\n",
            "---------------\n",
            "Processing epoch: 1278 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6233258843421936\n",
            "Training loss:  \t 0.5913603931665421\n",
            "---------------\n",
            "Processing epoch: 1279 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6279088854789734\n",
            "Training loss:  \t 0.5981895297765731\n",
            "---------------\n",
            "Processing epoch: 1280 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.62802354991436\n",
            "Training loss:  \t 0.5939218491315842\n",
            "---------------\n",
            "Processing epoch: 1281 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6184056401252747\n",
            "Training loss:  \t 0.5932021692395211\n",
            "---------------\n",
            "Processing epoch: 1282 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6250287145376205\n",
            "Training loss:  \t 0.5960077479481697\n",
            "---------------\n",
            "Processing epoch: 1283 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277756839990616\n",
            "Training loss:  \t 0.5904590755701065\n",
            "---------------\n",
            "Processing epoch: 1284 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6282067447900772\n",
            "Training loss:  \t 0.5932149201631546\n",
            "---------------\n",
            "Processing epoch: 1285 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6259652227163315\n",
            "Training loss:  \t 0.5918620616197586\n",
            "---------------\n",
            "Processing epoch: 1286 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.624359980225563\n",
            "Training loss:  \t 0.5906741306185722\n",
            "---------------\n",
            "Processing epoch: 1287 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6238131672143936\n",
            "Training loss:  \t 0.5891528204083443\n",
            "---------------\n",
            "Processing epoch: 1288 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263810694217682\n",
            "Training loss:  \t 0.588175705075264\n",
            "---------------\n",
            "Processing epoch: 1289 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258038133382797\n",
            "Training loss:  \t 0.5906321316957474\n",
            "---------------\n",
            "Processing epoch: 1290 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.630426213145256\n",
            "Training loss:  \t 0.5905768319964408\n",
            "---------------\n",
            "Processing epoch: 1291 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6236095577478409\n",
            "Training loss:  \t 0.5911581739783287\n",
            "---------------\n",
            "Processing epoch: 1292 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246779561042786\n",
            "Training loss:  \t 0.5917546808719635\n",
            "---------------\n",
            "Processing epoch: 1293 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6231695711612701\n",
            "Training loss:  \t 0.5956369817256928\n",
            "---------------\n",
            "Processing epoch: 1294 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6293446570634842\n",
            "Training loss:  \t 0.5908425778150559\n",
            "---------------\n",
            "Processing epoch: 1295 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6298286467790604\n",
            "Training loss:  \t 0.5910718441009521\n",
            "---------------\n",
            "Processing epoch: 1296 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6278290897607803\n",
            "Training loss:  \t 0.5906103283166886\n",
            "---------------\n",
            "Processing epoch: 1297 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277772337198257\n",
            "Training loss:  \t 0.5892880171537399\n",
            "---------------\n",
            "Processing epoch: 1298 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6249183714389801\n",
            "Training loss:  \t 0.5916204139590263\n",
            "---------------\n",
            "Processing epoch: 1299 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6210628151893616\n",
            "Training loss:  \t 0.5909228265285492\n",
            "---------------\n",
            "Processing epoch: 1300 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6268437057733536\n",
            "Training loss:  \t 0.5871693551540375\n",
            "---------------\n",
            "Processing epoch: 1301 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277678459882736\n",
            "Training loss:  \t 0.5902104049921035\n",
            "---------------\n",
            "Processing epoch: 1302 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6300113350152969\n",
            "Training loss:  \t 0.5944791287183762\n",
            "---------------\n",
            "Processing epoch: 1303 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6226697266101837\n",
            "Training loss:  \t 0.5897634655237198\n",
            "---------------\n",
            "Processing epoch: 1304 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6296439319849014\n",
            "Training loss:  \t 0.5925567150115967\n",
            "---------------\n",
            "Processing epoch: 1305 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258459538221359\n",
            "Training loss:  \t 0.5925204589962959\n",
            "---------------\n",
            "Processing epoch: 1306 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6254956722259521\n",
            "Training loss:  \t 0.5896814584732055\n",
            "---------------\n",
            "Processing epoch: 1307 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6240976750850677\n",
            "Training loss:  \t 0.5887588024139404\n",
            "---------------\n",
            "Processing epoch: 1308 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6309836804866791\n",
            "Training loss:  \t 0.5891439884901046\n",
            "---------------\n",
            "Processing epoch: 1309 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6273209601640701\n",
            "Training loss:  \t 0.5926945820450783\n",
            "---------------\n",
            "Processing epoch: 1310 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6276045739650726\n",
            "Training loss:  \t 0.590346360206604\n",
            "---------------\n",
            "Processing epoch: 1311 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258651912212372\n",
            "Training loss:  \t 0.5903336256742477\n",
            "---------------\n",
            "Processing epoch: 1312 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6255704164505005\n",
            "Training loss:  \t 0.5893807530403137\n",
            "---------------\n",
            "Processing epoch: 1313 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246313601732254\n",
            "Training loss:  \t 0.5899875029921532\n",
            "---------------\n",
            "Processing epoch: 1314 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6249479204416275\n",
            "Training loss:  \t 0.5898277834057808\n",
            "---------------\n",
            "Processing epoch: 1315 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6217992901802063\n",
            "Training loss:  \t 0.5894833207130432\n",
            "---------------\n",
            "Processing epoch: 1316 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.626299262046814\n",
            "Training loss:  \t 0.5890347778797149\n",
            "---------------\n",
            "Processing epoch: 1317 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6228374689817429\n",
            "Training loss:  \t 0.5923607915639877\n",
            "---------------\n",
            "Processing epoch: 1318 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6282238811254501\n",
            "Training loss:  \t 0.5904463604092598\n",
            "---------------\n",
            "Processing epoch: 1319 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.62470743060112\n",
            "Training loss:  \t 0.5912166357040405\n",
            "---------------\n",
            "Processing epoch: 1320 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6270593106746674\n",
            "Training loss:  \t 0.5905031070113183\n",
            "---------------\n",
            "Processing epoch: 1321 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6211883723735809\n",
            "Training loss:  \t 0.589432156085968\n",
            "---------------\n",
            "Processing epoch: 1322 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246467232704163\n",
            "Training loss:  \t 0.5883601129055023\n",
            "---------------\n",
            "Processing epoch: 1323 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.627482682466507\n",
            "Training loss:  \t 0.5911429822444916\n",
            "---------------\n",
            "Processing epoch: 1324 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263928115367889\n",
            "Training loss:  \t 0.5897603034973145\n",
            "---------------\n",
            "Processing epoch: 1325 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6243634521961212\n",
            "Training loss:  \t 0.5882530450820923\n",
            "---------------\n",
            "Processing epoch: 1326 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6228557974100113\n",
            "Training loss:  \t 0.5905005991458893\n",
            "---------------\n",
            "Processing epoch: 1327 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6236133426427841\n",
            "Training loss:  \t 0.5895631402730942\n",
            "---------------\n",
            "Processing epoch: 1328 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6241878718137741\n",
            "Training loss:  \t 0.5878757685422897\n",
            "---------------\n",
            "Processing epoch: 1329 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251560896635056\n",
            "Training loss:  \t 0.5878960981965065\n",
            "---------------\n",
            "Processing epoch: 1330 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6309209614992142\n",
            "Training loss:  \t 0.5892357707023621\n",
            "---------------\n",
            "Processing epoch: 1331 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6211261600255966\n",
            "Training loss:  \t 0.5888564616441727\n",
            "---------------\n",
            "Processing epoch: 1332 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6250908672809601\n",
            "Training loss:  \t 0.5883852764964104\n",
            "---------------\n",
            "Processing epoch: 1333 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6269558370113373\n",
            "Training loss:  \t 0.5889864578843117\n",
            "---------------\n",
            "Processing epoch: 1334 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6252614706754684\n",
            "Training loss:  \t 0.588259482383728\n",
            "---------------\n",
            "Processing epoch: 1335 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6245168447494507\n",
            "Training loss:  \t 0.5890057355165481\n",
            "---------------\n",
            "Processing epoch: 1336 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.630016952753067\n",
            "Training loss:  \t 0.5892082154750824\n",
            "---------------\n",
            "Processing epoch: 1337 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6223677098751068\n",
            "Training loss:  \t 0.5914492338895798\n",
            "---------------\n",
            "Processing epoch: 1338 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.623583197593689\n",
            "Training loss:  \t 0.5884618416428566\n",
            "---------------\n",
            "Processing epoch: 1339 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.623006135225296\n",
            "Training loss:  \t 0.5904937475919724\n",
            "---------------\n",
            "Processing epoch: 1340 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6301469802856445\n",
            "Training loss:  \t 0.5914539009332657\n",
            "---------------\n",
            "Processing epoch: 1341 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6243677735328674\n",
            "Training loss:  \t 0.5929163932800293\n",
            "---------------\n",
            "Processing epoch: 1342 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263773739337921\n",
            "Training loss:  \t 0.5924137726426124\n",
            "---------------\n",
            "Processing epoch: 1343 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6268720477819443\n",
            "Training loss:  \t 0.5924217298626899\n",
            "---------------\n",
            "Processing epoch: 1344 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6240483224391937\n",
            "Training loss:  \t 0.5926772877573967\n",
            "---------------\n",
            "Processing epoch: 1345 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6313383132219315\n",
            "Training loss:  \t 0.5894824594259263\n",
            "---------------\n",
            "Processing epoch: 1346 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6239059567451477\n",
            "Training loss:  \t 0.5899985954165459\n",
            "---------------\n",
            "Processing epoch: 1347 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263522505760193\n",
            "Training loss:  \t 0.5894768729805946\n",
            "---------------\n",
            "Processing epoch: 1348 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6255240738391876\n",
            "Training loss:  \t 0.5879984974861145\n",
            "---------------\n",
            "Processing epoch: 1349 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6254347413778305\n",
            "Training loss:  \t 0.5914298892021179\n",
            "---------------\n",
            "Processing epoch: 1350 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6262513697147369\n",
            "Training loss:  \t 0.5905756071209908\n",
            "---------------\n",
            "Processing epoch: 1351 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6243761628866196\n",
            "Training loss:  \t 0.5894052475690842\n",
            "---------------\n",
            "Processing epoch: 1352 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6248372495174408\n",
            "Training loss:  \t 0.5889418363571167\n",
            "---------------\n",
            "Processing epoch: 1353 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6229483038187027\n",
            "Training loss:  \t 0.5908939272165299\n",
            "---------------\n",
            "Processing epoch: 1354 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6235785037279129\n",
            "Training loss:  \t 0.5894776374101639\n",
            "---------------\n",
            "Processing epoch: 1355 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6289237886667252\n",
            "Training loss:  \t 0.5873567566275597\n",
            "---------------\n",
            "Processing epoch: 1356 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6200472936034203\n",
            "Training loss:  \t 0.5892142564058304\n",
            "---------------\n",
            "Processing epoch: 1357 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6254285126924515\n",
            "Training loss:  \t 0.590066023170948\n",
            "---------------\n",
            "Processing epoch: 1358 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6213462203741074\n",
            "Training loss:  \t 0.5924396485090255\n",
            "---------------\n",
            "Processing epoch: 1359 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6279196590185165\n",
            "Training loss:  \t 0.590671806037426\n",
            "---------------\n",
            "Processing epoch: 1360 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6301349401473999\n",
            "Training loss:  \t 0.5914491280913353\n",
            "---------------\n",
            "Processing epoch: 1361 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6265345066785812\n",
            "Training loss:  \t 0.5936135903000832\n",
            "---------------\n",
            "Processing epoch: 1362 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6258819401264191\n",
            "Training loss:  \t 0.5923623576760292\n",
            "---------------\n",
            "Processing epoch: 1363 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6236995309591293\n",
            "Training loss:  \t 0.5897303774952889\n",
            "---------------\n",
            "Processing epoch: 1364 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6215531677007675\n",
            "Training loss:  \t 0.5870089337229729\n",
            "---------------\n",
            "Processing epoch: 1365 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6247481852769852\n",
            "Training loss:  \t 0.5889709770679474\n",
            "---------------\n",
            "Processing epoch: 1366 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6302389055490494\n",
            "Training loss:  \t 0.5945442765951157\n",
            "---------------\n",
            "Processing epoch: 1367 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6243266463279724\n",
            "Training loss:  \t 0.5888783648610115\n",
            "---------------\n",
            "Processing epoch: 1368 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6269585937261581\n",
            "Training loss:  \t 0.5876969680190086\n",
            "---------------\n",
            "Processing epoch: 1369 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6229511797428131\n",
            "Training loss:  \t 0.5888014599680901\n",
            "---------------\n",
            "Processing epoch: 1370 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6253985315561295\n",
            "Training loss:  \t 0.5935351461172104\n",
            "---------------\n",
            "Processing epoch: 1371 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6288032978773117\n",
            "Training loss:  \t 0.5918265223503113\n",
            "---------------\n",
            "Processing epoch: 1372 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6327458769083023\n",
            "Training loss:  \t 0.5904596865177154\n",
            "---------------\n",
            "Processing epoch: 1373 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6214147359132767\n",
            "Training loss:  \t 0.5877534925937653\n",
            "---------------\n",
            "Processing epoch: 1374 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.625205472111702\n",
            "Training loss:  \t 0.5905492171645165\n",
            "---------------\n",
            "Processing epoch: 1375 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277109682559967\n",
            "Training loss:  \t 0.5920381024479866\n",
            "---------------\n",
            "Processing epoch: 1376 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6260956376791\n",
            "Training loss:  \t 0.5877223700284958\n",
            "---------------\n",
            "Processing epoch: 1377 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6232771277427673\n",
            "Training loss:  \t 0.5892616465687752\n",
            "---------------\n",
            "Processing epoch: 1378 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6329172402620316\n",
            "Training loss:  \t 0.5881818309426308\n",
            "---------------\n",
            "Processing epoch: 1379 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6199797987937927\n",
            "Training loss:  \t 0.5879952117800713\n",
            "---------------\n",
            "Processing epoch: 1380 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6257918030023575\n",
            "Training loss:  \t 0.5879872277379036\n",
            "---------------\n",
            "Processing epoch: 1381 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6255485117435455\n",
            "Training loss:  \t 0.5873376190662384\n",
            "---------------\n",
            "Processing epoch: 1382 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6245756149291992\n",
            "Training loss:  \t 0.5903077214956284\n",
            "---------------\n",
            "Processing epoch: 1383 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6253265589475632\n",
            "Training loss:  \t 0.5871284559369088\n",
            "---------------\n",
            "Processing epoch: 1384 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6269660741090775\n",
            "Training loss:  \t 0.5895787745714187\n",
            "---------------\n",
            "Processing epoch: 1385 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6262440532445908\n",
            "Training loss:  \t 0.5912835642695426\n",
            "---------------\n",
            "Processing epoch: 1386 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.624171257019043\n",
            "Training loss:  \t 0.5873840808868408\n",
            "---------------\n",
            "Processing epoch: 1387 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6293617188930511\n",
            "Training loss:  \t 0.5887847498059273\n",
            "---------------\n",
            "Processing epoch: 1388 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6248176842927933\n",
            "Training loss:  \t 0.586648415029049\n",
            "---------------\n",
            "Processing epoch: 1389 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.626662015914917\n",
            "Training loss:  \t 0.588941964507103\n",
            "---------------\n",
            "Processing epoch: 1390 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246789395809174\n",
            "Training loss:  \t 0.5932619199156761\n",
            "---------------\n",
            "Processing epoch: 1391 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6248387843370438\n",
            "Training loss:  \t 0.5878863871097565\n",
            "---------------\n",
            "Processing epoch: 1392 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.624191090464592\n",
            "Training loss:  \t 0.5901928931474686\n",
            "---------------\n",
            "Processing epoch: 1393 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6275328993797302\n",
            "Training loss:  \t 0.5866427302360535\n",
            "---------------\n",
            "Processing epoch: 1394 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251285821199417\n",
            "Training loss:  \t 0.5863819658756256\n",
            "---------------\n",
            "Processing epoch: 1395 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6226375102996826\n",
            "Training loss:  \t 0.5875500619411469\n",
            "---------------\n",
            "Processing epoch: 1396 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6266527324914932\n",
            "Training loss:  \t 0.5883593469858169\n",
            "---------------\n",
            "Processing epoch: 1397 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6257482022047043\n",
            "Training loss:  \t 0.5897222638130188\n",
            "---------------\n",
            "Processing epoch: 1398 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6242084354162216\n",
            "Training loss:  \t 0.5899989038705826\n",
            "---------------\n",
            "Processing epoch: 1399 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6280519366264343\n",
            "Training loss:  \t 0.588839003443718\n",
            "---------------\n",
            "Processing epoch: 1400 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6276526153087616\n",
            "Training loss:  \t 0.5915797874331474\n",
            "---------------\n",
            "Processing epoch: 1401 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6209549456834793\n",
            "Training loss:  \t 0.591493059694767\n",
            "---------------\n",
            "Processing epoch: 1402 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6266987323760986\n",
            "Training loss:  \t 0.5902573049068451\n",
            "---------------\n",
            "Processing epoch: 1403 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6244703233242035\n",
            "Training loss:  \t 0.5859994858503341\n",
            "---------------\n",
            "Processing epoch: 1404 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.623850405216217\n",
            "Training loss:  \t 0.5891213148832322\n",
            "---------------\n",
            "Processing epoch: 1405 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6234090477228165\n",
            "Training loss:  \t 0.5899604976177215\n",
            "---------------\n",
            "Processing epoch: 1406 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6271962970495224\n",
            "Training loss:  \t 0.5859631985425949\n",
            "---------------\n",
            "Processing epoch: 1407 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6219312697649002\n",
            "Training loss:  \t 0.5876668155193329\n",
            "---------------\n",
            "Processing epoch: 1408 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6277270615100861\n",
            "Training loss:  \t 0.5917837738990783\n",
            "---------------\n",
            "Processing epoch: 1409 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6268888711929321\n",
            "Training loss:  \t 0.5908522814512253\n",
            "---------------\n",
            "Processing epoch: 1410 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6244500577449799\n",
            "Training loss:  \t 0.5929892927408218\n",
            "---------------\n",
            "Processing epoch: 1411 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6270436346530914\n",
            "Training loss:  \t 0.5885005101561547\n",
            "---------------\n",
            "Processing epoch: 1412 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6249853521585464\n",
            "Training loss:  \t 0.5926827147603035\n",
            "---------------\n",
            "Processing epoch: 1413 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.622388020157814\n",
            "Training loss:  \t 0.5950829610228539\n",
            "---------------\n",
            "Processing epoch: 1414 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6245948970317841\n",
            "Training loss:  \t 0.5882902294397354\n",
            "---------------\n",
            "Processing epoch: 1415 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251929849386215\n",
            "Training loss:  \t 0.5862523838877678\n",
            "---------------\n",
            "Processing epoch: 1416 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6217162907123566\n",
            "Training loss:  \t 0.5864530861377716\n",
            "---------------\n",
            "Processing epoch: 1417 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.622312381863594\n",
            "Training loss:  \t 0.5844572275876999\n",
            "---------------\n",
            "Processing epoch: 1418 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.626462459564209\n",
            "Training loss:  \t 0.5878108084201813\n",
            "---------------\n",
            "Processing epoch: 1419 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6215364709496498\n",
            "Training loss:  \t 0.5861367136240005\n",
            "---------------\n",
            "Processing epoch: 1420 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6239316463470459\n",
            "Training loss:  \t 0.5870903849601745\n",
            "---------------\n",
            "Processing epoch: 1421 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6208020448684692\n",
            "Training loss:  \t 0.5908534288406372\n",
            "---------------\n",
            "Processing epoch: 1422 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6226142942905426\n",
            "Training loss:  \t 0.5887429282069206\n",
            "---------------\n",
            "Processing epoch: 1423 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6268076300621033\n",
            "Training loss:  \t 0.5890275448560714\n",
            "---------------\n",
            "Processing epoch: 1424 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.624613881111145\n",
            "Training loss:  \t 0.5879114210605622\n",
            "---------------\n",
            "Processing epoch: 1425 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6269937455654144\n",
            "Training loss:  \t 0.5882904902100563\n",
            "---------------\n",
            "Processing epoch: 1426 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246355324983597\n",
            "Training loss:  \t 0.5956702008843422\n",
            "---------------\n",
            "Processing epoch: 1427 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6278263628482819\n",
            "Training loss:  \t 0.5912483662366868\n",
            "---------------\n",
            "Processing epoch: 1428 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6239628791809082\n",
            "Training loss:  \t 0.5882940262556076\n",
            "---------------\n",
            "Processing epoch: 1429 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6257541924715042\n",
            "Training loss:  \t 0.5933460563421249\n",
            "---------------\n",
            "Processing epoch: 1430 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6327675580978394\n",
            "Training loss:  \t 0.5942094027996063\n",
            "---------------\n",
            "Processing epoch: 1431 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6189232096076012\n",
            "Training loss:  \t 0.58734862357378\n",
            "---------------\n",
            "Processing epoch: 1432 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6269514560699463\n",
            "Training loss:  \t 0.5858915179967881\n",
            "---------------\n",
            "Processing epoch: 1433 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6274749785661697\n",
            "Training loss:  \t 0.5885254114866256\n",
            "---------------\n",
            "Processing epoch: 1434 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6249356120824814\n",
            "Training loss:  \t 0.5861935004591942\n",
            "---------------\n",
            "Processing epoch: 1435 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246819198131561\n",
            "Training loss:  \t 0.5890904814004898\n",
            "---------------\n",
            "Processing epoch: 1436 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6255854070186615\n",
            "Training loss:  \t 0.5894837036728859\n",
            "---------------\n",
            "Processing epoch: 1437 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6220323741436005\n",
            "Training loss:  \t 0.5872472763061524\n",
            "---------------\n",
            "Processing epoch: 1438 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6222961395978928\n",
            "Training loss:  \t 0.5863134682178497\n",
            "---------------\n",
            "Processing epoch: 1439 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6230000853538513\n",
            "Training loss:  \t 0.5857435464859009\n",
            "---------------\n",
            "Processing epoch: 1440 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6301055699586868\n",
            "Training loss:  \t 0.5875042885541916\n",
            "---------------\n",
            "Processing epoch: 1441 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6177901029586792\n",
            "Training loss:  \t 0.5875466153025627\n",
            "---------------\n",
            "Processing epoch: 1442 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6249063163995743\n",
            "Training loss:  \t 0.5865052312612533\n",
            "---------------\n",
            "Processing epoch: 1443 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.621122196316719\n",
            "Training loss:  \t 0.5870765715837478\n",
            "---------------\n",
            "Processing epoch: 1444 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.629843071103096\n",
            "Training loss:  \t 0.5896829158067703\n",
            "---------------\n",
            "Processing epoch: 1445 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6252306997776031\n",
            "Training loss:  \t 0.5967025399208069\n",
            "---------------\n",
            "Processing epoch: 1446 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6238403469324112\n",
            "Training loss:  \t 0.5874218136072159\n",
            "---------------\n",
            "Processing epoch: 1447 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6240145713090897\n",
            "Training loss:  \t 0.5876866325736045\n",
            "---------------\n",
            "Processing epoch: 1448 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6216586530208588\n",
            "Training loss:  \t 0.5887777000665665\n",
            "---------------\n",
            "Processing epoch: 1449 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6243965029716492\n",
            "Training loss:  \t 0.588778804242611\n",
            "---------------\n",
            "Processing epoch: 1450 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6275041401386261\n",
            "Training loss:  \t 0.5873251378536224\n",
            "---------------\n",
            "Processing epoch: 1451 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6206185668706894\n",
            "Training loss:  \t 0.5878652811050415\n",
            "---------------\n",
            "Processing epoch: 1452 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6244643032550812\n",
            "Training loss:  \t 0.5865928173065186\n",
            "---------------\n",
            "Processing epoch: 1453 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6238489747047424\n",
            "Training loss:  \t 0.5945416629314423\n",
            "---------------\n",
            "Processing epoch: 1454 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6212849617004395\n",
            "Training loss:  \t 0.5855296641588211\n",
            "---------------\n",
            "Processing epoch: 1455 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.627005085349083\n",
            "Training loss:  \t 0.5869097292423249\n",
            "---------------\n",
            "Processing epoch: 1456 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6196129024028778\n",
            "Training loss:  \t 0.586957897245884\n",
            "---------------\n",
            "Processing epoch: 1457 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6329020410776138\n",
            "Training loss:  \t 0.5897297695279121\n",
            "---------------\n",
            "Processing epoch: 1458 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6198389232158661\n",
            "Training loss:  \t 0.5904174864292144\n",
            "---------------\n",
            "Processing epoch: 1459 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6317039281129837\n",
            "Training loss:  \t 0.5878195554018021\n",
            "---------------\n",
            "Processing epoch: 1460 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6256493628025055\n",
            "Training loss:  \t 0.5902594164013862\n",
            "---------------\n",
            "Processing epoch: 1461 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6203653812408447\n",
            "Training loss:  \t 0.5865719020366669\n",
            "---------------\n",
            "Processing epoch: 1462 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6255515217781067\n",
            "Training loss:  \t 0.588228365778923\n",
            "---------------\n",
            "Processing epoch: 1463 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6232377886772156\n",
            "Training loss:  \t 0.5849295824766159\n",
            "---------------\n",
            "Processing epoch: 1464 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6205547675490379\n",
            "Training loss:  \t 0.5880267083644867\n",
            "---------------\n",
            "Processing epoch: 1465 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6246302574872971\n",
            "Training loss:  \t 0.588771803677082\n",
            "---------------\n",
            "Processing epoch: 1466 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6199040859937668\n",
            "Training loss:  \t 0.586683577299118\n",
            "---------------\n",
            "Processing epoch: 1467 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6263158619403839\n",
            "Training loss:  \t 0.5879517048597336\n",
            "---------------\n",
            "Processing epoch: 1468 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.62142314016819\n",
            "Training loss:  \t 0.5970189943909645\n",
            "---------------\n",
            "Processing epoch: 1469 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6284373700618744\n",
            "Training loss:  \t 0.5852039188146592\n",
            "---------------\n",
            "Processing epoch: 1470 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6203483641147614\n",
            "Training loss:  \t 0.5854952305555343\n",
            "---------------\n",
            "Processing epoch: 1471 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251386404037476\n",
            "Training loss:  \t 0.5907224416732788\n",
            "---------------\n",
            "Processing epoch: 1472 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6250689923763275\n",
            "Training loss:  \t 0.5880141466856003\n",
            "---------------\n",
            "Processing epoch: 1473 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251632422208786\n",
            "Training loss:  \t 0.5866149052977562\n",
            "---------------\n",
            "Processing epoch: 1474 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6202019155025482\n",
            "Training loss:  \t 0.5858105719089508\n",
            "---------------\n",
            "Processing epoch: 1475 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6260193735361099\n",
            "Training loss:  \t 0.5873237431049347\n",
            "---------------\n",
            "Processing epoch: 1476 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6255542188882828\n",
            "Training loss:  \t 0.5858181864023209\n",
            "---------------\n",
            "Processing epoch: 1477 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6252108067274094\n",
            "Training loss:  \t 0.5846675246953964\n",
            "---------------\n",
            "Processing epoch: 1478 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6270064264535904\n",
            "Training loss:  \t 0.5862378790974617\n",
            "---------------\n",
            "Processing epoch: 1479 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6201675087213516\n",
            "Training loss:  \t 0.5876082181930542\n",
            "---------------\n",
            "Processing epoch: 1480 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6233698576688766\n",
            "Training loss:  \t 0.5886485934257507\n",
            "---------------\n",
            "Processing epoch: 1481 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6314148902893066\n",
            "Training loss:  \t 0.5871168732643127\n",
            "---------------\n",
            "Processing epoch: 1482 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.627434715628624\n",
            "Training loss:  \t 0.5939119219779968\n",
            "---------------\n",
            "Processing epoch: 1483 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6276938766241074\n",
            "Training loss:  \t 0.5866867393255234\n",
            "---------------\n",
            "Processing epoch: 1484 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6232775002717972\n",
            "Training loss:  \t 0.5865997806191444\n",
            "---------------\n",
            "Processing epoch: 1485 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6309822499752045\n",
            "Training loss:  \t 0.5879642561078071\n",
            "---------------\n",
            "Processing epoch: 1486 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6190049648284912\n",
            "Training loss:  \t 0.5874875694513321\n",
            "---------------\n",
            "Processing epoch: 1487 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.623956024646759\n",
            "Training loss:  \t 0.5859555810689926\n",
            "---------------\n",
            "Processing epoch: 1488 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6229448169469833\n",
            "Training loss:  \t 0.5864561051130295\n",
            "---------------\n",
            "Processing epoch: 1489 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6259748935699463\n",
            "Training loss:  \t 0.5854646548628807\n",
            "---------------\n",
            "Processing epoch: 1490 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6264788508415222\n",
            "Training loss:  \t 0.5849977284669876\n",
            "---------------\n",
            "Processing epoch: 1491 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6286202371120453\n",
            "Training loss:  \t 0.592675855755806\n",
            "---------------\n",
            "Processing epoch: 1492 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6214345991611481\n",
            "Training loss:  \t 0.5863237723708152\n",
            "---------------\n",
            "Processing epoch: 1493 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251231580972672\n",
            "Training loss:  \t 0.5850556522607804\n",
            "---------------\n",
            "Processing epoch: 1494 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6203136891126633\n",
            "Training loss:  \t 0.5899158746004105\n",
            "---------------\n",
            "Processing epoch: 1495 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6296606808900833\n",
            "Training loss:  \t 0.5842448770999908\n",
            "---------------\n",
            "Processing epoch: 1496 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.627407893538475\n",
            "Training loss:  \t 0.5861784070730209\n",
            "---------------\n",
            "Processing epoch: 1497 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6212687939405441\n",
            "Training loss:  \t 0.586690329015255\n",
            "---------------\n",
            "Processing epoch: 1498 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6195423603057861\n",
            "Training loss:  \t 0.5874893009662628\n",
            "---------------\n",
            "Processing epoch: 1499 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.621900737285614\n",
            "Training loss:  \t 0.5866148814558982\n",
            "---------------\n",
            "Processing epoch: 1500 of 1500\n",
            "---------------\n",
            "Validation loss:\t 0.6251629590988159\n",
            "Training loss:  \t 0.5889476329088211\n"
          ]
        }
      ],
      "source": [
        "epochs = 1500\n",
        "learning_rate = 0.0003\n",
        "decay = 0.0025\n",
        "\n",
        "model = ANN_approved()\n",
        "weight = 1\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1,weight]))\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=decay)\n",
        "\n",
        "best_model1, train_lst1, val_lst1 = train_model_2(model=model,train_loader=train_approved_loader,val_loader=val_approved_loader,epochs=epochs,optimizer=optimizer,criterion=criterion)\n",
        "\n",
        "model_2 = ANN()\n",
        "weight = 1\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1,weight]))\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=decay)\n",
        "\n",
        "best_model2, train_lst2, val_lst2 = train_model(model1=best_model1, model2 = model_2 ,train_loader=train_gender_loader,val_loader=val_gender_loader,epochs=epochs,optimizer=optimizer,criterion=criterion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t\t Male Prediction \t Female Prediction\n",
            "Male Label \t 25 \t\t\t 5\n",
            "Female Label\t 15 \t\t\t 18\n",
            "\n",
            "\n",
            "Accuracy: 0.6825396825396826\n",
            "\n",
            "Accuracy male: 0.8333333333333334\n",
            "Precision male: 0.625\n",
            "Recall male: 0.8333333333333334\n",
            "F1-score male: 0.7142857142857143\n",
            "\n",
            "Accuracy female: 0.5454545454545454\n",
            "Precision female: 0.782608695652174\n",
            "Recall female: 0.5454545454545454\n",
            "F1-score female: 0.6428571428571429\n"
          ]
        }
      ],
      "source": [
        "test_gender(best_model1,best_model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_lst1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x12f427c1cd0>]"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(val_lst1)\n",
        "plt.plot(train_lst1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x12f3fde3290>]"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGeCAYAAAC3nVoKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpoUlEQVR4nO3dd3hT1RsH8G+StuluoaWTQtl7j7JBKLJEcQIiKD9ARUCQISAyXIALcaAoAuJAEERE2ZQNpZWyV5mlZbSlhe6RNrm/P26zmqRJutLx/TxPnt6ce+7NuRXJyxnvkQiCIICIiIioApPaugFERERE5jBgISIiogqPAQsRERFVeAxYiIiIqMJjwEJEREQVHgMWIiIiqvAYsBAREVGFx4CFiIiIKjwGLERERFTh2dm6AaVBpVLh3r17cHNzg0QisXVziIiIyAKCICA9PR0BAQGQSs30oQjF8M033wh169YV5HK50LlzZyEiIqLI+l988YXQuHFjwdHRUahdu7Ywbdo0ITs7u0T31BUXFycA4Isvvvjiiy++KuErLi7O7He91T0sGzduxPTp07Fy5UqEhIRg+fLlGDBgAKKjo+Hj42NQf/369ZgzZw7WrFmDbt264erVq3jllVcgkUiwbNmyYt2zMDc3NwBAXFwc3N3drX0kIiIisoG0tDQEBQVpvseLIhEE6zY/DAkJQadOnfDNN98AEIdjgoKCMGXKFMyZM8eg/uTJk3H58mWEhYVpymbMmIGIiAgcPXq0WPcsLC0tDR4eHkhNTWXAQkREVElY8/1t1aRbhUKBqKgohIaGam8glSI0NBTh4eFGr+nWrRuioqIQGRkJALh58yZ27NiBwYMHF/ueubm5SEtL03sRERFR1WXVkFBSUhKUSiV8fX31yn19fXHlyhWj17z44otISkpCjx49IAgC8vPz8frrr+Odd94p9j2XLFmC9957z5qmExERUSVW5suaDx48iMWLF+Pbb7/FqVOnsGXLFmzfvh0ffPBBse85d+5cpKamal5xcXGl2GIiIiKqaKzqYfH29oZMJkNCQoJeeUJCAvz8/IxeM3/+fIwePRrjx48HALRq1QqZmZl49dVXMW/evGLdUy6XQy6XW9N0IiIiqsSs6mFxcHBAhw4d9CbQqlQqhIWFoWvXrkavycrKMlhbLZPJAACCIBTrnkRERFS9WL2sefr06Xj55ZfRsWNHdO7cGcuXL0dmZibGjh0LABgzZgwCAwOxZMkSAMDQoUOxbNkytGvXDiEhIbh+/Trmz5+PoUOHagIXc/ckIiKi6s3qgGX48OF48OABFixYgPj4eLRt2xa7du3STJqNjY3V61F59913IZFI8O677+Lu3buoVasWhg4dio8++sjiexIREVH1ZnUeloqIeViIiIgqnzLLw0JERERkCwxYiIiIqMJjwEJEREQVHgMWIiIiqvAYsBQlXwHsmgvsmAXk59q6NURERNUWA5YiCcCJb4HIH4D8HFs3hoiIqNpiwFIUqb32WJlvu3YQERFVcwxYiiKVApKCX5Eqz7ZtISIiqsYYsJij7mVRMmAhIiKyFQYs5sgKAhb2sBAREdkMAxZzpAXbLXEOCxERkc0wYDGHPSxEREQ2x4DFHHUPi4o9LERERLbCgMUczaRbBixERES2woDFHJm6h4VDQkRERLbCgMUcLmsmIiKyOQYs5nDSLRERkc0xYDGHy5qJiIhsjgGLOexhISIisjkGLOZwDgsREZHNMWAxR8Y8LERERLbGgMUcJo4jIiKyOQYs5nBIiIiIyOYYsJjDSbdEREQ2x4DFHC5rJiIisjkGLOawh4WIiMjmGLCYwzksRERENseAxRxufkhERGRzDFjM0fSwcA4LERGRrTBgMYdzWIiIiGyOAYs5mlVCDFiIiIhshQGLOZpMt0rbtoOIiKgaY8BiDoeEiIiIbI4Bizlc1kxERGRzDFjM4bJmIiIim2PAYg6XNRMREdkcAxZzOIeFiIjI5hiwmMNVQkRERDbHgMUciUT8Kahs2w4iIqJqjAGLOZKCXxEDFiIiIpthwGKORCb+ZMBCRERkMwxYzFH3sHAOCxERkc0wYDFHyh4WIiIiW2PAYg7nsBAREdkcAxZzNAELh4SIiIhshQGLOexhISIisjkGLOZoJt0yYCEiIrIVBixFyMlT4r3t0QAAJVcJERER2QwDliLIpBLcS80FAAjsYSEiIrIZBixFsJNKoIKYml9QcbdmIiIiW2HAUgSJRAJJQR4WgZNuiYiIbIYBixlSdcDCOSxEREQ2w4DFDHUPC1cJERER2Q4DFjOkHBIiIiKyOQYsZkhl3PyQiIjI1hiwmMFJt0RERLbHgMUMqWYOC3tYiIiIbIUBixlSWUHAwh4WIiIim2HAYgYn3RIREdkeAxYzZJx0S0REZHMMWMyQSu3EA0GwbUOIiIiqMQYsZsgK5rBIBPawEBER2QoDFnOknHRLRERkawxYzJBI1L8iBixERES2woDFDIlU/BVJ2MNCRERkMwxYzJGo57AwYCEiIrIVBixmsIeFiIjI9hiwmMNJt0RERDbHgMUMiXpIiJNuiYiIbIYBixlSGYeEiIiIbK1YAcuKFSsQHBwMR0dHhISEIDIy0mTdPn36QCKRGLyGDBmiqfPKK68YnB84cGBxmlbqtMuamemWiIjIVuysvWDjxo2YPn06Vq5ciZCQECxfvhwDBgxAdHQ0fHx8DOpv2bIFCoVC8z45ORlt2rTB888/r1dv4MCBWLt2rea9XC63tmllQiqVAAAkTM1PRERkM1YHLMuWLcOECRMwduxYAMDKlSuxfft2rFmzBnPmzDGoX7NmTb33GzZsgLOzs0HAIpfL4efnZ1EbcnNzkZubq3mflpZm7WNYTCpl4jgiIiJbs2pISKFQICoqCqGhodobSKUIDQ1FeHi4RfdYvXo1RowYARcXF73ygwcPwsfHB02aNMHEiRORnJxs8h5LliyBh4eH5hUUFGTNY1hFPSQkYQcLERGRzVgVsCQlJUGpVMLX11ev3NfXF/Hx8Wavj4yMxIULFzB+/Hi98oEDB+Lnn39GWFgYPv74Yxw6dAiDBg2CUml8w8G5c+ciNTVV84qLi7PmMayiCVjYw0JERGQzVg8JlcTq1avRqlUrdO7cWa98xIgRmuNWrVqhdevWaNCgAQ4ePIh+/foZ3Ecul5fbHBf1kJCEk26JiIhsxqoeFm9vb8hkMiQkJOiVJyQkmJ1/kpmZiQ0bNmDcuHFmP6d+/frw9vbG9evXrWlemdCuEgLAibdEREQ2YVXA4uDggA4dOiAsLExTplKpEBYWhq5duxZ57aZNm5Cbm4uXXnrJ7OfcuXMHycnJ8Pf3t6Z5ZUKdhwUAAxYiIiIbsToPy/Tp07Fq1SqsW7cOly9fxsSJE5GZmalZNTRmzBjMnTvX4LrVq1dj2LBh8PLy0ivPyMjArFmzcOLECcTExCAsLAxPPfUUGjZsiAEDBhTzsUqPpGBZMwCm5yciIrIRq+ewDB8+HA8ePMCCBQsQHx+Ptm3bYteuXZqJuLGxsTpLgUXR0dE4evQo9uzZY3A/mUyGc+fOYd26dUhJSUFAQAAef/xxfPDBBxUiF4tUd0iI81iIiIhsQiIIlX+cIy0tDR4eHkhNTYW7u3up3vvrHVGYEtlXfPPuA8DOoVTvT0REVF1Z8/3NvYTMkEo4JERERGRrDFjMkMpkOu8qfWcUERFRpcSAxQy9+TjsYSEiIrIJBixmMA8LERGR7TFgMYNzWIiIiGyPAYsZnMNCRERkewxYzJCwh4WIiMjmGLCYIdPtYeEcFiIiIptgwGKGfg8LAxYiIiJbYMBihoSp+YmIiGyOAYsZMhnzsBAREdkaAxYzpBJAJRQMC3FIiIiIyCYYsJghkUiggnoeCwMWIiIiW2DAYoZUIoGgDlg4JERERGQTDFjMkEqg7WHhkBAREZFNMGAxQ0zNzx4WIiIiW2LAYoZEt4eFc1iIiIhsggGLGZzDQkREZHsMWMyQ6q4S4hwWIiIim2DAYoZUAvawEBER2RgDFjMkukNCREREZBMMWMwQe1gKsIeFiIjIJhiwmCGT6k665RwWIiIiW2DAYoaUqfmJiIhsjgGLGRJOuiUiIrI5BixmcFkzERGR7TFgMYOp+YmIiGyPAYsZUqbmJyIisjkGLGZImJqfiIjI5hiwmKHXw8I5LERERDbBgMUMqZQ9LERERLbGgMUMvb2EOIeFiIjIJhiwmCGRSCAIHBIiIiKyJQYsZsgkEp29hBiwEBER2QIDFjPExHEFvybOYSEiIrIJBixmSHR3a+YcFiIiIptgwGKGfg8LAxYiIiJbYMBihlT3N8QhISIiIptgwGKGXg8Lh4SIiIhsggGLGVLdOSzsYSEiIrIJBixmSLhKiIiIyOYYsJghlUigVP+aVErbNoaIiKiaYsBihlQC5MFOfKPMs21jiIiIqikGLGZIJRIoNAGLwraNISIiqqYYsJghlUqQJzBgISIisiUGLGZwSIiIiMj2GLCYIZVIdAIW9rAQERHZAgMWMyQSIA8y8Q0DFiIiIptgwGKGfg8Lh4SIiIhsgQGLGboBi8AeFiIiIptgwGKGVAIoBHFISMhnwEJERGQLDFjMkOj1sHBIiIiIyBYYsJihu6yZQ0JERES2wYDFDL1Jt/m5tm0MERFRNcWAxQypRIJc2AMAhLxsG7eGiIioemLAYoZEAmQKjuIbRZZtG0NERFRNMWAxQyaVIBty8U1eFpASC/wzDUi6ZtN2ERERVScMWMyQSiTIEgoCFkUG8PtIIGotsGagbRtGRERUjTBgMUMqAbJQMCSUlwUkXBCPs5Js1ygiIqJqhgGLGRKJBFkFQ0KSPM5hISIisgUGLBbIUc9hUWTatiFERETVFAMWCygkDgAACTPdEhER2QQDFgsoC/KwyNLv2LglRERE1RMDFgvkS+xs3QQiIqJqjQGLBfIl9sZPZKeUazuIiIiqKwYsFlCa6mGJ3lG+DSEiIqqmGLBYIFUhMX5i60RmvCUiIioHDFgsoICJISEA2DWn/BpCRERUTTFgsYACRUy6VeWXX0OIiIiqKQYsFsgrKmCRcgURERFRWStWwLJixQoEBwfD0dERISEhiIyMNFm3T58+kEgkBq8hQ4Zo6giCgAULFsDf3x9OTk4IDQ3FtWsVZ26IClIoBRPzWBiwEBERlTmrA5aNGzdi+vTpWLhwIU6dOoU2bdpgwIABSExMNFp/y5YtuH//vuZ14cIFyGQyPP/885o6n3zyCb766iusXLkSERERcHFxwYABA5CTk1P8JytlJntZru4q34YQERFVQ1YHLMuWLcOECRMwduxYNG/eHCtXroSzszPWrFljtH7NmjXh5+enee3duxfOzs6agEUQBCxfvhzvvvsunnrqKbRu3Ro///wz7t27h61btxq9Z25uLtLS0vReZa3oeSwqnWMl8Oh2mbeHiIioOrEqYFEoFIiKikJoaKj2BlIpQkNDER4ebtE9Vq9ejREjRsDFxQUAcOvWLcTHx+vd08PDAyEhISbvuWTJEnh4eGheQUFB1jxGsWg2QDRGka493jwW+LI1cOnvMm8TERFRdWFVwJKUlASlUglfX1+9cl9fX8THx5u9PjIyEhcuXMD48eM1ZerrrLnn3LlzkZqaqnnFxcVZ8xjFkiy4mT6pm/FWHagcXV6WzSEiIqpWynXG6OrVq9GqVSt07ty5RPeRy+WQy4vo8SgDgZJk0ydzUgDU1S/jcmciIqJSY1UPi7e3N2QyGRISEvTKExIS4OfnV+S1mZmZ2LBhA8aNG6dXrr6uOPcsTw8ED9Mnje0ppFKWWVuIiIiqG6sCFgcHB3To0AFhYWGaMpVKhbCwMHTt2rXIazdt2oTc3Fy89NJLeuX16tWDn5+f3j3T0tIQERFh9p7laWreJNMnFRmGZeoelphjwJ2osmkUERFRNWH1KqHp06dj1apVWLduHS5fvoyJEyciMzMTY8eOBQCMGTMGc+fONbhu9erVGDZsGLy8vPTKJRIJpk2bhg8//BDbtm3D+fPnMWbMGAQEBGDYsGHFe6oycEGojxOqZsZPKjINy1T5QHo88NNg4Me+gCCUbQOJiIiqMKvnsAwfPhwPHjzAggULEB8fj7Zt22LXrl2aSbOxsbGQSvXjoOjoaBw9ehR79uwxes+3334bmZmZePXVV5GSkoIePXpg165dcHR0LMYjlR2lYCK+M9bDIiiB+Ava9/k5gL1T2TSMiIioipMIQuX/p39aWho8PDyQmpoKd3f3Ur9/8JztAID19h+im+ySYYUmQ4CO/wMahQKLCua6eAQBfeYAfxcMJb19C3CuCeSmAxteBJo9CXSeUOptJSIiqiys+f7mXkIWmD2wKQDATmJiIm30duC3Z4HMJG1ZahygzNO+z8sWf0b+ANw6DOyYWUatJSIiqnoYsFhgYp8GAAB7aAOWCFVTw4pZD/XfGwtY8nO1ZTvnlFYTiYiIqjQGLFawgza3yhFlK/yc31+/Qvw5/fd5WYbHMgdtWcR32kCGiIiITGLAYgU7nR4We4kSdwVv/Qp/6ueY0Vs9pA5M7AolvKv8U4iIiIjKHAMWK3yQP1pzLIMSmTCyiqlGPe2xbg9LfkHAotvDAoiriYiIiKhIDFiscFzVUnN8TNUSWYKR7QEEnZ2bdZc755kIWJjCn4iIyCwGLBYa1FLcJqBjznd4PncBwlUtjPew6Kbk1xsSKuhtKTwkxBT+REREZjFgsdCyF9oCAJLggf8EcYWQFEbmn+gO8Sh0J90W9LBICv3KGbAQERGZxYDFQk4OMvRspJ1kO6JTEFr7OhhWTL+vPY7erj1WByyFAxQOCREREZnFgMUKPRpqAxY/D0fIWw61/GJ1wFJ4ki0DFiIiIrMYsFjh6faBmmMnexm8vLzRJedryy7W9LAUClC4SoiIiMgsqzc/rM583LSTbANrOMHd0R7x8CriCh13o4CcVCNDQgxYiIiIzGHAYqU/J3bFiZsPMailPyQA2tfxBBItuPDabuD7XkCXN/TLOSRERERkFoeErNShbk1MeqwhZFIJpFIJ1k/ogmdyF+GGyh8qQVL0xY9i9PcXAtjDQkREZAEGLCXkaC/DzHGj0U/xOUbnWbCZYdpd/ffsYSEiIjKLAUsp6NbQG96uDghXtcBP+Y8XXTk7Rf/97eNl1i4iIqKqggFLKTn89mPo09QPi/JfQbuclaYr5qTqv989V5yQS0RERCYxYCklzg52eO/JFgCAR3DHOMUM4xULBywAcDu8DFtGRERU+TFgKUVBNZ1xcGYfAECYqoPROsrCQ0JERERkFgOWUhbs7YJrHw0CACzMexmPBFe987LEC7ZoFhERUaXGgKUM2Muk6BxcE+uUA9Au93tbN4eIiKjSY8BSRr57qX3BkQQnVY1t2hYiIqLKjgFLGfFyleN6wdDQK4q3cUDZxnTlo8vKqVVERESVEwOWMmQnk2LPW70wPrQNshx9TFfMSgYifgBWdOGKISIiIiMYsJSxxr5umBbaGEEuqqIr7pwFPLgM/DTE+Plr+4Cre0q/gURERJUAA5Zy0qSG/vuP8l40XlEwsrdQXg7w27PA+ueBnLTSbxwREVEFx4ClnMgb99Mcd85ZgQShpuUXK3O1x4qMUmwVERFR5WBn6wZUG51fBZxq4KK8LRLX3cJeVXvz1xjD3Z2JiKgaYg9LeZHZA21fRItmzbFtcndkwxHr8/tadq1ukCKYmQtDRERUBTFgsYHWtT2xcGhz/K60MGDRDVKMzXEhIiKq4hiw2MjY7vXw64LXcUPlb76ybg8Lh4SIiKgaYsBiQx5O9jgrNDA8cfpX/fe6vSrKvLJtFBERUQXEgMXGQvoOMyz8e5L+e70eFgYsRERU/TBgsTH/4OZGyzNz87Vv2MNCRETVHAMWG5O61jJa/sTXR7VvVAxYiIioemPAYmteDaGsHWJQfCspAw8zFeIbnVVCglJRXi0jIiKqMBiw2JpUCtm43cCUU3rFzsjF0K+PAtkpQNRPmvKNEbfKt31EREQVAAOWikAiAbz0VwuNle3C3ZQsCFsmAOHfaMp3n79T3q0jIiKyOabmr6Bm2f+Bc0J9SK7p79DsgHwTVxAREVVd7GGpwNpJrhuU2YGJ44iIqPphwFKRjNyo93a6/WaDKk6SXIMyIiKiqo4BS0XSZKDZKl5IQ24+e1mIiKh6YcBS0fSdX+Rpb0kqjt9IRnoO87EQEVH1wYClouk1E5gXb/J0sCQen/30B/76cCQGz12BVYdvlmPjiIiIbIOrhCoieyeTp/rLTqG/TMzZEihJwrgdwZjQq355tYyIiMgm2MNSifWTnQYAwzkt0buAY18CgmCDVhEREZU+9rBUVC61gMwHFlWNT81BXS8XbcHvw8Wf3k0smshLRERU0bGHpaIav8/iqndTso2fiDlSSo0hIiKyLQYsFVWNYOCd+xZVfXFVBHaeN1I33bLriYiIKjoOCVVkDs4WV5342ykEejrBRS6DJpn/hT+B59aUSdOIiIjKE3tYKrqeMyyuejclG1cTMvTKclPYy0JERJUfA5aKrtubRZ7uKLkCCVQmz4/+/jAErhYiIqJKjgFLRefkCSxKBWbfBhobrvjZLH8fK+2X65ToBycPUtLx8NEjCIKAj3ddwb/n7pVpc4mIiMoCA5bKwskTkLsZPTVAdhJTZFsAANJCAcsvDkvg/kMHRJ6MxHcHb2Dy+tNl3VIiIqJSx4ClMkmJM3lqRsHOzrJCw0O1JUmwz3kI/zNflmnTiIiIyhIDlsqkUajZKjIY38n5Umyi5jgnj7s9ExFR5cKApTLp/Crw+EcmTx+c2Qd2JgIWO+Rrjh+k50IQBIRdTjCddI6IiKgCYR6WysTRA+jwMrBnntHTdWo6o3fDGsAdw3P2OoFMz08OaI6dHWS49D7T9xMRUcXGHpbKxsEVCO5p9JQ05xFWDPU3es5Uz0uWgsNDRERU8bGHpbKRSICX/xGPf30GuLFfe+6TeiYvk0vyTJ5TqQTcSs5ERk4+2gR56p27fD8Nj7IU6NbAuyStJiIiKhH2sFRGEon4emmLxZe4wPRclZTsPPT7/BCeWnEMD9Jz9c4N+vIIXlwVwbkuRERkUwxYKjOJxOKqTWsAG1/tYvTcdp2NE++nZmPpziuYtP4UsnWGi34Oj0FajuleGiIiorLEgKWye3GTRdUkuekIqe+lV+biIAMAzN96QVP2ID0XKw/dwPZz9/HWxjOa8u8P3US3JfuRp9TmeUlIy4FSxbT/RERU9hiwVHb1ellWLzcdEARsndQdANAy0B2ZRibcjlt3UnO862K83rmM3Hy8uOoEHmUqEH4jGSGLwzB1AzPnEhFR2WPAUtnZOwJDPjdfT1ACeVlo+2gvbs1sgn8m98BLXepY/XH/xTxCuw/2YuSqEwCAf89ph5PSc/Lwx8k4pGZph46+2X8NH++6YvXnEBER6ZIIVWAr37S0NHh4eCA1NRXu7u62bk75y00HltQ2X2/gx8Cu2eLxolQAQPCc7SX+eC8XB9R0cYBKEHDjQSYA4M1+jTDpsQZo8u4uAMDxOX0R4Olk9PpdF+4jNTsPwztZH0AREVHlZc33N5c1VwUmNkU0cPOgQdH6CSEIu5wIV7kdvgy7VqyPT85UIDlToVf2Vdg19G6sXQptajsAQRDw+q+nAADdGngjqKZzsdpARERVGwOWqqLvfGD/B0XXUSoMiro18NbkWJnQqz7+OnUH8/++CABwtJdi8dOtoNgyCUrIMC9/nFVNeva7cM2xqQR1OXnaSbwPMxUMWIiIyCgGLFVFr5lAg8eAdU8BinRg1J/iz8v/Atf3AjmpRgMWAIAgAOc3wdW/LUZ3bYwXQ+pix/n76BRcE8hIhJ/dQQDAx/kjkAaXYjVv6+m7iI5Px8b/4rB8RFtkKfKRk6eCn4ejps7VhHT8dfouXutdH/4exoePiIioeuIclurgyzbAoxggqAsQJ06WVc9hAQBc3ApsetmwHEBW8l04f90cAJAxNRrT/7mDPZcSSqVZEgmw482eGPTlEb3yTsE1sOn1bqXyGUREVHFZ8/1drFVCK1asQHBwMBwdHRESEoLIyMgi66ekpGDSpEnw9/eHXC5H48aNsWPHDs35RYsWQSKR6L2aNm1anKaRMcqCVTvqYAUAlPlAXkH22jv/mbzU2UHbCedqB6wY1V7zft7gZohZOgTt6ngWq1mCAINgBQCibj8q1v2IiKjqsjpg2bhxI6ZPn46FCxfi1KlTaNOmDQYMGIDExESj9RUKBfr374+YmBhs3rwZ0dHRWLVqFQIDA/XqtWjRAvfv39e8jh49WrwnIkNpdw3LfhkGfBwMZCaJkYMpgs7cE6UC9jLtHxkXuRjMLB/eFlP7NcL+Gb0157xdHYrdXIlEgnsp2Siq8y89J6/I80REVLVYPYdl2bJlmDBhAsaOHQsAWLlyJbZv3441a9Zgzpw5BvXXrFmDhw8f4vjx47C3twcABAcHGzbEzg5+fn4WtSE3Nxe5udo9b9LS0qx9DIop6Nn4phOQ/dB0PVW+9jhfnAPz7pBmCLuciGHtAgAAdb1c8Fb/xgCAvyd1R2J6Lvo29UF6Th7GrTtpdY+JUiWg29L9mNinAV7v1QDOchmycpWIjHmIx5rUwpX4dDy14hheCqmD955qKTZTJRRssWT5dgVERFR5WNXDolAoEBUVhdDQUO0NpFKEhoYiPDzc6DXbtm1D165dMWnSJPj6+qJly5ZYvHgxlEr9VSPXrl1DQEAA6tevj1GjRiE2NtZkO5YsWQIPDw/NKygoyJrHIF1FBSuAfsBSMGl3fM/6+P3VLnrDRWptgjzRv7kvZFIJPJ0dsPjpVvB2lRerad8dvIE27+9Bo3k70eb9PZjw80msPHQD3+y/DqVKwLrw28hTqvDdwRuo/84OTPj5pPmbEhFRpWRVwJKUlASlUglfX1+9cl9fX8THxxu95ubNm9i8eTOUSiV27NiB+fPn4/PPP8eHH36oqRMSEoKffvoJu3btwnfffYdbt26hZ8+eSE9PN3rPuXPnIjU1VfOKi4uz5jHIGirdIaFc0/VMaOLnhpPvhmLWgCYIbeZT4uZ8tucqZFJtL0qjeTs1mXT3XU7Ee/9cNJnzhYiIKq8yX9asUqng4+ODH374ATKZDB06dMDdu3fx6aefYuHChQCAQYMGaeq3bt0aISEhqFu3Lv744w+MG2eY+0Mul0MuL96/2qulUZuB354r3rVGhoRwYiVwdRcwYj3gYFnelEmPNQRgPLPugBa+2H3R8pVHurtLF7b2WAzWHovBy13rwstVjmc71Mbx60no08QHtdz4Z4aIqLKyKmDx9vaGTCZDQoL+l0tCQoLJ+Sf+/v6wt7eHTCbTlDVr1gzx8fFQKBRwcDCcnOnp6YnGjRvj+vXr1jSPTGnUv/jXGhkS0qT3P7se6DTeqtsteaYV3vvnImY+3gSX76ejZaA7xnavhwV/X8DP4beL385C1hXca9neqwCAFgHu2P5mT6N1Vxy4Di8XB4zoXAfpOXmwl0nhaC8zWtcainwV7KQSSKWcV0NEVFJWDQk5ODigQ4cOCAsL05SpVCqEhYWha9euRq/p3r07rl+/DpVKm9H06tWr8Pf3NxqsAEBGRgZu3LgBf39/a5pHRZmwH/BtBfSaZd11egFLoSEhZR6sNbJzHVz5YBDG96yPz19og7Hd6wEAFg1tgRuLB2vq1XC2t/reRbl4Lw3fHryOmCRxr6Oj15Iw44+zuHA3FZ/ujsacLeeRrVCi1ycH0G3pfotXIG05dQf/nL1nUJ6tUKLnJ/vx0uqIUn0OIqLqyuplzdOnT8eqVauwbt06XL58GRMnTkRmZqZm1dCYMWMwd+5cTf2JEyfi4cOHmDp1Kq5evYrt27dj8eLFmDRpkqbOzJkzcejQIcTExOD48eN4+umnIZPJMHLkyFJ4RAIABHYAJh4FWr1g3XW6c1hiI4A/dXpUJFIg4VLRy6ItJJVKIJNK8Ex7cbn7kmdao5GPKwDAwU7/j+mITkFoV8cTWyd1h39BptzXetU3+xmf7IrGiwW7TL+0OgJ/nrqDJ77WLp+/dD8Nj7Ly8DBTgW1GgpAd5+/j3J0UzfuHmQpM/+Mspvx+Gjl5SmyOuoM/o+4AACJuJSMhLRfHbyRz+TURUSmweg7L8OHD8eDBAyxYsADx8fFo27Ytdu3apZmIGxsbC6lU+wUTFBSE3bt346233kLr1q0RGBiIqVOnYvbs2Zo6d+7cwciRI5GcnIxatWqhR48eOHHiBGrVqlUKj0h6vBoCcncg18Kl4Lo9LIc/0T+3823x5/DfgGZPlErzPn2uDab1a4w6Xs5oEeCOvZcS8GJIHeSrBLRcuBsAsHBoCzg5iEM2B2b2gUKpgpvcDt8fvmn2/vdSc0zuUP0gPUdzPHXDGTTxc0NTPzHz4oW7qXjjN3GTxn+n9MDMTWfxQkft6rRrCRmYueksAGBIa3/Y6fw/kJOn0rS3uBLTcpCYnouWgR4lug8RUWXF1PzVlSAAseHA2kH65d2nAec3Ac+uBup2BWKOAj8NKfpejQcCL24ss6aqHb2WBHuZBCH1vYyeNxWIWKqxryuuJmTolTXzd8fbA5tg2oYzSM02PQQ2d1BTLNkprlaKeKcfriVkaIaDIt7pB193R4NrMnPz4ewgM8gdIwiCQZn62fZN742GBT1PJZWSpcA/Z+/hidYBqOEiDs8qVYLeKiwiorJU5qn5qQqQSAAHIxsZHlsuZsZdOxBIuAicK/tAxFI9GnmbDFYA4MTcfnrDRNYqHKwAwOX7aRi79r8igxUAmmAFAFKz85CRq+2ZenfrBaRkKZCvVOHHIzex4sB1rD12C+0/2Iv3/rkEALibko2cPCXupmQjZHEYPt8Trble998UT31zFCN/OIHY5CyLnmnXhXi89stJvfan5eQhPjUHUzecwfy/L+LNDacBALeSMtH2vT34ZNcVU7crNbn5Shy/noTcfMMl6PGpOfg5PAZZinwjV4rXqlSV/t9ZRGQl9rBUZ4pMYHFAye9TTj0sloqOT8dne6IxKqQOtp6+i2c71Mbl+2lYvKPsv4gBwE1uh/Rc/S/bgS38sOui8VxFjzf3xb7LCajpIkcjH1eE30wGAMQsFXu2Pvj3ElYfvWVw3YGZfRB1+xGeaReItJw8/Bx+G0+3C0RQTe1Sc3XPjLerA6aGNsboLnXR/oO9eJipv3N3zNIhGL/uJPZdTtD77JJQqgRk5ObDw8lwAvU7f53H+ohYjO5SF+892UIvS/FTK47hbFwKnu9QG58+30bvupw8Jfp+dhC13OTYOqm7Xk/Udwdv4M9Td7Dh1S4WJyv89cRt1KnpjF6NS2/4+ei1JBy+9gCzBjTR28qCiAyxh4Us4+ACzLohzmupQpr4uWHVmI7o08QHy0e0Q89GtfBqrwaY0b8xmvi64ZVuwWbvMbVfo2J/fuFgBYDJYAUA9lxKgEoAkjJyNcEKABy6+gBpOXlGgxUAeOyzg5i56Sz+PnsX7/x1Hsv2XtUMQ2Up8vH25rOaukkZCszfegH9lx0yCFbUEnXm8ABA3MMs3Hyg7XX66dgtPPvdcaRmib01jzIV2BAZi8yC591x/j5+i7gNQRBw51EWxv70Hzp9tA9n41IMPmt9hJjJ+pcTt9H384N47ZcozTl1/U1Rdwx6Uu48ysa91BycvZOK2If6vUwf77qC64kZ6PjhPihVAhb+fQF/nNQmlcxS5CPq9kPNPc/GpeDdrRcwZk0k8pQq5CtVsIRKJeDvM3cR99B4L9dLqyPww+Gb+D3SdLZuIrJemSeOowrOxRsYtxf4pF7x76HIBFQqQFqx498p/RphSr9GyMlTIuxKAuIeZmPyYw3xXIfaGL0mAnEPszV1p/ZrhC/DrtmwtcDLayLRoJaRYbtClu29qmn77eQs9P70AG6bGDK6lmg47AWIPR66AUBqVh56fnIAAHDhvQFwldthUcHw1czNZxHo6YSbSZk4fPUB5mw5D3dHO6TliIHLvL8u6N37qRXHMKS1Pz5/vo3R/DYxyVmISc7C9cQMg/k5G0/GoamfG4K9XBCTnIn9V7SbrN54kIG6XsZ/PyNXnUDkLXHbiWfb18ahq4l4759LuJ2chQ+GtcToLnURnaDNpB267BBkEgn2Te8NqVSCtJw8ONrJDFaoAcDmqDt4+89zkEiAW0tM90TdeZRt8hwRWY8BCwHONUt2fcwR4PfhwKhNpdOeMuZoL8P+GX0gk2iTuh15uy/6fnYQNwvytEilEkx+rCG+OXAdT7T2hyJfhT2XtAkTn2obgL/PGC59Lm03HmSaraMbaAEwGawURd3joTb4qyOa425LwjTBCADsvWSYlVj3vDHbz91Hm9oeGNm5Dr7YazwQDF12CMfn9NUrm7vlPABAKgEKT1tJy9Z+5sFo/d3i1cEKAPRfdkjz3xUANv4Xi451a+Dtzec0Zerf2fm7qXhpdQTSc/JRv5YL9s/oo7n/vZQcvBhSB0evJwEwv5rfrojJy4Ig4HZyFurUdGZiQSILcQ4LiVb1BZKuWb7c2ZhFqaXXHhsYuPwwrsSL/+pWz+FQr9hRqQTM/vMcNhXkWdnyRjc88+1xAECDWi4WBRZU+nzc5Hirf2NNYFNSnYJr4L8Y7e7iVz4YCAeZFPXf2QFA3I38sz3ROHJNDFra1/HET//rDHdHe/wcHoOLd9OwUWcYave0Xmji52bwOb+cuI35Wy/glW7BWPRki1JpO1FlZM33NwMWEinzxCRxH/mar2vKgkcVflioKN8evI5PdkWjnrcLDszsY3D+yLUHGL06EoAY0CSm5cDV0Q7/xTzCy2vE8il9G+JmUia2nzO935Epvu5ytK9TAypBsGpvJSo7zg4y1HB2wN0U08M7TvYyhM/ti7bv7zU418TXDbvf6mVQ3nLhbs1KsuJMcBYEAfkqQW9Sb75Shee/D0fdms5YPqKd1fcksgVrvr85JEQimb34GrAE2D3XfH1jsh8BLoWWHcdGAKo8ILhHydtYxib0rI+6NV3QuZ7xIbKejWrhq5Ht0Nxf/J/KpyC3Sq9G3vh6ZDs083dHQx9XCIKAY9eTkJKVh98ndIGnsz3GrzuJmQMa462NZwvd0xtrX+kEO5lU05sTeeuhQcAy/4nm+ODfSxY9R7s6nni5azCmbTxj5W+ACstSKJGlKHouSnae0miwAgDRCen4M+oOnu1QW69cbidFhonNz+MeZiHuYRa6NfQ2+Zlzt5zHjvP3sW9Gb9R0dsDZO6n45+w9nI5NwenYFHz2fBvYcYUSVTHsYSFDe+YDx78Sj7tOBrpMBL6woNs65HWgx3Rxk8R/pwGNHhez4cocgLdvAfLSSXhWGeQrVUhIz0Wgp5Ne+Y9HbuKHwzfh5SrHa73qY1i7QINrBUHA94dvoqazA5IzFXiUpcCcgU01wxJqnz/fBjMKsut+O6o9/jl7D/W8XfD2wKaaOvGpORi56gRuJWVCbidFbn7RK2Ec7KRQFFGnVaAHzt8tnaG/zvVq6s01qcpe6RaMIa39cS8lG0+2CUD3pftxL1VclXV2weN4buVxBHg6Yc0rndCg4L/znxO7oUPdGsjJUyI3TwUPnf211MvVQ5v5oq6Xs8FKsv/mhRrsTq7IV+Hr/dfQq3EtdAou4bw1olLCISEqmdwM4OASoMXTQO2OYtmtw8Dxr4Fre4q+1rsx4OorTsTV9dYlwMPwy5ksF5uchZx8JU7dfoSTtx/h42db48i1B7hwNxWTHmtokB1X16V7aQjwdMS3B2/gh4ItDGrXcMKv40IglUiw9cxdnIlLwYoX2+O3iNv4cPtlAMAHw1qiS72aeP/fS2ji64ZZA5vgr1N3McfKOSMT+zRAoKcT3t0qriBaPz4ELWt7oPUiM3+eCjk0qw9WHrqBB+m52Hc50fwFFdC8wc3wW8RtxBRM9B3Syh/bz4tDiIGeTprhp6n9GuHlbsFo/4HYe6NerQWYz+qsnjuTkqVAanYe6nq5YH1ELN75S/zvZskwVEqWAsO/P4GhbfwxuW8j5CtV7LWhUseAhcrOqr7A3aii6zi4AopCy2ennAK8GpRdu8gi+UoVzt5JRVpOHloHesDLRIK1JTsv4/ydVKwd2wlyO/2lyCqVgIhbD/HLiRhcvJeGHW/2BAAs+Psi9l9JwKOCPC1DWvtr5vKovyCbvLsTufkqnJ7fHzVcHLD/SgKyFSr8cTIOh64+0HzGL+M6a+YLqbUIcMf2gs9auvMKVh66UQq/EdvwcZMjMV0cE3KQSaEwkgNmfI962B+diJs6E7qb+rlhSt9GmLT+VJH3/3VcCHo08kbjeTuhUKpwbE5f/PFfnGapviUBy9dh1/D53qsAgG9ebIeZm87iqxHt8HgLP4ufk8gczmGhsjPidyDsPSA/F7iw2XidwsEKAORlibla4iIAv1aWDw8JApB4Wey5kfGPa0nZyaToULeG2XpzBzUzeU4qlaBrAy90beClt+/R5y+0gSAIyM5Tapb8RsU80tuwMXJeKLIVSs3eRX2bipO8h7T2x/VEcQPJyY81RM9GtbBtcnecv5sKDyd7/HYiFp+/oM16W0RnkoaXiwOi5vdHTp4Sey4lYN6W85qkfjFLh6DXJwcMks/pMpaxuLSogxUARoMVANh3OUHTC6N2JT7dbLACAFcT0vH94Ruae/964rbe8GRaTh7cHQ0zEOvK11lHPnm9uH3Dq79ElUoWZKLiYA8LFY8iC9i3EIj8wbL64/YB8eeA7dOBBv2A0VvElUnZj8TNFZ29gJf/NQxKjn8D7JkHtB0FDPu29J+DylSeUgU7qaTI4ariSEzPwegfI/Fch9qo4eKAC3dTceJmsmZZOgC9PCoAMGZNJA4X9OLELB2C5IxcjF4diUv3tUv5vVwcsOWNbth3ORGDWvqh29L9Bp/t5SLOLapsdHMHzRrQBK90C8Zfp++id+Naets5AOI8qpmbzuHPU3cM7qMOWLadvYdNJ+Pw5Yh2qFkQgBbXmbgUHL+RhFd71uewUzXDISEqP4s8zNcBgBf/AHbNAR6K8ycwPgxYM1DsbblX8C/GN08DNesD2SmARAo4ugNLgrS5YSp5nhcqe9cS0vHh9ss4dPUBvh7ZDkPbaPfK2nr6LqZtPINWgR74Z4q4ai0hLQf9lx3CkNYBWDi0uUEmXmNzRXo28sYLHYMw5ffTeuWjQupgYp8G6PHxgTJ4srLj5+6IE+/0Q0ZuPuIeZiGopjMe++wgHqQbX8akDljUv5tRIXXw0dOtStQG9b0+erolRoXULdG9qHLhkBBVPOtf0H+/uj8gqLTBCgBc2wtc3ArEHgdq1BMDGMFId3leDnD0C6DpYMC/jeF5qrYa+brhx5c74nZylsG2Bk+1DUAdL2c09tUmcvN1d0TU/P4me4He7NsQq47cwrbJ3fHRjss4GP0A/+teD32a1EIzfzeELjsMAJg7qCkm9KwPqVSCxU+3wjt/nccbfRrgxZA6+PHILfx0PKZMn7sk4tNysPX0XSzcdhGp2Xlo5u9uMlgxJjmj9Hqbrur0kBEVxoCFSuaVHcAfo4GsZPN1dRkLRHa+rT1+dAvIyzZe7/AnwJHPgUNLtb0ul/8VVycFdbKuHcVx77S4VNuXGUorInuZ1GBPIkDcDbp9HcP5O0XtqDz98SaY0q8R7GVS/DC6I+6mZKOetxgINfTRBj4DW/ppUuy/GFIHfZv6wNddDolEgkVPtsBrvetj8vrTcJHbaYalKhLdnD2X75vPdp2ek6c5FlDpO+mpkmDAQiUT3B2YcRU4txGo0wVwDwTCvwb2f1jye5/+VZznopaZLCamu3VYv17yDWDjKPG4rIeNctKAH/qIxwseAlLDzfyoalEHNA52Uk2wohY+ty+SMxQGmzD6eTjqvff3cMKfE7tBEATUm6ufT8eYKX0b4tn2tZGWk4dD0Q80q3XMea13fZyMeYSo24/MVy6mPKUKrXSWo+++mICD0Yno08SnxPd+YCqbHhEAzm6ikpPZAe1GicuW7R2BkIliuXsgMMrESiJL7JwlZslV+7Q+cGUHkFuo2/jmQe1xnomspKl3AWUprPjIStIe6wZTVC35ezjprYIyRyKRYMOrXTBbJ7mfrlVjOuLJNgF4tVd9BHu7oHVtT0zp18ji+88d1Ax/vNYVHzzVAnvf6gVvE8vWS6LRvJ0GZa+s/Q8AEB2fjvf+uYikYgYeO87Hl6htVLUxYKHSJ3cF5t4R56A06g8M/Lj07r1hpLiySE2RKa48UsswkkzsdjjwRXPg16dLoQE68xxUDFjIel3qe2FinwYY2TlIU9bUzw1/TuyG/s198dXIdnArtOS48HwcY0IKtpSQSSUY3TUYjXzdsOn1rqXbeDMGf3UEa4/FYM6f55CvVCHTzLLwTSfjsGjbRb0yS9aBRMenY83RW8gzsSS8sstS5ONWUvE3VDX3O3yYqcDDSrjSjUNCVDbkOjvUdn5VXPWzaw4gKEt+7wydfXY2jS10LhGoUWiVQdRa8WfhoaTi0J2YyR4WKoFFT7bAU20D0aFujSLn0QDAm/0aYeqGMxjRKQgDW/rhlbX/4bVe9TF3cDMkpucgNjkLHY2k26/n7YL9M3pj4baLmh2mezbyxvejO6D5gt0WtbO+twtuWvDl+c3+a1AW5G7ZdzkRg786gqsJGTi74HG9bQV0zdp8zqBs7pbzWPps6yI/a8By8f9liQQY272e2bYVZfXRW/B2dcBTbQ0zcZ+7kwIfN0eDIb6ysu3sPXy0/RIS0sQeqq2TuqNtkKdV98hWKDHoy8NoX6cGlg1va3A+N1+pyZ587aNBZv/sVSQMWKjsSaVAyKviCwDObQK2jBePazUFajUBLv1dvHtfK/SXbo6ROSySUpxnovsvF1XZJBWj6kFuJ0OX+l7mKwJ4qm0g2gZ5onYNZ8ikEpya3x81CoIAHzdH+LiZ/kKtX8sVv4wLwbWEdPwWEYuJfRrAyb7o/yf2vNULj38hBgVN/NwsClg+26M/z+ZqgphA8sStZAywIjvuhv/izAYsaufulGzO2pX4NM2mooUDluj4dDz5zTEAxdtRuzjeLLRUfteFeKsDlj2X4hGTnIWY5CyjAcujzDydY4VmE9fKgAELlb9Wz4lf9rU7Ad4NgaRrxQ9YCjOWZVdSiv+C0F21xICFypHuxN7iJGpr5OuGRU9qV7b9OKYj0nPz4OvmiLsp2RjaJgCLtl1EiwB3vaXf5oKbyuy2TibhPKUKJ2Me4ej1B5gW2tjiictKlYCcPCVc5IZfpyqVoFk9BgDHrifhn7P3MG9IM4Nhv9KSr7R81dbk9afxR6Fhw19P3EbY5QR88lwbgw00bY0BC5U/iQRoO1L73kM7lo+p54Czv4ubLxbHgY+A8BXACz8D7v5imbQUAxbdIIVDQlSJhTb3NSgz1rPRPMAdDXxc8enu6FL7bEEQSmUOhUqnxzM9J8/iIEClEpCpyEdKlrYNWQolRq46AUBMpicz8vdG3MMs1HKT6yUYHL06AsdvJCPinX7w1emtSM7IxcAvj2BIK39NoDjqxwgAgKvcDu8+0dxsO6XFSBCtVFkesETGGO6Wrt6gtNNH+7DypQ4Y2LLi7B3FgIVsz94RmBMHSO0AB2egzxzgvx+BzGLkq0gq6JZe1hQY/hvQ7Imih4Qe3gLc/MU2WEI3YGEPC1UDUokEkx5raDRgqevljMGt/PHdQdMbURqb/zl3y3ls+C/O5DXHriehe0NvzV5Vqdl5yM1XGgx9/X3mHjyd7NHQxxXz/76IT55tjRc6BZm4q9aEn08i7Eoi/qcz/yVboZ1fdzMp02CvpdOxj/D0t8dRv5YLVr/cCYIgYNfFeBy/Ieag+ufsPYzvWV9T/6fjMXiQnoufjsfA3dEOh65pVxiq97DKU6ow+89z8HaVI+xyAgorzo4WSp1fuCAIWLzjMmq4OGBwS38Ee7tYlTfn3a0XMLCln96eYbbEgIUqBsdCKZmnnQdiTwAQgF+Kubpn4yig3wLtpFsA+HuymOp/4FIg9Y6Ycbd2Z2D8XsPrU++ISeKaPqH9m4M9LFRN1HKT40F6Lvo0qQUAmP9Ec818D11ujtZ/jRQVrABiT8SNxYPx3MrjyFYoNXtETe/fGBfv6c9bWRd+W3P89p/n4CyX4fiNZLz3ZAu9CaXrI2Lh6y5Hv2a+CLsirib8NUJ77Se7r2iOU7PzsPZYjN7nqPdVuvkgE499dtCgzXmFhmJ0N4/8av91o8/5Z9QdbDl11+g5AJBAgl0X7sPdyR7dGnibrGfqc4/fSMaqI7cAAJ/sisbJd0Ot6oGRSoC/z9zFB/9ewvejO6BDXcOJ3eWJAQtVTPZOQIPHgOv7SnafsPf135/+Rfx56W/tUNSdSMPrlPnA8tbiqqaX/wHq9RLL2cNC1cTBmX3wMFOh2RhxXI966NnIG1KJBKHLDgEQe0/MD8NovyAfZSqw8WTRwYra5ftpOB2bole2zIIEeuqdpTvWrYFn2tcGAFxPTMc7f50HANxaMlhTV5GvnZOmGzjcSDScC2duBXXhJdYqM4HBrgvxmLPlfJF17qfm4JsDYrBj6cRf3c8tnA/nanw6atdwLnyJyR6UtJw8TN1wBgAwdu1/OLdogEVtKCuVZz0TVU/BvYDAjoCdTldwr1na3C7OXkCHV4p379Qi/uL861XtEux7OjP3VbqTbtnDQlWXi9zOYBfnxr5uBtseeJmZAKzQ6XmYtP4Ulu68UkRtrfSckv2DQPf6JJ39jtKyzd+3cG/JF3uvYutp0z0h4jUq7LkYjyU7L0OlEvR6Oox5/dcos+3QDTjylCrk5isRdjkBufmm00PoBk4qwbDXJ1+lH1idjn2Edh/sxR9Ger1y8rR100r436M0sIeFKjY7B2BCmBgoXN8rZs/1ayme6/K6+FMQgHajgR/7Ff9zVEpx88U974rLrK/8qz2XeBmIXCX2sih1JgqGrwAGfQI41xQz7ObnAE6Ge9UQVTU+bnIkpueiV2Nv9GlSC5Mfa6jpCSjszd9P4+aDDLzSLVgz38MSqdkl+weBk4N27pqdzuzVt/88a/baS4X2U/oy7JrZa8IuJ+LrgqGfK/fTSyW/ie6k26/3X8eD9Bz8HhmHTsE18GTbQGw7cxc/jO6IGgVBo1Il4MPtlzXXXC/UU7T19F10rqc/rDN5/WmkZOXh7T/PWTT/x5YkgiVpBSs4a7anpipKEID3PMVjZ2/9FPqWqN3Z+NBQYXZOQL5O+v8mg4GRvwOfNgIyE4HZtwEnT+s+2xJnNwB3T4lzb0pz1RNRMdxNycbei/F4vmOQZjlv8JztRV7Tr6mPZu6IJT4c1lKzYqU4Zg9siida+6OWmxzj1v2HY9et3KC1DD3e3Bd7LhlOsi2uG4sHQyoBZmw6W+ScGGN83eWaRHXrJ4TgxVURJuuWRT4aa76/GbBQ1bG0jpg4buZ1IOW2OEflTiSw8aWy/dw3IoBvQ8TjEevF3pb9H4pLq/11lolmJotzcpo/Kc7Rscaigv1qRm4AmgwqnXYTlSJzAYutvNmvEb6yoIekMnu8uTiR2JoJtcVh64CFQ0JUdUy7IO4t5FpLfAFAs6FiEHFgCfDMD8B3ZbC3ijpYAYANL2qPN/8PmHJS+/7XZ4D7Z4CE88DjxdzNOsswbwIRmVbVgxUApdpbU5Gxb5mqDkd3bbI4XU2HABOPAr7NgTGFMur2mA4MWFw27Um+Bhz+VPv+/hnx5/k/rbuPbieotOpmHaXKTXfy7dA2AWbrFycpWllwqER76dja2LWRZlc/lSX+l6LqpX4fYNJ/QK1mwLOrgdCFQNdJ4jDS+DDj19RqVvzP2/8h8NdE/dVF6feAGwcsv0d+jva4NPdFIipFe6f3Rn1vFzTyccVnz7fGX290K7J+4T1yZg9sWoatM+3YnL42+dzKKPxmst5WA+WNAQtVP7UaA5NOiHsaqbnWAmp3BIYsM6w/6UTJPu/seiA2XL/sl2FAfq7R6gYU2v1OipX6kqgc1HRxwP6ZfbDnrV6Q28n00tcDwJOFel1qOOsvh24ZaDh/YUb/xqXfUB2/jOtc4fbLqcjKav8jSzFgIdLVaRywKFXsfQGAJgWTzEb/BXQaX/z73jWSc+GLlkBOmrgNQfRO4No+/Z4YNd0NHZUl33+FqCypE5AVDli+GtkO1z7SThj3cNb/8jP2ZVjHSz8PTICHNh9TafxDv2cjca7bh8Na6pVvf7OHVfcZaMVu1Naq5+2CxwqyDdtacbIalyYGLETGtHwWeOME8PxP4vsGfYEhn+vXCe5p+f32zjcsy0wEVnQGts8Afh8B/PYscPpn/Tq3DgOHP9G+z9FPS24VlVJ8EZUDR3vt14vcTjy2l0nxwbCWGNk5CB8Oa4lAT+1qOVcjux0XzmVyfK4211KrQA/UKUhs17ORZWnrda18qYPm+KUudbF2bCfN+8LJ8QDg6XaBJu/13UvtLfpMN7kdfhjdQW8PI3MOzOyDtWM7W1x/VEgdi+tay83If6PyxICFyBiJBPBpJiau09XlDfFnu5fElP0jN5Tsc9Lv67//ZyqQUpBxUqUC1g0FTv+qPb9rTvE+R6UCvu8N/NDbeC9OrmEqcqKScLTT9rD8OVE7n2V0l7pY8kxrODvYYe/0XnrXdGvghSa+bngrtDH6NKmF0GbaHaU7B+snPLOXSbHxtS74YFhL/DC6I47OfszitvVuXMtgF2IXB+2Xsb2RXEdPtQ3AlQ8G4u2BTfTK69dysXhjwHXjOuPxFn5447EGFrdVrXYNy1IhlOWwjSt7WIgqkb7zxcm5TywXg5omg8QJu6M2m6j/rvWfoc7Ym2FmqaLu3BZzMh+Iy6njzwM5KfrnrocBSwKB/R9Z1Uyiosh1elh83I3PE3Gyl8HbVQ4nexmCajrht/Eh2Dm1J6aGNsJPYzvDwU57jyfbinNgljzTCrXc5Fj0ZAv4ezhhdJe6cHKQGd0jx5jXezfA8uFtDcp1O3OkUglcHPSHtNTzct7o01Cv/K+J3Y1+jm6PjVQCTH6sIdrXETNhe7vK0cTXzeCa3o1ND/389UZ3fDfKfE+Obs9WaZPb2XbSPwMWIms4OIuTc2U6/4pxrQU06g/MiAZ89cfCNXNgrJGRAPw8DFhmYtVEfq64XHppEBBzFLh/TttrYqz3BAAE3T2QCu0JsmOW+FN36ImohJwd7PB67wb4X/d68HFzNFpHIpHg6OzHEDU/FHI7GSQSicEqFHVa/S71xR6WkZ3rIPKdfmgZ6GFxW/o394WvuxyfPd8GcwY11aSy19Xc3wP2MgmCaoo9GXun98Ynz2oTP+oGT2pucjvNXJyVL7XHIJ1eG91Jxb+N74KZA/R7ZpSFcra6OMiKHHaq5SbHoFbatA3dG3rhxzEdcWKu/pYkzjqBliXLy63hZG/bgIWJ44hKi5sfMPGYGEB8XzC/xcUbmJ8EbBgl7lHkWQfYMdP8vW4Wsez595HAjYIl2D8VBET9FgA1goG/pwDPrQGaDNS/Jk+nNyY/R5zLos7pIuG/W6hszBlkfqly4cm5hf03LxRJGblo6KPtkTA3BDO4lR9e69UAT604BgBoGeCBVWM6FnmNk4MM5xYOgJ1MvHeApxMeb+GLtwvSJsl0Aqkfx3TEwm0XseyFNpqygS39MbClP1Ydvom7KdloU9sDr/dugJikTIQU2r8HgF5W2kvvD4BKEIMWDyd7jP3pP5PtbBPkibNxKfhyRDt4u4o9VzFLh2gyDXetr53P0zrQA/+cvQdAXMX1MLNkk/YLb5xY3hiwEJU2n2ZAzQZiQODsJf4c9Yf2fP3HgENLgZsHxaEaAHjyG+DS3+IGj+bcMJIvJux97fGGF4GFD8VemEe3gd5vA1/rdCX/8oy40/T/douZc3WT0aXEiYGXzLbLF4nUarg4GO0RKYpUIkGbQnleLOFUaBjITmecSLfjJ7S5L0Kb+8KYCb3qa46LCtjaBXniVlImZFIJnHXmzzzW1AeNfFxxLTHD6CTXLRO7ITtPaTBJ+cjbjyHuURZa1db2POn2Vv2vezAa+rhZtEu0rkBPJ9xNEfdPy81nwEJUtcjsgUkR4jCMscy03g2BZ38Uj++dBhxcAe9GQJuRYiCjmx23OAQlcOuImLQOAE7/on8+uSBV+ef6XdQAgOUtgYb9gZdMzMkhqsA8nOyRmp2Hx5r4AADa1fHE6dgUzfwXa+nu8iwt5RxIC4e2QICnE4a1M2zbqjEd8dX+a3i9t+HkXJlUYnRFVVBNZwTV1J/HoxtkSaUSDGzph69GtsObv58GAGx5oxs+2x2NYe0C0Tm4JpIzc/EgPRcb/ovDwWjxH1P7Z/ZG+/f3IlOh1JsEbQsMWIjKgqU9FAHtdK6xA/q8I+ZaOfZlyT5/3RPFv9aSXh6iCmjv9F44fydVE7Bseq0r0nLyUdPKHho1e70eltINWDyc7Q3mtagFe7tg2QttS/wZrWt7ao7V7R/a2h91azqjoY8rXOR2WD+hi97nAuJ8nYPRD9DQxxVyOxkOzOyDk7cf4XETvUrlhQELUUUilQL93wca9BN7XpS5wOZx4rlajcVhJFt5FAPYOYpDRrqSbwB7F4j7MtXuYPRSixxYLPZKFWdlFREAHzdH9GumneBrJ5MWO1gB9OetqCfjVgb7Z/TG7eQsdKhbQ1MmKwhYJBYMlz3WxAfb3+yBYC8xgPFxd8TgVkb2aStnDFiIKqL6vbXHMy6LPx/FiBNu278M3IkEAtoDRz4Hsst4B2dBALKSgS8LJhguKpS8btPL4nLpK/9qz2U/Ava8Kw5zBVuQNTQnFTj0sXjc5Q3AudAkRUEATq4B/FoBQZYn0SIqqah3Q6FQqmyelt4a9Wu5on4tMfldDWd7PMrKw2NNLc+WK5FI0CLA8lVY5YUBC1FlUSMYeEO9J9Hr4o/GA4BvOgLO3uLEXqkd8H0vU3ew3LGvgMRLQJ854v10M+zmK/QT6iVdM7x+7wIx4d3pXw0DHGOUOkutjW0/cOsQsH26eGzJ/YhKiZdr5d5r6MjsvniYoTDY5qAyYsBCVJl5NwLePAO4+QP2BV3hXScD4d+U7L7qrQTO/m54TpEB2On0gEiN/DVy/5x1n6cbpBTOEwMAKbHaY0HgJpBEFnKV2xmdpFsZMQEDUWVXs542WAGAAR+JmXjLysW/xOR1W98Azm4EJIVWQgmCOCSkZix3Q9ZDcdNHdT3dgCU/F1DmATcPAdveBJKuA3KdnXxz00rvWYio0mDAQlQVdRwLTDkF9NRJUhcyUXs8/TLQ8rni3Xv7dOBDH+DMb8BfrwK5OkM0e+YD73kCKbe1ZfsWiEGLbmbPLRPETR83jgbCvwUe3tSeUyrEuTo/PwmcWgf88rT+52ckFq/dRFSpVY1+IiIy5NUA6Ddf3HnaqYa4ukeRDng3BtwDgKe/By7o5FtpN9owZ4u1jn9lpOxrMSleSizw2hEgLxu4vk88F3NEfOl6dFt/aXVqrP48mYxEcSisLNw9BZxcDfRdALjZdgknEemTCEKhDQ0qobS0NHh4eCA1NRXu7u7mLyAi0Q99xOR1Xd4ABi4Rh2j+niyu+NEVFALERdikiQaeWwu0fKZ07nVipTik1niA+H5RwcqIxgOBFzeWzmcQkUnWfH+zh4WoOhu1Gbi2F2gxTHzvVAMY8RuQkwb8OR64thsY/BnQeQJw5ndg6+s2bS6A0hsSij0B7JotHhdeefQgunQ+g4hKDeewEFVnLt5A25GAfaGkWI7u4jLpRalisAKI9ebeAYIKMmM+t6Z826qWEQ8osgzLDywBIr63/D6Jl02f44aQRBUO/68kIsvJ3YCXtwFTzwLNC02GfUwnQ23PGcCI34GO40q/DUe/ABb76y91Tr4h7sO0821xhZEldFcy3TsDJF7RvlcHLCoV8NfrwKES7u9ERCXGgIWIrGMnF5PYSaXAE18AkADj9gK9ZgLv3AcmRQJ95gJNBwNPLCv6Xu1fLn47lrcCfnpCXCL9Y6i2fN1Q4Nwf2mGdrIfAwY/FCbUbRolDYID+UuofegPfhmjfqzetjD8r5qI58KHxXh1LZDwAvu0qBlrX9gKHP9NfMVUaUmIBRWbp3pOoguGkWyIqW6d+AbZNBjqNF+efXN4mlnebAjz+oXaia1noPg0IXwGoCvW6jN8P/DsNiDeR4M6nBfDGcXHXa/VGkuP3F2+vpEOfAAc+0i8b9SfQKNR4fWs9uAqs6CQmD5xxxXx9ogqEk26JqOJoPxqo30f8QpVIgX0LxWXKvQsmvNbrBdw6bP4+dXsAt49a99nHlhsv/7Fv0dclXhR7anTnsuju2SQI4qTkGnWBfguKvpexnbvT7hR9jTWu7hR/pt8vvXsSVUAMWIio7HkGaY8f/0D/3DOrxF6Y9mOA/GzAo444RFO49+OJL8SehPJSOIjKTRdf6fFAzFFtDpu+84veKsDB1bAs4VLptZOommDAQkS25eYH9J6lX5afY1jPzkHs8RCMpPovD8eWA5vHGpbn5+pvjVCYsbklkd8DPd4Sn70090U69QsQvRN49kfAofJvdkeki5Nuiaji6fKG+LPRAG2ZSy1xQm+Lp4GaDYDRfwELHolLrZs+ATQeVLZtun/WeLkiA1AptRNpDywBvmyrzRdjajLssqbiBNyiHPoE+Lab2LOjdnUPcHW39r3uNMRtk4Ho7UDEyqLvS1QJsYeFiCqeDq8AgR2AWk2AtHtiQODgIqbkf/4n/bpyNzHZXb4C+GMMULujuBrHuSYQvUOs8789wPk/xI0aI63I1WKJrGRgZQ9xy4Phv4rLqwFg7SDxc9VtMObAh4a9S1kPgcv/iMn81JN1l9QWc+IosoD1z4tlc++Iz24M57NQFcSAhYgqHokE8G8tHtesZ9k1dg7AixvE414Fmz4m3wDysgC/VkCdECA3o/QDlhWdxZ/p94GlOnN1kq8Dn9a37l5xkcDq/uLxP2/qnxMEcR8mtZw00wGLsSE1okqOQ0JEVHV5NRCDFTW5KzDzOtDnHW1Zu5eA5k+VLCdMSRz/Rpvj5e/Jput91gh4oLNsuahhnzwGLFT1sIeFiKoX11pAn9niqzCVEjjzq/a93AMYtxtw8bG+t8RSe+YBD2+KezYlFbGHUeYD4KfB2vfHvwLajgLOrDesW5o9LLkZwLmN4jwh7mBNNsQeFiIiDZ0JrJP+A+bcBnyaAS5egL2LWN5pvJjptzSdXA28X8P6674NMR7k5Oca+Yy1wD9TxaDMHJUKuH9O3OZg52xg+3Tg12etbx9RKWIPCxGRWp85QFwE0PlVoFZj/XNvhIv5V1oPB2R2pjP0NgwFru8zfs7VT9y8saxd2w1c3CpO3L1zUpxP8+80bfuaDTW8JvWOmNxPKhOHm3bPFXtwzhfkm0k4X/btJioCe1iIiNQ86wBTooCQ1wzP1agLtBslBisA0HqE/vlubwLvJgIv/Wl4bf/3xR6akb8DTQbrz6spzD2w+O3Xtell4FGMuM/SXzrPc/MgoMzXr3t1D/BFCzF7LwAcLtjs8cxvgNJIbw0gTgBO5FYAVH64lxARUXHkpgOXtgF/F+SMmZegTSD38JaYETc/G3BwA4I6iUGCOtgRBCA2HEi4CLQZCez/QDuJttEAMbB5v2bZtb3tKGDYt9r3qx8Xe5YAcfn0502NL41elKo9XjMIiD0OvPgH0LggX87DW+IWBoFW7rn0IFpcIdV2lLipJlUb3EuIiKisyd3EHpemQ8Tsu7rZbmvWM1yOLdP561YiAep2E18AMGCJNmDJShaHZdxrl+6eQ7rO/AYMWAw4eYrv1cGKmp3c+HXJN8SVV4AYrADAf6u1ActXbcWfb56xfDk6oF0abicHWr9g+XVUrRQrlF2xYgWCg4Ph6OiIkJAQREZGFlk/JSUFkyZNgr+/P+RyORo3bowdO/STKVl7TyKiCsHJU0xSVxJSqZh4DhADIABQ5ZuuX5hvS2DWDbEHpH4fy675uC6w8SXg6Bf65b+PFIeSjPm6AxBbKLjJyzKsZ2oXbHPu/Fe866hasDpg2bhxI6ZPn46FCxfi1KlTaNOmDQYMGIDExESj9RUKBfr374+YmBhs3rwZ0dHRWLVqFQIDA4t9TyKiKueV7cAzPwJdJ4nvn/xa/Nl7trikGACGfgU0HwaM3Aj0fVcsG7kRmHgMcPEW34/aDLxmwe7XgJhRd98i/bKiMvNCAPa8Cxz7UlsUcwTYu0DMNKwWuQpIK0a2XVvtE0WVgtVzWEJCQtCpUyd88803AACVSoWgoCBMmTIFc+bMMai/cuVKfPrpp7hy5Qrs7Y1ss16MexbGOSxEVCXlpAKOJlYjCQKQ/ch4705edsF+RoVWJDl7ieeM9YqU1BPLtSuR1N59IOaEcTTx97JKCSRdE5dnA0DHccATy0q/bVRhWfP9bVUPi0KhQFRUFEJDQ7U3kEoRGhqK8PBwo9ds27YNXbt2xaRJk+Dr64uWLVti8eLFUCqVxb5nbm4u0tLS9F5ERFWOqWAFEOfBmBqKsncCpp7RHx4K7gm8eRqYd1+cH1PaCgcrAPBhLXG7grungAt/ikvB1wzUnt8+QxusANDLg0NUiFUBS1JSEpRKJXx99bMd+vr6Ij7eeG6BmzdvYvPmzVAqldixYwfmz5+Pzz//HB9++GGx77lkyRJ4eHhoXkFBQUbrERFVW/ZO4pYDaq/8qw2Axm4H+i0ov7asfhzY/D/xODZcXA4tCEDUWv16JV20KghiZl6qksp8/ZhKpYKPjw9++OEHdOjQAcOHD8e8efOwcmXxtz+fO3cuUlNTNa+4uLhSbDERURXR/hVxqGZSoUUMNYKBnjPEeTAtnhZ3sQbEIRm1V3YATYYAdbqVvB2qPP3334YA73ka1jOWodeY49+IE4DT7umX//sWsCQQiL9QrGYapbvhJNmUVcuavb29IZPJkJCQoFeekJAAPz8/o9f4+/vD3t4eMplMU9asWTPEx8dDoVAU655yuRxyuYlld0REJJJKgY5jTZ/vNUv/vUoF1GoCBIUAAW2B4O5ir4VucFGW2XrPrhdfY7YBbn7iyimJRDx3dQ+QkSAGW3vmiWWHPwWe+AK4eQhQZGp7bI4uA55bU/L2/PejOGw1/Ffj2YGpXFnVw+Lg4IAOHTogLCxMU6ZSqRAWFoauXbsavaZ79+64fv06VCrt7O+rV6/C398fDg4OxbonERGVAalUzPIb0FZbpg4Y1KadAwZ+rH3f5Q2gXi/tezf/krfj5yfF3CwnVwPZKeIcmPXPA9smA+ue0NZTKsTcMD8/CWwYqS23cyp5GwAxWAGAP2y0k3d5UOYDqXdt3QqLWD0kNH36dKxatQrr1q3D5cuXMXHiRGRmZmLsWDGKHzNmDObOnaupP3HiRDx8+BBTp07F1atXsX37dixevBiTJk2y+J5ERGRDdQr+8diwv5jcrcUw7bk+c8QekXH7gLcuib0RpjR9wvQ5Y7bPEPPFrHrM+PmES8DX7Q3LTSW+MybPgp2tBQs2jKzI7kYB26YAGQ8Mz61/HviiubhlQwVndabb4cOH48GDB1iwYAHi4+PRtm1b7Nq1SzNpNjY2FlKd1MpBQUHYvXs33nrrLbRu3RqBgYGYOnUqZs+ebfE9iYjIhl74BTi/CWhTsH+Sqy/Q6gVAItVO5A3qJP50DxD3WapRVzwXvgJIK/gXfP/3gSv/Gv8Mmdz0vkWm3DtlvNzO0Xh5xgMgJ0Vst72zmCDvp8Fi/pdnVwOtnjP9WbkZgNzVuvbZgiAY9oqt6iv+zH5kGFDe2C/+jFxledJBG+FeQkREVHbyc4EtEwCfFkCf2dpdrj3rACmxZfOZPd4CQheJx1d3A+tNpPuv1Qx4cFn7XnevJEB/R+5ubwLtRgO/PiPev9M4VAj5CsDOQTxOvAysHSROqO42RVtH/RzeTYDJhSZgq881G1p071gZKbM8LERERFaxkwMv/CwGK4DYk+HiAzz9PdDhFW29J74wenmxHF0ufhGvftx0sAIY9kQU5d5pYMcMIDUO2D5dLCvNFUQpceKkZ2s8ug18Ug/Y8bb4ftdcsRdlz7vG60skQHqCflZi7UnrPtsGGLAQEVH5afUcMOuauPGjbgd/x/8Bgz4tpQ8puG/hTR0LKxxw3DgA7Jkv7rQdvVP/nJ1cXImkdugT4CM/4Pbxkjf3/GZgeUvgnynm6+o68hmgyAAivxffS3S+0s9vNqyfdBX4vLF2iEiXbvCWXkarwEqIAQsREdmGSy399yGvlu/nF96i4JdhwPGvgM+bAL+P0D8nk4tbCagd+Ej8qe7dKK5TvwB/Fgwvnf4ViDlmWCc3Q/+zdcv12uigPf7TyJCVeq+mhPOG59TBzvFvxOc/8rn5tpczBixERGQb3aeKyemeXa0tc/HRHs++DUw8Dji4AY0HAkFdSvfzFVbsqRS93fRqoYe3zGfpvbEfiPhBv5cGEJdq6/ppsP779AQxGd7PT+mXCwJwcYt+mZ0Diq+gh0Wd4ybsfXHJs7GVRTZi9SohIiKiUuHoDoxcr1828ndg60Sg/weAk6f4evum9ss4+Ya4oiXiO/F9w1Cg73zgh97Wf74i3br6mUmGZQnnga/aAo9/KG5W6d0EaP28fh1BAH55WjzeOQtY8BCQyoCI701/jnr37cvbxJ8xR/TrFB6yAvR7WKxlbD7P2kHAnUjgjQjAp2nx711KGLAQEVHFUbsjMPk//TLdngOvBsCgpWLvzJlfxe0HXGsB06+Iwc2KECDldtm0Lf2+6XO6E10LBywPrhR6Hw34NAN2mhhO+rQBMD5M/F0IhSbiXt8n7rp9/GvD6woHLMaWOJtkpN6dghVF5zYCoQstvE/ZYcBCRESVj7u//tYC7gUZdsfuFBOh2dJ33YGBS8QMwJnJwLeFhrK+6wq0et74tWpHPgeaDNIPapJvAL8+a7x+bgaQkahfpswr4TCRWsXIfsI5LEREVHV4BAJj/gaGfQeM3ADIPfTPNx4I9Jhetm1IuACsGypuwnjbyCRaQEzEVxR7JzE7ra6i8tZ81w24vle/rKhEfDveBtJ0eowubDY+5AUY9vLYCAMWIiKqWur3Adq+KPZQzLkNdJoglv9vtxjE6CZVc6pZ9L36lWAoZGUPw52qLXXhT8OyX4aZrm9sGMxovpUCkd8DywrNS4lcZbzusS/NTyouBwxYiIio6pJIgMGfAnPvAHW6iO+dawKzbgJP/wBMiQImHDB9fdfJ+sM3HkFWfLgARP5Y7KaX2Kf1xWXKlsrLNH3u2HJxKwMbBi4MWIiIqGqTSAC5m36ZixfQZrgYvAS2B+Yni8NIhSeu2jkAfbQb+qLdaOs+O7YUEsuVhHqZsiWK2ghy3yLgy7Y2HR5iwEJERCSzE4eR5sUDc+8Cj80Tl/MCgGddbb0aweJkWjUHN3FPorE7gRbPFP0ZT31rWOboYVhmKzFHiz7vXFNcjm0jDFiIiIjUpDJxV+beb2tzj8jsgLo9AHsXoGE/wL+Ntv7Us8D4feJWA8+vFefIGBPyOtB6uGG5s1fpP0Nx6W4EaZRt9xvismYiIiJzxvwtpvJ3dNffUsClUMDRZJC46/P1feJO0T3eAtwDtOennBJ3Vf77DTHRXOvhwMEl2vNydyA3zXQ7XGoBmTrZZ2s2AB7e0L4fthLY+nrxntGcLBOriMoJAxYiIiJzZHaAzF087jRB3L256ROm6zcMFV+FeTUQX34txSGY1sPFtP35ucCE/dohlxv7tdlx9a5vqB+wKAutQmo7suwCFhtjwEJERGQNB2fg+Z9Kdo8aweILEJdbA/pZaRv0FXtqYo4B0TuAW4fFDRAbDwBiw3VupLNqx02nJ6ew144Ado7Aik7m2+bmbzyrb1GrqcoBAxYiIiJbKip9fnB38aVSifWUCiDhkhjAPLda7Jn5tWCy7+i/xJ9jdwGbx4rzai7/Awz+DPBvrX/fVi8A5/8w/pkv/Ays7m9YHtje+mcrRQxYiIiIKjppwRoZOznwrE6Ct3untcc1ClYz1e0KzCjYv0il0l4LiD0t2Y/EoSd1wFKjHtB+tLhDMyDmmplyCvjatgFKYQxYiIiIKqtaTQE7J3HJsZ2j4XlpocXAuj0tL20R58SoA530BEBQavdlmnoO+Kaj2KvTekTZtN8KEkGoAPl2SygtLQ0eHh5ITU2Fu7u7rZtDRERUfnIzxB4Te6fSv3fafXFYqe1Iw+R7pXF7K76/2cNCRERUmcldy+7e7v5AyKtld38rMHEcERERVXgMWIiIiKjCY8BCREREFR4DFiIiIqrwGLAQERFRhceAhYiIiCo8BixERERU4TFgISIiogqPAQsRERFVeAxYiIiIqMJjwEJEREQVHgMWIiIiqvAYsBAREVGFVyV2axYEAYC4TTURERFVDurvbfX3eFGqRMCSnp4OAAgKCrJxS4iIiMha6enp8PDwKLKORLAkrKngVCoV7t27Bzc3N0gkklK9d1paGoKCghAXFwd3d/dSvXdFxOet+qrbM/N5qzY+b+UmCALS09MREBAAqbToWSpVoodFKpWidu3aZfoZ7u7uVeIPh6X4vFVfdXtmPm/VxuetvMz1rKhx0i0RERFVeAxYiIiIqMJjwGKGXC7HwoULIZfLbd2UcsHnrfqq2zPzeas2Pm/1USUm3RIREVHVxh4WIiIiqvAYsBAREVGFx4CFiIiIKjwGLERERFThMWAhIiKiCo8BixkrVqxAcHAwHB0dERISgsjISFs3yWpLlixBp06d4ObmBh8fHwwbNgzR0dF6dXJycjBp0iR4eXnB1dUVzz77LBISEvTqxMbGYsiQIXB2doaPjw9mzZqF/Pz88nyUYlm6dCkkEgmmTZumKatqz3v37l289NJL8PLygpOTE1q1aoWTJ09qzguCgAULFsDf3x9OTk4IDQ3FtWvX9O7x8OFDjBo1Cu7u7vD09MS4ceOQkZFR3o9illKpxPz581GvXj04OTmhQYMG+OCDD/Q2T6vsz3v48GEMHToUAQEBkEgk2Lp1q9750nq+c+fOoWfPnnB0dERQUBA++eSTsn40o4p63ry8PMyePRutWrWCi4sLAgICMGbMGNy7d0/vHlXleQt7/fXXIZFIsHz5cr3yyvS8pUYgkzZs2CA4ODgIa9asES5evChMmDBB8PT0FBISEmzdNKsMGDBAWLt2rXDhwgXhzJkzwuDBg4U6deoIGRkZmjqvv/66EBQUJISFhQknT54UunTpInTr1k1zPj8/X2jZsqUQGhoqnD59WtixY4fg7e0tzJ071xaPZLHIyEghODhYaN26tTB16lRNeVV63ocPHwp169YVXnnlFSEiIkK4efOmsHv3buH69euaOkuXLhU8PDyErVu3CmfPnhWefPJJoV69ekJ2dramzsCBA4U2bdoIJ06cEI4cOSI0bNhQGDlypC0eqUgfffSR4OXlJfz777/CrVu3hE2bNgmurq7Cl19+qalT2Z93x44dwrx584QtW7YIAIS//vpL73xpPF9qaqrg6+srjBo1Srhw4YLw+++/C05OTsL3339fXo+pUdTzpqSkCKGhocLGjRuFK1euCOHh4ULnzp2FDh066N2jqjyvri1btght2rQRAgIChC+++ELvXGV63tLCgKUInTt3FiZNmqR5r1QqhYCAAGHJkiU2bFXJJSYmCgCEQ4cOCYIg/oVgb28vbNq0SVPn8uXLAgAhPDxcEATxfzCpVCrEx8dr6nz33XeCu7u7kJubW74PYKH09HShUaNGwt69e4XevXtrApaq9ryzZ88WevToYfK8SqUS/Pz8hE8//VRTlpKSIsjlcuH3338XBEEQLl26JAAQ/vvvP02dnTt3ChKJRLh7927ZNb4YhgwZIvzvf//TK3vmmWeEUaNGCYJQ9Z638BdaaT3ft99+K9SoUUPvz/Ps2bOFJk2alPETFa2oL3C1yMhIAYBw+/ZtQRCq5vPeuXNHCAwMFC5cuCDUrVtXL2CpzM9bEhwSMkGhUCAqKgqhoaGaMqlUitDQUISHh9uwZSWXmpoKAKhZsyYAICoqCnl5eXrP2rRpU9SpU0fzrOHh4WjVqhV8fX01dQYMGIC0tDRcvHixHFtvuUmTJmHIkCF6zwVUvefdtm0bOnbsiOeffx4+Pj5o164dVq1apTl/69YtxMfH6z2vh4cHQkJC9J7X09MTHTt21NQJDQ2FVCpFRERE+T2MBbp164awsDBcvXoVAHD27FkcPXoUgwYNAlD1nrew0nq+8PBw9OrVCw4ODpo6AwYMQHR0NB49elROT1M8qampkEgk8PT0BFD1nlelUmH06NGYNWsWWrRoYXC+qj2vpRiwmJCUlASlUqn3hQUAvr6+iI+Pt1GrSk6lUmHatGno3r07WrZsCQCIj4+Hg4OD5n9+Nd1njY+PN/q7UJ+raDZs2IBTp05hyZIlBueq2vPevHkT3333HRo1aoTdu3dj4sSJePPNN7Fu3ToA2vYW9Wc5Pj4ePj4+euft7OxQs2bNCve8c+bMwYgRI9C0aVPY29ujXbt2mDZtGkaNGgWg6j1vYaX1fJXpz7iunJwczJ49GyNHjtTsVlzVnvfjjz+GnZ0d3nzzTaPnq9rzWsrO1g2g8jVp0iRcuHABR48etXVTykxcXBymTp2KvXv3wtHR0dbNKXMqlQodO3bE4sWLAQDt2rXDhQsXsHLlSrz88ss2bl3p++OPP/Dbb79h/fr1aNGiBc6cOYNp06YhICCgSj4vaeXl5eGFF16AIAj47rvvbN2cMhEVFYUvv/wSp06dgkQisXVzKhT2sJjg7e0NmUxmsHIkISEBfn5+NmpVyUyePBn//vsvDhw4gNq1a2vK/fz8oFAokJKSoldf91n9/PyM/i7U5yqSqKgoJCYmon379rCzs4OdnR0OHTqEr776CnZ2dvD19a1Sz+vv74/mzZvrlTVr1gyxsbEAtO0t6s+yn58fEhMT9c7n5+fj4cOHFe55Z82apelladWqFUaPHo233npL05tW1Z63sNJ6vsr0ZxzQBiu3b9/G3r17Nb0rQNV63iNHjiAxMRF16tTR/P11+/ZtzJgxA8HBwQCq1vNagwGLCQ4ODujQoQPCwsI0ZSqVCmFhYejatasNW2Y9QRAwefJk/PXXX9i/fz/q1aund75Dhw6wt7fXe9bo6GjExsZqnrVr1644f/683v8k6r80Cn9Z2lq/fv1w/vx5nDlzRvPq2LEjRo0apTmuSs/bvXt3g2XqV69eRd26dQEA9erVg5+fn97zpqWlISIiQu95U1JSEBUVpamzf/9+qFQqhISElMNTWC4rKwtSqf5fXTKZDCqVCkDVe97CSuv5unbtisOHDyMvL09TZ+/evWjSpAlq1KhRTk9jGXWwcu3aNezbtw9eXl5656vS844ePRrnzp3T+/srICAAs2bNwu7duwFUree1iq1n/VZkGzZsEORyufDTTz8Jly5dEl599VXB09NTb+VIZTBx4kTBw8NDOHjwoHD//n3NKysrS1Pn9ddfF+rUqSPs379fOHnypNC1a1eha9eumvPqZb6PP/64cObMGWHXrl1CrVq1KuQyX2N0VwkJQtV63sjISMHOzk746KOPhGvXrgm//fab4OzsLPz666+aOkuXLhU8PT2Fv//+Wzh37pzw1FNPGV0G265dOyEiIkI4evSo0KhRowqzzFfXyy+/LAQGBmqWNW/ZskXw9vYW3n77bU2dyv686enpwunTp4XTp08LAIRly5YJp0+f1qyKKY3nS0lJEXx9fYXRo0cLFy5cEDZs2CA4OzvbZNlrUc+rUCiEJ598Uqhdu7Zw5swZvb/DdFfAVJXnNabwKiFBqFzPW1oYsJjx9ddfC3Xq1BEcHByEzp07CydOnLB1k6wGwOhr7dq1mjrZ2dnCG2+8IdSoUUNwdnYWnn76aeH+/ft694mJiREGDRokODk5Cd7e3sKMGTOEvLy8cn6a4ikcsFS15/3nn3+Eli1bCnK5XGjatKnwww8/6J1XqVTC/PnzBV9fX0Eulwv9+vUToqOj9eokJycLI0eOFFxdXQV3d3dh7NixQnp6enk+hkXS0tKEqVOnCnXq1BEcHR2F+vXrC/PmzdP78qrsz3vgwAGj/8++/PLLgiCU3vOdPXtW6NGjhyCXy4XAwEBh6dKl5fWIeop63lu3bpn8O+zAgQOae1SV5zXGWMBSmZ63tEgEQSc9JBEREVEFxDksREREVOExYCEiIqIKjwELERERVXgMWIiIiKjCY8BCREREFR4DFiIiIqrwGLAQERFRhceAhYiIiCo8BixERERU4TFgISIiogqPAQsRERFVeP8HDuL1yiK/uMEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(val_lst2)\n",
        "plt.plot(train_lst2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
